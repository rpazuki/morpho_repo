{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7dad9f",
   "metadata": {},
   "source": [
    "# A failed training without regularisation (Or why we need it)\n",
    "\n",
    "> Here, we test a training without regularisation. The same network and dataset, with the same changes in learning rate was succesfully trained with regulariser (Observation loss reduced to around 2.0 unit). In contrast, without regularisation, practically it is impossible to train the model. These are the observation:\n",
    "\n",
    "1) Initially the loss value reduces for a moderate learning rate. But it reaches to a plateau that after sometimes spikes start to appear in loss values, and in overal the value remains at the plateau.\n",
    "\n",
    "2) To remedy the problem, we have to reduce the loss. However, the loss that removes the spikes (or say cuases the loss value to climb down from the plateau) is so small that the loss reduction is not practically useful, except for very very long training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23383b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:10:20.806297Z",
     "start_time": "2022-08-18T13:10:19.847074Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import os\n",
    "#os.environ[\"LD_LIBRARY_PATH\"]=\"/local/cuda-10.2/lib64\"\n",
    "#sys.path.append(\"/local/cuda-10.2/bin\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "#physical_devices = tf.config.list_physical_devices('GPU') \n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import time\n",
    "import threading\n",
    "import gc\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"/end/home/rh2310/morpho_repo/turing_codebase\")\n",
    "from turing.utils import *\n",
    "import turing.pinns as tu\n",
    "from turing.loss_functions import *\n",
    "from turing.pinns_experimental import TINN_masked, TINN_multi_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c39d083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:10:23.110961Z",
     "start_time": "2022-08-18T13:10:23.096944Z"
    }
   },
   "outputs": [],
   "source": [
    "df_params = pd.read_pickle(\"../../bacterialcolony_dataset/df_circuit2_variant5716gaussian_30000parametersets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51da19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:10:23.887384Z",
     "start_time": "2022-08-18T13:10:23.860468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Va</th>\n",
       "      <th>Vb</th>\n",
       "      <th>Vc</th>\n",
       "      <th>Vd</th>\n",
       "      <th>Ve</th>\n",
       "      <th>Vf</th>\n",
       "      <th>ba</th>\n",
       "      <th>bb</th>\n",
       "      <th>bc</th>\n",
       "      <th>bd</th>\n",
       "      <th>...</th>\n",
       "      <th>kaa</th>\n",
       "      <th>kbd</th>\n",
       "      <th>kce</th>\n",
       "      <th>kda</th>\n",
       "      <th>keb</th>\n",
       "      <th>kee</th>\n",
       "      <th>kfe</th>\n",
       "      <th>mua</th>\n",
       "      <th>mulva</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360.066204</td>\n",
       "      <td>69.840434</td>\n",
       "      <td>33.468912</td>\n",
       "      <td>283.316201</td>\n",
       "      <td>79.328098</td>\n",
       "      <td>35.847305</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316063</td>\n",
       "      <td>2.874391</td>\n",
       "      <td>88.732068</td>\n",
       "      <td>9.363779</td>\n",
       "      <td>9.627162</td>\n",
       "      <td>0.275728</td>\n",
       "      <td>5.519184</td>\n",
       "      <td>4.664757</td>\n",
       "      <td>1.485684</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271.955874</td>\n",
       "      <td>101.868916</td>\n",
       "      <td>28.546540</td>\n",
       "      <td>347.711607</td>\n",
       "      <td>84.727223</td>\n",
       "      <td>41.786928</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>...</td>\n",
       "      <td>4.883066</td>\n",
       "      <td>3.640181</td>\n",
       "      <td>99.577576</td>\n",
       "      <td>9.439324</td>\n",
       "      <td>7.552942</td>\n",
       "      <td>0.252092</td>\n",
       "      <td>4.607892</td>\n",
       "      <td>2.973656</td>\n",
       "      <td>1.423090</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310.495835</td>\n",
       "      <td>79.551016</td>\n",
       "      <td>51.789526</td>\n",
       "      <td>197.624749</td>\n",
       "      <td>51.961358</td>\n",
       "      <td>40.627957</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.013251</td>\n",
       "      <td>...</td>\n",
       "      <td>3.245317</td>\n",
       "      <td>4.944193</td>\n",
       "      <td>34.494922</td>\n",
       "      <td>13.954478</td>\n",
       "      <td>8.398245</td>\n",
       "      <td>0.299176</td>\n",
       "      <td>4.757444</td>\n",
       "      <td>4.151729</td>\n",
       "      <td>1.129469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>368.363031</td>\n",
       "      <td>99.843451</td>\n",
       "      <td>51.223075</td>\n",
       "      <td>312.732434</td>\n",
       "      <td>89.436871</td>\n",
       "      <td>49.564425</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941270</td>\n",
       "      <td>2.693431</td>\n",
       "      <td>89.807684</td>\n",
       "      <td>10.478264</td>\n",
       "      <td>7.656785</td>\n",
       "      <td>0.347844</td>\n",
       "      <td>6.552310</td>\n",
       "      <td>3.452419</td>\n",
       "      <td>1.213001</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252.138904</td>\n",
       "      <td>90.823276</td>\n",
       "      <td>43.880020</td>\n",
       "      <td>293.190760</td>\n",
       "      <td>87.402367</td>\n",
       "      <td>59.800131</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>...</td>\n",
       "      <td>4.101435</td>\n",
       "      <td>3.625196</td>\n",
       "      <td>60.758534</td>\n",
       "      <td>9.479563</td>\n",
       "      <td>10.618988</td>\n",
       "      <td>0.174654</td>\n",
       "      <td>3.911595</td>\n",
       "      <td>4.190837</td>\n",
       "      <td>1.634196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Va          Vb         Vc          Vd         Ve         Vf  \\\n",
       "0  360.066204   69.840434  33.468912  283.316201  79.328098  35.847305   \n",
       "1  271.955874  101.868916  28.546540  347.711607  84.727223  41.786928   \n",
       "2  310.495835   79.551016  51.789526  197.624749  51.961358  40.627957   \n",
       "3  368.363031   99.843451  51.223075  312.732434  89.436871  49.564425   \n",
       "4  252.138904   90.823276  43.880020  293.190760  87.402367  59.800131   \n",
       "\n",
       "         ba        bb        bc        bd  ...       kaa       kbd        kce  \\\n",
       "0  0.007714  0.009772  0.010261  0.008996  ...  2.316063  2.874391  88.732068   \n",
       "1  0.008341  0.012020  0.013054  0.010064  ...  4.883066  3.640181  99.577576   \n",
       "2  0.010750  0.015593  0.009346  0.013251  ...  3.245317  4.944193  34.494922   \n",
       "3  0.008238  0.010022  0.007271  0.007357  ...  2.941270  2.693431  89.807684   \n",
       "4  0.008995  0.008820  0.007773  0.011784  ...  4.101435  3.625196  60.758534   \n",
       "\n",
       "         kda        keb       kee       kfe       mua     mulva    n  \n",
       "0   9.363779   9.627162  0.275728  5.519184  4.664757  1.485684  2.0  \n",
       "1   9.439324   7.552942  0.252092  4.607892  2.973656  1.423090  2.0  \n",
       "2  13.954478   8.398245  0.299176  4.757444  4.151729  1.129469  2.0  \n",
       "3  10.478264   7.656785  0.347844  6.552310  3.452419  1.213001  2.0  \n",
       "4   9.479563  10.618988  0.174654  3.911595  4.190837  1.634196  2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f6e493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:10:24.897986Z",
     "start_time": "2022-08-18T13:10:24.783770Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../bacterialcolony_dataset/2Dtimeseries_circuit2_variant5716gaussian_ca_fullcircuitID194_L10_J150_T120_N1200.pkl', 'rb') as f:\n",
    "    ds_1 = pickle.load(f)\n",
    "    \n",
    "with open('../../bacterialcolony_dataset/caMask_seed1_pdivision0.5_L10_J150_T120_N1200.pkl', 'rb') as f:\n",
    "    mask = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc63aad",
   "metadata": {},
   "source": [
    "# Test two: Using mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc534e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:10:29.117400Z",
     "start_time": "2022-08-18T13:10:28.968343Z"
    }
   },
   "outputs": [],
   "source": [
    "ID = 194\n",
    "L = 10\n",
    "data = np.array(ds_1)\n",
    "nodes_n = data.shape[0]\n",
    "node_names = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "x_size = data.shape[1]\n",
    "y_size = data.shape[2]\n",
    "T = data.shape[3]\n",
    "N = x_size*y_size\n",
    "\n",
    "t_star = np.arange(0, T)\n",
    "\n",
    "##########################\n",
    "# select a subset of data\n",
    "t_star = t_star[-2:]\n",
    "T = len(t_star)\n",
    "data = data[:, :, :, -2::]\n",
    "\n",
    "model_params = {'training_data_size': T*N,#T*32,\n",
    "                'pde_data_size': T*N}\n",
    "\n",
    "\n",
    "dataset = create_dataset_multi_nodes_mask(data, mask, t_star, N, T, L, **model_params)\n",
    "lb = dataset['lb']\n",
    "ub = dataset['ub']\n",
    "obs_X = np.float32(dataset['obs_input'])\n",
    "obs_Y = np.float32(dataset['obs_output'])\n",
    "pde_X = np.float32(dataset['pde'])[dataset['pde_mask'] > 0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db5f343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-18T13:30:13.103784Z",
     "start_time": "2022-08-18T13:30:13.056222Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [3, 1024, 1024, 1024, 1024, 1024, 6]\n",
    "#layers = [3, 1024, 512, 256, 128, 64, 6]\n",
    "#layers = [3, 1024, 1024, 512, 256, 128, 6]\n",
    "pinn = tu.NN(layers, lb, ub, dtype=tf.float32)\n",
    "pde_loss = Circuit2_variant5716(dtype=tf.float32, \n",
    "        D_A=df_params.d_A[ID],\n",
    "        D_B = df_params.d_B[ID],\n",
    "        b_A=df_params.ba[ID],\n",
    "        b_B=df_params.bb[ID],\n",
    "        b_C=df_params.bc[ID],\n",
    "        b_D=df_params.bd[ID],\n",
    "        b_E=df_params.be[ID],\n",
    "        b_F=df_params.bf[ID],\n",
    "        V_A=df_params.Va[ID],\n",
    "        V_B=df_params.Vb[ID],\n",
    "        V_C=df_params.Vc[ID],\n",
    "        V_D=df_params.Vd[ID],\n",
    "        V_E=df_params.Ve[ID],\n",
    "        V_F=df_params.Vf[ID],\n",
    "        k_AA=df_params.kaa[ID],\n",
    "        k_BD=df_params.kbd[ID],\n",
    "        k_CE=df_params.kce[ID],\n",
    "        k_DA=df_params.kda[ID],\n",
    "        k_EB=df_params.keb[ID],\n",
    "        k_EE=df_params.kee[ID],\n",
    "        k_FE=df_params.kfe[ID],\n",
    "        mu_A=df_params.mua[ID],\n",
    "        mulv_A=df_params.mulva[ID])\n",
    "\n",
    "model = TINN_multi_nodes(pinn, \n",
    "                pde_loss, \n",
    "                nodes_n = nodes_n,\n",
    "                node_names = node_names,\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                alpha = 0.9, \n",
    "                print_precision=\".10f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf14540e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T00:19:15.870933Z",
     "start_time": "2022-08-18T13:30:19.638141Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training observations acc over epoch: 1145.0648193359\n",
      "total loss: 15829.0304870605, total regularisd loss (sum of batches): 696031.7690429688\n",
      "obs A loss: 4.2246743375, pde A loss: 5120.3623228073\n",
      "obs B loss: 4.6927841678, pde B loss: 256.7527177765\n",
      "obs C loss: 6.1464076936, pde C loss: 125.4461393282\n",
      "obs D loss: 6386.1614685059, pde D loss: 2154.5577612498\n",
      "obs E loss: 332.3585329056, pde E loss: 955.4344156832\n",
      "obs F loss: 202.7661969662, pde F loss: 280.1267388350\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 90.77s\n",
      "\n",
      "Start of epoch 1\n",
      "Training observations acc over epoch: 1060.5767822266\n",
      "total loss: 6910.3076171875, total regularisd loss (sum of batches): 304117.3178710938\n",
      "obs A loss: 0.7801252254, pde A loss: 125.8224857450\n",
      "obs B loss: 2.9428949729, pde B loss: 129.4230917692\n",
      "obs C loss: 2.7675320208, pde C loss: 2.3425850272\n",
      "obs D loss: 5879.0951766968, pde D loss: 65.4639121275\n",
      "obs E loss: 347.2613539696, pde E loss: 77.7738163471\n",
      "obs F loss: 130.6142287254, pde F loss: 146.0204238892\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 71.49s\n",
      "\n",
      "Start of epoch 2\n",
      "Training observations acc over epoch: 1074.8598632812\n",
      "total loss: 7113.6170501709, total regularisd loss (sum of batches): 312963.0444335938\n",
      "obs A loss: 1.6517572184, pde A loss: 140.5764174759\n",
      "obs B loss: 3.4949749671, pde B loss: 115.6578225344\n",
      "obs C loss: 2.8185003474, pde C loss: 2.7771916380\n",
      "obs D loss: 5941.6505889893, pde D loss: 133.6592292637\n",
      "obs E loss: 357.1732659340, pde E loss: 103.2312026769\n",
      "obs F loss: 142.3700561523, pde F loss: 168.5559988022\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.57s\n",
      "\n",
      "Start of epoch 3\n",
      "Training observations acc over epoch: 1011.4115600586\n",
      "total loss: 6585.8013992310, total regularisd loss (sum of batches): 289756.6625976562\n",
      "obs A loss: 2.9656674587, pde A loss: 112.3310570568\n",
      "obs B loss: 3.3854736723, pde B loss: 103.5155313611\n",
      "obs C loss: 2.9024770595, pde C loss: 2.9854266564\n",
      "obs D loss: 5590.7880401611, pde D loss: 139.8647178859\n",
      "obs E loss: 350.1785407066, pde E loss: 40.2296442557\n",
      "obs F loss: 118.2491152287, pde F loss: 118.4057335854\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.27s\n",
      "\n",
      "Start of epoch 4\n",
      "Training observations acc over epoch: 979.6982421875\n",
      "total loss: 6149.7159347534, total regularisd loss (sum of batches): 270566.3950195312\n",
      "obs A loss: 1.5415165294, pde A loss: 28.8050721437\n",
      "obs B loss: 3.3170001730, pde B loss: 81.3637868762\n",
      "obs C loss: 3.2168556675, pde C loss: 0.6454327422\n",
      "obs D loss: 5445.6971206665, pde D loss: 28.6461220458\n",
      "obs E loss: 317.6014842987, pde E loss: 34.0560776591\n",
      "obs F loss: 106.8159725666, pde F loss: 98.0095083714\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.79s\n",
      "\n",
      "Start of epoch 5\n",
      "Training observations acc over epoch: 818.5479125977\n",
      "total loss: 5410.2454071045, total regularisd loss (sum of batches): 237992.8476562500\n",
      "obs A loss: 41.7086205781, pde A loss: 110.5991413854\n",
      "obs B loss: 20.0816431493, pde B loss: 66.8799363971\n",
      "obs C loss: 3.7296359129, pde C loss: 7.9752668079\n",
      "obs D loss: 4425.9157485962, pde D loss: 158.7703228444\n",
      "obs E loss: 313.2456173897, pde E loss: 36.4579870850\n",
      "obs F loss: 106.6063325405, pde F loss: 118.2751595974\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.56s\n",
      "\n",
      "Start of epoch 6\n",
      "Training observations acc over epoch: 674.7352294922\n",
      "total loss: 4252.4045791626, total regularisd loss (sum of batches): 187109.6838378906\n",
      "obs A loss: 13.2258186452, pde A loss: 10.0141410604\n",
      "obs B loss: 37.7900933921, pde B loss: 7.9860005341\n",
      "obs C loss: 2.2746122442, pde C loss: 2.0244268417\n",
      "obs D loss: 3603.2934265137, pde D loss: 31.0635561384\n",
      "obs E loss: 285.8573474884, pde E loss: 30.1245488822\n",
      "obs F loss: 105.9707038403, pde F loss: 122.7799479961\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.93s\n",
      "\n",
      "Start of epoch 7\n",
      "Training observations acc over epoch: 651.7338867188\n",
      "total loss: 4100.0080261230, total regularisd loss (sum of batches): 180396.5134277344\n",
      "obs A loss: 1.8827225603, pde A loss: 3.5296807662\n",
      "obs B loss: 8.9818350226, pde B loss: 3.4375056401\n",
      "obs C loss: 2.2302501611, pde C loss: 0.8967592922\n",
      "obs D loss: 3517.7722091675, pde D loss: 30.5128233116\n",
      "obs E loss: 272.3974704742, pde E loss: 24.7959747910\n",
      "obs F loss: 107.1387052536, pde F loss: 126.4320764542\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.11s\n",
      "\n",
      "Start of epoch 8\n",
      "Training observations acc over epoch: 646.1055297852\n",
      "total loss: 4286.7863616943, total regularisd loss (sum of batches): 188628.7619628906\n",
      "obs A loss: 1.2430496886, pde A loss: 6.3034417480\n",
      "obs B loss: 11.2051593885, pde B loss: 9.7087199241\n",
      "obs C loss: 2.1531831324, pde C loss: 1.1912170374\n",
      "obs D loss: 3474.1893157959, pde D loss: 214.8858450651\n",
      "obs E loss: 281.9557242393, pde E loss: 64.6983372569\n",
      "obs F loss: 105.8865251541, pde F loss: 113.3658387661\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.66s\n",
      "\n",
      "Start of epoch 9\n",
      "Training observations acc over epoch: 658.6596069336\n",
      "total loss: 4110.9548263550, total regularisd loss (sum of batches): 180881.1455078125\n",
      "obs A loss: 0.6248374712, pde A loss: 4.4369163364\n",
      "obs B loss: 35.0855091214, pde B loss: 2.7353294734\n",
      "obs C loss: 2.2974301111, pde C loss: 1.2572199531\n",
      "obs D loss: 3473.0090255737, pde D loss: 26.5070202919\n",
      "obs E loss: 326.9043006897, pde E loss: 17.9866215140\n",
      "obs F loss: 114.0369668007, pde F loss: 106.0736176968\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.23s\n",
      "\n",
      "Start of epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 644.9301147461\n",
      "total loss: 4135.1134796143, total regularisd loss (sum of batches): 182020.2954101562\n",
      "obs A loss: 0.5530930422, pde A loss: 10.8018799014\n",
      "obs B loss: 27.8202286363, pde B loss: 15.7622132841\n",
      "obs C loss: 2.1871196218, pde C loss: 1.6824504739\n",
      "obs D loss: 3470.2143249512, pde D loss: 180.9030066368\n",
      "obs E loss: 268.7820878029, pde E loss: 30.3622667845\n",
      "obs F loss: 100.0242922306, pde F loss: 26.0204958303\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.30s\n",
      "\n",
      "Start of epoch 11\n",
      "Training observations acc over epoch: 648.1217041016\n",
      "total loss: 4003.8960189819, total regularisd loss (sum of batches): 176161.0305175781\n",
      "obs A loss: 1.3900408158, pde A loss: 8.1599837090\n",
      "obs B loss: 7.6755603403, pde B loss: 10.0304435657\n",
      "obs C loss: 2.3248440214, pde C loss: 1.3234826557\n",
      "obs D loss: 3471.6738662720, pde D loss: 63.4792629629\n",
      "obs E loss: 298.2850365639, pde E loss: 11.8544196067\n",
      "obs F loss: 107.3802464008, pde F loss: 20.3188023828\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.78s\n",
      "\n",
      "Start of epoch 12\n",
      "Training observations acc over epoch: 634.5226440430\n",
      "total loss: 3824.7455368042, total regularisd loss (sum of batches): 168291.9067382812\n",
      "obs A loss: 1.8081261907, pde A loss: 0.7389157267\n",
      "obs B loss: 4.6707528606, pde B loss: 0.8065740226\n",
      "obs C loss: 2.0739474837, pde C loss: 0.1448525748\n",
      "obs D loss: 3469.5950546265, pde D loss: 12.4284131201\n",
      "obs E loss: 237.8257031441, pde E loss: 2.5762436436\n",
      "obs F loss: 91.1622620821, pde F loss: 0.9146516601\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.29s\n",
      "\n",
      "Start of epoch 13\n",
      "Training observations acc over epoch: 638.2457275391\n",
      "total loss: 4165.1078491211, total regularisd loss (sum of batches): 183256.4860839844\n",
      "obs A loss: 2.0406863168, pde A loss: 4.4973024763\n",
      "obs B loss: 3.7247941941, pde B loss: 13.2791369737\n",
      "obs C loss: 2.1523521803, pde C loss: 0.7562249333\n",
      "obs D loss: 3477.1780624390, pde D loss: 207.6576151410\n",
      "obs E loss: 243.9093484879, pde E loss: 32.5433442923\n",
      "obs F loss: 100.4689730406, pde F loss: 76.9000148413\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.48s\n",
      "\n",
      "Start of epoch 14\n",
      "Training observations acc over epoch: 641.1593627930\n",
      "total loss: 3960.2339706421, total regularisd loss (sum of batches): 174243.2785644531\n",
      "obs A loss: 4.2010857090, pde A loss: 1.5536235466\n",
      "obs B loss: 3.1214521341, pde B loss: 1.2376228641\n",
      "obs C loss: 2.1410117112, pde C loss: 0.6534383585\n",
      "obs D loss: 3474.0179977417, pde D loss: 6.8993844626\n",
      "obs E loss: 252.0852966309, pde E loss: 21.8407002389\n",
      "obs F loss: 111.3890016079, pde F loss: 81.0933837295\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.19s\n",
      "\n",
      "Start of epoch 15\n",
      "Training observations acc over epoch: 644.1171875000\n",
      "total loss: 3902.5814285278, total regularisd loss (sum of batches): 171712.5327148438\n",
      "obs A loss: 1.9670469873, pde A loss: 0.8525510161\n",
      "obs B loss: 3.1662647948, pde B loss: 2.5299196796\n",
      "obs C loss: 2.1257356592, pde C loss: 0.5422142050\n",
      "obs D loss: 3469.1710662842, pde D loss: 13.7568559311\n",
      "obs E loss: 281.0199060440, pde E loss: 16.2527101557\n",
      "obs F loss: 107.2531825304, pde F loss: 3.9439785337\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.44s\n",
      "\n",
      "Start of epoch 16\n",
      "Training observations acc over epoch: 636.6838378906\n",
      "total loss: 3841.4549713135, total regularisd loss (sum of batches): 169023.4631347656\n",
      "obs A loss: 1.0734023806, pde A loss: 0.3042703291\n",
      "obs B loss: 2.9528835379, pde B loss: 0.2561075269\n",
      "obs C loss: 2.0710869543, pde C loss: 0.1390655143\n",
      "obs D loss: 3469.9081344604, pde D loss: 9.3944873039\n",
      "obs E loss: 243.1029572487, pde E loss: 10.5682786484\n",
      "obs F loss: 100.9939985275, pde F loss: 0.6902877227\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.82s\n",
      "\n",
      "Start of epoch 17\n",
      "Training observations acc over epoch: 640.7475585938\n",
      "total loss: 3854.9118347168, total regularisd loss (sum of batches): 169620.8920898438\n",
      "obs A loss: 1.3616754059, pde A loss: 0.4112040268\n",
      "obs B loss: 3.0061231181, pde B loss: 0.4168177031\n",
      "obs C loss: 2.1025025845, pde C loss: 0.2793479817\n",
      "obs D loss: 3470.9711685181, pde D loss: 6.0835571680\n",
      "obs E loss: 268.5438628197, pde E loss: 2.3146575470\n",
      "obs F loss: 98.5000815392, pde F loss: 0.9208777392\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.80s\n",
      "\n",
      "Start of epoch 18\n",
      "Training observations acc over epoch: 638.0427246094\n",
      "total loss: 3972.0545272827, total regularisd loss (sum of batches): 174762.5498046875\n",
      "obs A loss: 1.1844852371, pde A loss: 4.4383553928\n",
      "obs B loss: 2.8289796151, pde B loss: 3.0755350881\n",
      "obs C loss: 2.1541723050, pde C loss: 0.3447199888\n",
      "obs D loss: 3469.9384460449, pde D loss: 17.6068017413\n",
      "obs E loss: 234.2221426964, pde E loss: 30.0838700300\n",
      "obs F loss: 117.9279639721, pde F loss: 88.2491090996\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.75s\n",
      "\n",
      "Start of epoch 19\n",
      "Training observations acc over epoch: 636.4793090820\n",
      "total loss: 3839.7873382568, total regularisd loss (sum of batches): 168942.3344726562\n",
      "obs A loss: 1.5206891689, pde A loss: 0.5685620020\n",
      "obs B loss: 2.8533832841, pde B loss: 0.4453702813\n",
      "obs C loss: 2.1111510992, pde C loss: 0.2885017617\n",
      "obs D loss: 3470.1595382690, pde D loss: 8.4815294436\n",
      "obs E loss: 242.1286725998, pde E loss: 9.2472532201\n",
      "obs F loss: 100.1021072865, pde F loss: 1.8805995896\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.10s\n",
      "\n",
      "Start of epoch 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 632.7202148438\n",
      "total loss: 3811.5100784302, total regularisd loss (sum of batches): 167715.2639160156\n",
      "obs A loss: 1.4185680579, pde A loss: 0.4017478712\n",
      "obs B loss: 2.8467535563, pde B loss: 0.1305537321\n",
      "obs C loss: 2.0705337934, pde C loss: 0.0903144925\n",
      "obs D loss: 3469.5379180908, pde D loss: 3.0750740397\n",
      "obs E loss: 231.7844357491, pde E loss: 10.9955764664\n",
      "obs F loss: 88.6627900600, pde F loss: 0.4957725230\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.48s\n",
      "\n",
      "Start of epoch 21\n",
      "Training observations acc over epoch: 653.5951538086\n",
      "total loss: 4327.7883377075, total regularisd loss (sum of batches): 190410.3359375000\n",
      "obs A loss: 1.4412632417, pde A loss: 11.2691223698\n",
      "obs B loss: 2.7522144727, pde B loss: 7.6207724031\n",
      "obs C loss: 2.2229979374, pde C loss: 0.9525397010\n",
      "obs D loss: 3471.4253540039, pde D loss: 131.1901305672\n",
      "obs E loss: 289.2974243164, pde E loss: 81.7161024809\n",
      "obs F loss: 154.4306933880, pde F loss: 173.4697762188\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.25s\n",
      "\n",
      "Start of epoch 22\n",
      "Training observations acc over epoch: 647.4113769531\n",
      "total loss: 4077.3844909668, total regularisd loss (sum of batches): 179410.1513671875\n",
      "obs A loss: 1.6232345942, pde A loss: 4.9427488297\n",
      "obs B loss: 2.7154357918, pde B loss: 2.4972424237\n",
      "obs C loss: 2.2264090143, pde C loss: 1.0988607703\n",
      "obs D loss: 3473.7413330078, pde D loss: 7.1150529695\n",
      "obs E loss: 279.4159245491, pde E loss: 42.7400606871\n",
      "obs F loss: 124.7469389439, pde F loss: 134.5212814808\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.77s\n",
      "\n",
      "Start of epoch 23\n",
      "Training observations acc over epoch: 647.8282470703\n",
      "total loss: 3967.6368560791, total regularisd loss (sum of batches): 174573.7060546875\n",
      "obs A loss: 1.8854051083, pde A loss: 1.9049951572\n",
      "obs B loss: 2.7367449589, pde B loss: 1.2709142838\n",
      "obs C loss: 2.1399600804, pde C loss: 0.4074304357\n",
      "obs D loss: 3470.0455169678, pde D loss: 7.7676266227\n",
      "obs E loss: 292.6388511658, pde E loss: 14.5181126008\n",
      "obs F loss: 117.5218367577, pde F loss: 54.7994383797\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.04s\n",
      "\n",
      "Start of epoch 24\n",
      "Training observations acc over epoch: 637.1599731445\n",
      "total loss: 3840.8229370117, total regularisd loss (sum of batches): 168991.3977050781\n",
      "obs A loss: 1.9842994809, pde A loss: 0.6112855570\n",
      "obs B loss: 2.6961758211, pde B loss: 0.3748449534\n",
      "obs C loss: 2.1178252846, pde C loss: 0.3208078061\n",
      "obs D loss: 3469.7682723999, pde D loss: 10.6492525991\n",
      "obs E loss: 246.3803968430, pde E loss: 5.1855923058\n",
      "obs F loss: 100.0117998123, pde F loss: 0.7223880822\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.20s\n",
      "\n",
      "Start of epoch 25\n",
      "Training observations acc over epoch: 633.3864135742\n",
      "total loss: 3808.2254333496, total regularisd loss (sum of batches): 167557.8955078125\n",
      "obs A loss: 1.8268988989, pde A loss: 0.4261039152\n",
      "obs B loss: 2.6758110821, pde B loss: 0.3565192745\n",
      "obs C loss: 2.2154014744, pde C loss: 0.2565705266\n",
      "obs D loss: 3469.2008361816, pde D loss: 1.1405548033\n",
      "obs E loss: 233.8587241173, pde E loss: 5.0715774350\n",
      "obs F loss: 90.5405814648, pde F loss: 0.6558567731\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.83s\n",
      "\n",
      "Start of epoch 26\n",
      "Training observations acc over epoch: 635.9883422852\n",
      "total loss: 4065.0322036743, total regularisd loss (sum of batches): 178875.7358398438\n",
      "obs A loss: 1.7068146393, pde A loss: 4.3779046260\n",
      "obs B loss: 2.6967904158, pde B loss: 4.5825296507\n",
      "obs C loss: 2.1143629681, pde C loss: 0.4369808912\n",
      "obs D loss: 3470.8728256226, pde D loss: 101.3158964646\n",
      "obs E loss: 240.8964457512, pde E loss: 87.7471175796\n",
      "obs F loss: 97.6425451040, pde F loss: 50.6420111416\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.41s\n",
      "\n",
      "Start of epoch 27\n",
      "Training observations acc over epoch: 642.0781250000\n",
      "total loss: 3985.6045761108, total regularisd loss (sum of batches): 175358.9487304688\n",
      "obs A loss: 1.8679922260, pde A loss: 6.0268140025\n",
      "obs B loss: 2.6847905107, pde B loss: 4.1691608187\n",
      "obs C loss: 2.2371891551, pde C loss: 0.1963804502\n",
      "obs D loss: 3472.3262176514, pde D loss: 35.6772519499\n",
      "obs E loss: 240.1967744827, pde E loss: 29.4144964814\n",
      "obs F loss: 133.1555812359, pde F loss: 57.6518903954\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.56s\n",
      "\n",
      "Start of epoch 28\n",
      "Training observations acc over epoch: 633.7770385742\n",
      "total loss: 3830.3100051880, total regularisd loss (sum of batches): 168532.2219238281\n",
      "obs A loss: 2.0318012014, pde A loss: 1.3993409763\n",
      "obs B loss: 2.6743679456, pde B loss: 3.5994642340\n",
      "obs C loss: 2.1291675791, pde C loss: 0.0702747354\n",
      "obs D loss: 3470.6607666016, pde D loss: 5.9372377871\n",
      "obs E loss: 225.0829849243, pde E loss: 14.8242358905\n",
      "obs F loss: 100.0823400021, pde F loss: 1.8179621371\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.76s\n",
      "\n",
      "Start of epoch 29\n",
      "Training observations acc over epoch: 634.9281005859\n",
      "total loss: 3861.6510848999, total regularisd loss (sum of batches): 169911.9338378906\n",
      "obs A loss: 2.2423220575, pde A loss: 2.1856700904\n",
      "obs B loss: 2.6871789880, pde B loss: 3.3422603247\n",
      "obs C loss: 2.1029327214, pde C loss: 0.1753925856\n",
      "obs D loss: 3469.2170486450, pde D loss: 15.1879594245\n",
      "obs E loss: 223.3595628738, pde E loss: 25.1818910083\n",
      "obs F loss: 109.9596490860, pde F loss: 6.0092489193\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.72s\n",
      "\n",
      "Start of epoch 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 633.4503784180\n",
      "total loss: 3853.2257385254, total regularisd loss (sum of batches): 169538.0288085938\n",
      "obs A loss: 2.8563318085, pde A loss: 2.1863525917\n",
      "obs B loss: 2.6808093749, pde B loss: 6.2234320017\n",
      "obs C loss: 2.1185701862, pde C loss: 0.1808684627\n",
      "obs D loss: 3469.2932815552, pde D loss: 12.4946023275\n",
      "obs E loss: 213.6795978546, pde E loss: 24.9297635653\n",
      "obs F loss: 110.0737165213, pde F loss: 6.5083885393\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.46s\n",
      "\n",
      "Start of epoch 31\n",
      "Training observations acc over epoch: 631.3270874023\n",
      "total loss: 3877.1918182373, total regularisd loss (sum of batches): 170587.1203613281\n",
      "obs A loss: 2.2866909448, pde A loss: 6.8766830294\n",
      "obs B loss: 2.6917972527, pde B loss: 5.3098538838\n",
      "obs C loss: 2.1600286588, pde C loss: 0.1348349198\n",
      "obs D loss: 3469.3495788574, pde D loss: 51.4867988378\n",
      "obs E loss: 201.7494328022, pde E loss: 16.0105127739\n",
      "obs F loss: 109.7244868279, pde F loss: 9.4110913377\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.43s\n",
      "\n",
      "Start of epoch 32\n",
      "Training observations acc over epoch: 650.7285766602\n",
      "total loss: 8242.0543518066, total regularisd loss (sum of batches): 362421.1496582031\n",
      "obs A loss: 2.9578877008, pde A loss: 212.6476731100\n",
      "obs B loss: 7.4949590378, pde B loss: 144.0609377484\n",
      "obs C loss: 3.1547839120, pde C loss: 7.7009024897\n",
      "obs D loss: 3602.7905044556, pde D loss: 3480.3179703243\n",
      "obs E loss: 196.3727517128, pde E loss: 241.9312856952\n",
      "obs F loss: 91.6012305021, pde F loss: 251.0234503554\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.67s\n",
      "\n",
      "Start of epoch 33\n",
      "Training observations acc over epoch: 623.8831787109\n",
      "total loss: 3917.3648605347, total regularisd loss (sum of batches): 172358.0495605469\n",
      "obs A loss: 3.2037538737, pde A loss: 48.9746509194\n",
      "obs B loss: 8.8947969675, pde B loss: 35.4698066711\n",
      "obs C loss: 2.3300453685, pde C loss: 0.1503559767\n",
      "obs D loss: 3479.3532257080, pde D loss: 12.8631671225\n",
      "obs E loss: 189.2451889515, pde E loss: 28.3583664596\n",
      "obs F loss: 60.2724997997, pde F loss: 48.2489881516\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 34\n",
      "Training observations acc over epoch: 624.6244506836\n",
      "total loss: 3858.7589263916, total regularisd loss (sum of batches): 169783.3728027344\n",
      "obs A loss: 3.1025660783, pde A loss: 31.6804758906\n",
      "obs B loss: 9.1134338975, pde B loss: 35.9101262689\n",
      "obs C loss: 2.1386809610, pde C loss: 0.0629913520\n",
      "obs D loss: 3474.5657882690, pde D loss: 0.4202592671\n",
      "obs E loss: 205.0309467316, pde E loss: 12.8001656234\n",
      "obs F loss: 53.7948671579, pde F loss: 30.1386553645\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 35\n",
      "Training observations acc over epoch: 624.5834960938\n",
      "total loss: 3853.3727951050, total regularisd loss (sum of batches): 169544.7019042969\n",
      "obs A loss: 3.1281925738, pde A loss: 29.9486961365\n",
      "obs B loss: 9.0958288610, pde B loss: 35.7785977125\n",
      "obs C loss: 2.1452326514, pde C loss: 0.0544053472\n",
      "obs D loss: 3472.0795593262, pde D loss: 0.1701992073\n",
      "obs E loss: 207.8504247665, pde E loss: 11.5987736881\n",
      "obs F loss: 53.2010842562, pde F loss: 28.3217924237\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 36\n",
      "Training observations acc over epoch: 624.2839355469\n",
      "total loss: 3848.8043212891, total regularisd loss (sum of batches): 169344.1850585938\n",
      "obs A loss: 3.2254721671, pde A loss: 28.0412056446\n",
      "obs B loss: 9.1027442813, pde B loss: 35.8849534988\n",
      "obs C loss: 2.1527991891, pde C loss: 0.0486767737\n",
      "obs D loss: 3470.3346405029, pde D loss: 0.2286519788\n",
      "obs E loss: 207.8063011169, pde E loss: 11.7248963416\n",
      "obs F loss: 53.0811204910, pde F loss: 27.1728253365\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.76s\n",
      "\n",
      "Start of epoch 37\n",
      "Training observations acc over epoch: 623.7951660156\n",
      "total loss: 3844.8317947388, total regularisd loss (sum of batches): 169172.7814941406\n",
      "obs A loss: 3.2928520516, pde A loss: 26.9325997233\n",
      "obs B loss: 9.1052600443, pde B loss: 36.2429988980\n",
      "obs C loss: 2.1544114351, pde C loss: 0.0489651402\n",
      "obs D loss: 3468.1531143188, pde D loss: 0.1920774676\n",
      "obs E loss: 206.8611083031, pde E loss: 12.0524771065\n",
      "obs F loss: 53.2039153576, pde F loss: 26.5920161605\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 38\n",
      "Training observations acc over epoch: 623.1884155273\n",
      "total loss: 3840.3142166138, total regularisd loss (sum of batches): 168977.1906738281\n",
      "obs A loss: 3.3736652806, pde A loss: 25.9043160677\n",
      "obs B loss: 9.1111896634, pde B loss: 36.9172331691\n",
      "obs C loss: 2.1349080727, pde C loss: 0.0649911527\n",
      "obs D loss: 3465.2246475220, pde D loss: 0.1912429992\n",
      "obs E loss: 205.9235162735, pde E loss: 12.4463012218\n",
      "obs F loss: 53.3632128239, pde F loss: 25.6589956880\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 39\n",
      "Training observations acc over epoch: 622.6494140625\n",
      "total loss: 3835.8853988647, total regularisd loss (sum of batches): 168778.2441406250\n",
      "obs A loss: 3.4127516374, pde A loss: 25.0315969586\n",
      "obs B loss: 9.1346111447, pde B loss: 37.2886664271\n",
      "obs C loss: 2.1261597164, pde C loss: 0.0918888701\n",
      "obs D loss: 3462.6263427734, pde D loss: 0.3142141632\n",
      "obs E loss: 205.3596220016, pde E loss: 12.9881260693\n",
      "obs F loss: 53.2374163866, pde F loss: 24.2739857435\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 622.0767822266\n",
      "total loss: 3832.0242004395, total regularisd loss (sum of batches): 168611.6000976562\n",
      "obs A loss: 3.4345468581, pde A loss: 24.8401725888\n",
      "obs B loss: 9.1525178403, pde B loss: 37.2629528046\n",
      "obs C loss: 2.1338434033, pde C loss: 0.0779428205\n",
      "obs D loss: 3460.0109100342, pde D loss: 0.4109058753\n",
      "obs E loss: 204.1908745766, pde E loss: 13.2355683148\n",
      "obs F loss: 53.5379432440, pde F loss: 23.7359927297\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.84s\n",
      "\n",
      "Start of epoch 41\n",
      "Training observations acc over epoch: 621.5878906250\n",
      "total loss: 3827.5367889404, total regularisd loss (sum of batches): 168411.3173828125\n",
      "obs A loss: 3.4744657874, pde A loss: 24.3566288948\n",
      "obs B loss: 9.1989612281, pde B loss: 36.9938535690\n",
      "obs C loss: 2.1328220814, pde C loss: 0.0569685565\n",
      "obs D loss: 3457.6457138062, pde D loss: 0.5262133204\n",
      "obs E loss: 203.3250999451, pde E loss: 13.2747916877\n",
      "obs F loss: 53.7495799065, pde F loss: 22.8016622663\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 42\n",
      "Training observations acc over epoch: 620.5677490234\n",
      "total loss: 3821.3696136475, total regularisd loss (sum of batches): 168139.0007324219\n",
      "obs A loss: 3.4653102607, pde A loss: 24.6105035245\n",
      "obs B loss: 9.2084968388, pde B loss: 36.9774438739\n",
      "obs C loss: 2.1277652197, pde C loss: 0.0563175457\n",
      "obs D loss: 3452.3739852905, pde D loss: 0.6365747610\n",
      "obs E loss: 202.2673909664, pde E loss: 13.4345292449\n",
      "obs F loss: 53.9639303684, pde F loss: 22.2473491728\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 43\n",
      "Training observations acc over epoch: 619.3367309570\n",
      "total loss: 3812.0218658447, total regularisd loss (sum of batches): 167725.7944335938\n",
      "obs A loss: 3.4945030212, pde A loss: 23.9675658047\n",
      "obs B loss: 9.2971978486, pde B loss: 36.8409751654\n",
      "obs C loss: 2.1166052483, pde C loss: 0.0526623732\n",
      "obs D loss: 3445.2194137573, pde D loss: 1.1875639409\n",
      "obs E loss: 201.8066658974, pde E loss: 13.2212128043\n",
      "obs F loss: 54.0865944624, pde F loss: 20.7309150398\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 44\n",
      "Training observations acc over epoch: 618.2180175781\n",
      "total loss: 3817.0135192871, total regularisd loss (sum of batches): 167944.7470703125\n",
      "obs A loss: 3.5259291530, pde A loss: 23.0798918009\n",
      "obs B loss: 9.4054467678, pde B loss: 36.4037630558\n",
      "obs C loss: 2.1189887486, pde C loss: 0.0537093953\n",
      "obs D loss: 3439.2366333008, pde D loss: 15.1052301303\n",
      "obs E loss: 201.0450112820, pde E loss: 13.0079268962\n",
      "obs F loss: 53.9766718149, pde F loss: 20.0543217063\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 45\n",
      "Training observations acc over epoch: 616.2059326172\n",
      "total loss: 3789.0577468872, total regularisd loss (sum of batches): 166716.9672851562\n",
      "obs A loss: 3.5309697315, pde A loss: 22.5750324130\n",
      "obs B loss: 9.4993543774, pde B loss: 36.3376926184\n",
      "obs C loss: 2.0978424549, pde C loss: 0.0494491043\n",
      "obs D loss: 3427.9414596558, pde D loss: 1.6733499896\n",
      "obs E loss: 200.2680940628, pde E loss: 13.2375836670\n",
      "obs F loss: 53.8971885443, pde F loss: 17.9496828020\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.77s\n",
      "\n",
      "Start of epoch 46\n",
      "Training observations acc over epoch: 613.2837524414\n",
      "total loss: 3769.6513595581, total regularisd loss (sum of batches): 165867.9306640625\n",
      "obs A loss: 3.4786580428, pde A loss: 22.7751409113\n",
      "obs B loss: 9.7085096091, pde B loss: 36.3361733556\n",
      "obs C loss: 2.0955701694, pde C loss: 0.0393791184\n",
      "obs D loss: 3412.4206619263, pde D loss: 1.2365537696\n",
      "obs E loss: 198.3978552818, pde E loss: 13.5758572519\n",
      "obs F loss: 53.6015889645, pde F loss: 15.9854377508\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.92s\n",
      "\n",
      "Start of epoch 47\n",
      "Training observations acc over epoch: 610.2955322266\n",
      "total loss: 3746.0892639160, total regularisd loss (sum of batches): 164823.2834472656\n",
      "obs A loss: 3.4720971137, pde A loss: 22.0403348207\n",
      "obs B loss: 9.9921422750, pde B loss: 35.0991877317\n",
      "obs C loss: 2.0793525204, pde C loss: 0.0447634867\n",
      "obs D loss: 3396.5533905029, pde D loss: 1.7833729945\n",
      "obs E loss: 196.4573173523, pde E loss: 12.5192390531\n",
      "obs F loss: 53.2190414667, pde F loss: 12.8290153295\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 48\n",
      "Training observations acc over epoch: 607.3854370117\n",
      "total loss: 3729.1817703247, total regularisd loss (sum of batches): 164079.5207519531\n",
      "obs A loss: 3.5349048302, pde A loss: 21.8495785445\n",
      "obs B loss: 10.3191490322, pde B loss: 33.9921447933\n",
      "obs C loss: 2.0823891051, pde C loss: 0.0874509524\n",
      "obs D loss: 3380.3731536865, pde D loss: 6.8901088238\n",
      "obs E loss: 194.4791147709, pde E loss: 11.4494049400\n",
      "obs F loss: 53.5237599611, pde F loss: 10.6006446183\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 49\n",
      "Training observations acc over epoch: 604.4080200195\n",
      "total loss: 3706.8493499756, total regularisd loss (sum of batches): 163105.4443359375\n",
      "obs A loss: 3.6795100197, pde A loss: 22.2534388155\n",
      "obs B loss: 10.6189573109, pde B loss: 31.1353470981\n",
      "obs C loss: 2.0787551142, pde C loss: 0.0737118286\n",
      "obs D loss: 3363.4214096069, pde D loss: 8.3743974380\n",
      "obs E loss: 193.4659037590, pde E loss: 9.8607471809\n",
      "obs F loss: 53.1828058958, pde F loss: 8.7043411583\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.90s\n",
      "\n",
      "Start of epoch 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 601.1765747070\n",
      "total loss: 3683.4534149170, total regularisd loss (sum of batches): 162068.3398437500\n",
      "obs A loss: 3.7487487905, pde A loss: 19.7934915870\n",
      "obs B loss: 10.8337877840, pde B loss: 28.3120912015\n",
      "obs C loss: 2.0810726564, pde C loss: 0.1108901267\n",
      "obs D loss: 3346.6846618652, pde D loss: 13.7915909067\n",
      "obs E loss: 190.6766581535, pde E loss: 8.5398667604\n",
      "obs F loss: 53.0343676805, pde F loss: 5.8461943269\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.93s\n",
      "\n",
      "Start of epoch 51\n",
      "Training observations acc over epoch: 597.5546875000\n",
      "total loss: 3654.6847686768, total regularisd loss (sum of batches): 160807.7480468750\n",
      "obs A loss: 3.7972705811, pde A loss: 18.0509836972\n",
      "obs B loss: 11.0204835981, pde B loss: 24.6794096828\n",
      "obs C loss: 2.0674684569, pde C loss: 0.1500821455\n",
      "obs D loss: 3328.5540618896, pde D loss: 17.0220174342\n",
      "obs E loss: 188.0101463795, pde E loss: 5.3229553290\n",
      "obs F loss: 51.8791445494, pde F loss: 4.1307567842\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.93s\n",
      "\n",
      "Start of epoch 52\n",
      "Training observations acc over epoch: 594.4342041016\n",
      "total loss: 3637.0932769775, total regularisd loss (sum of batches): 160035.7780761719\n",
      "obs A loss: 3.7729872838, pde A loss: 18.1175468564\n",
      "obs B loss: 11.1590160578, pde B loss: 23.2203018665\n",
      "obs C loss: 2.0650993511, pde C loss: 0.1189866479\n",
      "obs D loss: 3311.8326797485, pde D loss: 17.1570711620\n",
      "obs E loss: 186.9493572712, pde E loss: 6.5166048147\n",
      "obs F loss: 50.8256690502, pde F loss: 5.3579188883\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.65s\n",
      "\n",
      "Start of epoch 53\n",
      "Training observations acc over epoch: 592.7327270508\n",
      "total loss: 3651.0732879639, total regularisd loss (sum of batches): 160648.0810546875\n",
      "obs A loss: 3.6478082947, pde A loss: 23.1313049197\n",
      "obs B loss: 11.4402812570, pde B loss: 26.4756996632\n",
      "obs C loss: 2.0789482053, pde C loss: 0.1444000379\n",
      "obs D loss: 3300.7014923096, pde D loss: 19.7948952168\n",
      "obs E loss: 186.3453783989, pde E loss: 12.3695334718\n",
      "obs F loss: 52.1822865009, pde F loss: 12.7612620741\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.01s\n",
      "\n",
      "Start of epoch 54\n",
      "Training observations acc over epoch: 590.2616577148\n",
      "total loss: 3626.0554122925, total regularisd loss (sum of batches): 159540.1997070312\n",
      "obs A loss: 3.5440441221, pde A loss: 20.6612452865\n",
      "obs B loss: 11.6250841767, pde B loss: 29.8464299440\n",
      "obs C loss: 2.0804019682, pde C loss: 0.0868685838\n",
      "obs D loss: 3283.0790252686, pde D loss: 4.8179652132\n",
      "obs E loss: 191.6603486538, pde E loss: 13.9082487524\n",
      "obs F loss: 49.5807325840, pde F loss: 15.1650167704\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.28s\n",
      "\n",
      "Start of epoch 55\n",
      "Training observations acc over epoch: 586.1934814453\n",
      "total loss: 3596.1969375610, total regularisd loss (sum of batches): 158237.6196289062\n",
      "obs A loss: 3.6189205684, pde A loss: 19.6304178536\n",
      "obs B loss: 11.4944885671, pde B loss: 28.1902170777\n",
      "obs C loss: 2.0685450323, pde C loss: 0.0720123444\n",
      "obs D loss: 3260.0744476318, pde D loss: 9.8218640722\n",
      "obs E loss: 191.8245384693, pde E loss: 10.7894514501\n",
      "obs F loss: 48.0804483891, pde F loss: 10.5316316932\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.10s\n",
      "\n",
      "Start of epoch 56\n",
      "Training observations acc over epoch: 584.7526855469\n",
      "total loss: 3608.3256378174, total regularisd loss (sum of batches): 158760.9819335938\n",
      "obs A loss: 3.6146527492, pde A loss: 22.6131887436\n",
      "obs B loss: 11.6207045019, pde B loss: 30.4361869991\n",
      "obs C loss: 2.0766342916, pde C loss: 0.1334653693\n",
      "obs D loss: 3249.4360351562, pde D loss: 19.4932427406\n",
      "obs E loss: 191.7585484982, pde E loss: 12.3512096405\n",
      "obs F loss: 50.0090462565, pde F loss: 14.7827025205\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.71s\n",
      "\n",
      "Start of epoch 57\n",
      "Training observations acc over epoch: 580.8778076172\n",
      "total loss: 3595.0550155640, total regularisd loss (sum of batches): 158180.2360839844\n",
      "obs A loss: 3.5252179205, pde A loss: 27.5594303012\n",
      "obs B loss: 11.6302817911, pde B loss: 31.4106932580\n",
      "obs C loss: 2.0913027972, pde C loss: 0.1685713138\n",
      "obs D loss: 3226.7986373901, pde D loss: 18.6632436216\n",
      "obs E loss: 190.4937667847, pde E loss: 13.7905368060\n",
      "obs F loss: 50.7278146744, pde F loss: 18.1955501735\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.96s\n",
      "\n",
      "Start of epoch 58\n",
      "Training observations acc over epoch: 566.4064941406\n",
      "total loss: 3558.9096755981, total regularisd loss (sum of batches): 156584.9965820312\n",
      "obs A loss: 3.4260324910, pde A loss: 29.4864613712\n",
      "obs B loss: 11.4647540748, pde B loss: 34.6092078090\n",
      "obs C loss: 2.1356624067, pde C loss: 0.2205135378\n",
      "obs D loss: 3138.4214553833, pde D loss: 65.1863741726\n",
      "obs E loss: 193.0452799797, pde E loss: 14.0131436288\n",
      "obs F loss: 49.9461520910, pde F loss: 16.9546792954\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.88s\n",
      "\n",
      "Start of epoch 59\n",
      "Training observations acc over epoch: 536.7767333984\n",
      "total loss: 3345.6396713257, total regularisd loss (sum of batches): 147206.5788574219\n",
      "obs A loss: 3.5111646950, pde A loss: 30.6064519584\n",
      "obs B loss: 11.1906964183, pde B loss: 32.3195154667\n",
      "obs C loss: 2.1413111798, pde C loss: 0.2008157738\n",
      "obs D loss: 2966.2495651245, pde D loss: 33.7782007307\n",
      "obs E loss: 188.5885190964, pde E loss: 14.6903441101\n",
      "obs F loss: 48.9793095589, pde F loss: 13.3837583959\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.25s\n",
      "\n",
      "Start of epoch 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 494.0459899902\n",
      "total loss: 3135.3179855347, total regularisd loss (sum of batches): 137946.2487792969\n",
      "obs A loss: 3.5292942449, pde A loss: 39.7652199864\n",
      "obs B loss: 11.0368944257, pde B loss: 33.0595058799\n",
      "obs C loss: 2.2296612635, pde C loss: 0.2458584027\n",
      "obs D loss: 2713.5060195923, pde D loss: 61.5873399973\n",
      "obs E loss: 184.8266029358, pde E loss: 20.0187915266\n",
      "obs F loss: 49.1477098465, pde F loss: 16.3650676608\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.06s\n",
      "\n",
      "Start of epoch 61\n",
      "Training observations acc over epoch: 438.1401672363\n",
      "total loss: 2836.1522026062, total regularisd loss (sum of batches): 124778.1816406250\n",
      "obs A loss: 3.6704062149, pde A loss: 51.4429830909\n",
      "obs B loss: 10.7101373821, pde B loss: 38.6446626186\n",
      "obs C loss: 2.3295978345, pde C loss: 0.3774164198\n",
      "obs D loss: 2381.4591674805, pde D loss: 81.0233966708\n",
      "obs E loss: 180.8702924252, pde E loss: 18.3545830250\n",
      "obs F loss: 49.8015084267, pde F loss: 17.4680712819\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.10s\n",
      "\n",
      "Start of epoch 62\n",
      "Training observations acc over epoch: 386.6804809570\n",
      "total loss: 2546.2976913452, total regularisd loss (sum of batches): 112028.6091308594\n",
      "obs A loss: 3.7709101699, pde A loss: 70.4535053968\n",
      "obs B loss: 10.4608075172, pde B loss: 44.6314636469\n",
      "obs C loss: 2.4203717448, pde C loss: 0.5630305405\n",
      "obs D loss: 2075.9707565308, pde D loss: 72.5823360682\n",
      "obs E loss: 176.8469254971, pde E loss: 19.5250537395\n",
      "obs F loss: 50.6131345034, pde F loss: 18.4593906105\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.05s\n",
      "\n",
      "Start of epoch 63\n",
      "Training observations acc over epoch: 338.7027893066\n",
      "total loss: 2281.6504707336, total regularisd loss (sum of batches): 100378.7106933594\n",
      "obs A loss: 3.7064991817, pde A loss: 85.2806193829\n",
      "obs B loss: 11.0019222796, pde B loss: 51.7279744744\n",
      "obs C loss: 2.6210613512, pde C loss: 0.6919087144\n",
      "obs D loss: 1789.9991798401, pde D loss: 72.1598431170\n",
      "obs E loss: 173.7851498127, pde E loss: 19.5809675753\n",
      "obs F loss: 51.1032270193, pde F loss: 19.9921030700\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.86s\n",
      "\n",
      "Start of epoch 64\n",
      "Training observations acc over epoch: 293.0103454590\n",
      "total loss: 2022.5037078857, total regularisd loss (sum of batches): 88980.9716796875\n",
      "obs A loss: 3.7480411306, pde A loss: 106.2064177990\n",
      "obs B loss: 11.6228825301, pde B loss: 58.5514061451\n",
      "obs C loss: 2.7776044384, pde C loss: 0.8655470386\n",
      "obs D loss: 1520.7462539673, pde D loss: 59.1363940537\n",
      "obs E loss: 167.6594920158, pde E loss: 20.2110275924\n",
      "obs F loss: 51.5076266527, pde F loss: 19.4710043371\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.83s\n",
      "\n",
      "Start of epoch 65\n",
      "Training observations acc over epoch: 271.0323791504\n",
      "total loss: 1872.5978889465, total regularisd loss (sum of batches): 82394.2165527344\n",
      "obs A loss: 3.8995398432, pde A loss: 108.8668421507\n",
      "obs B loss: 12.1062003672, pde B loss: 61.7427413464\n",
      "obs C loss: 2.8107940890, pde C loss: 0.8860284518\n",
      "obs D loss: 1391.3521308899, pde D loss: 37.8532688320\n",
      "obs E loss: 164.0912778378, pde E loss: 18.6901509762\n",
      "obs F loss: 51.9343684912, pde F loss: 18.3645360470\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.21s\n",
      "\n",
      "Start of epoch 66\n",
      "Training observations acc over epoch: 262.1752929688\n",
      "total loss: 1845.5005455017, total regularisd loss (sum of batches): 81195.6320800781\n",
      "obs A loss: 4.1508657672, pde A loss: 117.0978865623\n",
      "obs B loss: 12.4415764362, pde B loss: 66.5108692646\n",
      "obs C loss: 2.7682114542, pde C loss: 1.0128712654\n",
      "obs D loss: 1340.2414588928, pde D loss: 50.9852294326\n",
      "obs E loss: 161.9114613533, pde E loss: 19.1188724637\n",
      "obs F loss: 51.5381151438, pde F loss: 17.7231350541\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.33s\n",
      "\n",
      "Start of epoch 67\n",
      "Training observations acc over epoch: 260.3015136719\n",
      "total loss: 1855.0320320129, total regularisd loss (sum of batches): 81624.8525390625\n",
      "obs A loss: 4.0763098374, pde A loss: 117.9984365702\n",
      "obs B loss: 12.5104981363, pde B loss: 69.8465229273\n",
      "obs C loss: 2.7711641155, pde C loss: 1.0310651381\n",
      "obs D loss: 1328.9451255798, pde D loss: 70.9372622073\n",
      "obs E loss: 162.7069935799, pde E loss: 17.1786143482\n",
      "obs F loss: 50.7989697456, pde F loss: 16.2310584784\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.43s\n",
      "\n",
      "Start of epoch 68\n",
      "Training observations acc over epoch: 251.0941925049\n",
      "total loss: 1761.3180809021, total regularisd loss (sum of batches): 77487.1849365234\n",
      "obs A loss: 4.1740204841, pde A loss: 115.6277004480\n",
      "obs B loss: 12.5427005291, pde B loss: 71.0031555891\n",
      "obs C loss: 2.6411010325, pde C loss: 1.1002308168\n",
      "obs D loss: 1275.6958198547, pde D loss: 36.7963377237\n",
      "obs E loss: 162.1819870472, pde E loss: 16.0453685373\n",
      "obs F loss: 49.3295829296, pde F loss: 14.1800940484\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.61s\n",
      "\n",
      "Start of epoch 69\n",
      "Training observations acc over epoch: 243.0502929688\n",
      "total loss: 1721.6133880615, total regularisd loss (sum of batches): 75764.5820312500\n",
      "obs A loss: 4.2583339065, pde A loss: 120.3367136717\n",
      "obs B loss: 12.6595727056, pde B loss: 75.5297174454\n",
      "obs C loss: 2.6306584775, pde C loss: 1.3425895330\n",
      "obs D loss: 1231.2414398193, pde D loss: 35.2325752974\n",
      "obs E loss: 158.7264521122, pde E loss: 16.9723175615\n",
      "obs F loss: 48.7853385806, pde F loss: 13.8976625204\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.33s\n",
      "\n",
      "Start of epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 244.2928161621\n",
      "total loss: 1727.6321830750, total regularisd loss (sum of batches): 76022.7120361328\n",
      "obs A loss: 4.2152852379, pde A loss: 112.2764179707\n",
      "obs B loss: 12.6138108373, pde B loss: 73.6099110246\n",
      "obs C loss: 2.6168195046, pde C loss: 1.4065366480\n",
      "obs D loss: 1235.3006973267, pde D loss: 44.4821424186\n",
      "obs E loss: 163.2133505344, pde E loss: 15.4090081602\n",
      "obs F loss: 47.7972649336, pde F loss: 14.6909370422\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.10s\n",
      "\n",
      "Start of epoch 71\n",
      "Training observations acc over epoch: 243.0135345459\n",
      "total loss: 1707.2816123962, total regularisd loss (sum of batches): 75115.2344970703\n",
      "obs A loss: 4.3527790867, pde A loss: 100.0191078782\n",
      "obs B loss: 12.6487655789, pde B loss: 69.2373573780\n",
      "obs C loss: 2.5894354992, pde C loss: 1.1018749839\n",
      "obs D loss: 1232.3288841248, pde D loss: 52.2511279285\n",
      "obs E loss: 158.8853535652, pde E loss: 13.8035671562\n",
      "obs F loss: 47.2760417461, pde F loss: 12.7873048633\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.21s\n",
      "\n",
      "Start of epoch 72\n",
      "Training observations acc over epoch: 233.9989929199\n",
      "total loss: 1638.5988769531, total regularisd loss (sum of batches): 72088.3565673828\n",
      "obs A loss: 4.2850883994, pde A loss: 101.5315133333\n",
      "obs B loss: 12.6697096527, pde B loss: 72.1035003066\n",
      "obs C loss: 2.6582097225, pde C loss: 1.0674383147\n",
      "obs D loss: 1177.7833023071, pde D loss: 31.8943855762\n",
      "obs E loss: 160.4247305393, pde E loss: 15.4121994525\n",
      "obs F loss: 46.1729593873, pde F loss: 12.5958457440\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.44s\n",
      "\n",
      "Start of epoch 73\n",
      "Training observations acc over epoch: 233.5095825195\n",
      "total loss: 1646.9270286560, total regularisd loss (sum of batches): 72464.5541992188\n",
      "obs A loss: 4.7244603168, pde A loss: 92.3516795039\n",
      "obs B loss: 12.5546012968, pde B loss: 64.9147776365\n",
      "obs C loss: 2.4431250021, pde C loss: 1.0543978419\n",
      "obs D loss: 1185.0369319916, pde D loss: 61.1769255698\n",
      "obs E loss: 150.4481821060, pde E loss: 15.9004743099\n",
      "obs F loss: 45.8500220180, pde F loss: 10.4714514911\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.30s\n",
      "\n",
      "Start of epoch 74\n",
      "Training observations acc over epoch: 226.1212005615\n",
      "total loss: 1609.0928344727, total regularisd loss (sum of batches): 70813.5120849609\n",
      "obs A loss: 4.5646675900, pde A loss: 110.5866956711\n",
      "obs B loss: 12.5701808035, pde B loss: 67.4021912813\n",
      "obs C loss: 2.4118046165, pde C loss: 1.4133409364\n",
      "obs D loss: 1146.9484386444, pde D loss: 44.1519003659\n",
      "obs E loss: 145.4661500454, pde E loss: 18.2953404039\n",
      "obs F loss: 44.7660736442, pde F loss: 10.5160363987\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.79s\n",
      "\n",
      "Start of epoch 75\n",
      "Training observations acc over epoch: 242.5254821777\n",
      "total loss: 1732.8828735352, total regularisd loss (sum of batches): 76241.6297607422\n",
      "obs A loss: 3.7787956633, pde A loss: 119.5517899990\n",
      "obs B loss: 13.1262471080, pde B loss: 69.9957245588\n",
      "obs C loss: 2.8751857355, pde C loss: 1.1389234588\n",
      "obs D loss: 1229.7983818054, pde D loss: 38.7226351202\n",
      "obs E loss: 156.7229206562, pde E loss: 26.3879923820\n",
      "obs F loss: 48.8516505957, pde F loss: 21.9326392412\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.94s\n",
      "\n",
      "Start of epoch 76\n",
      "Training observations acc over epoch: 229.1743774414\n",
      "total loss: 1579.6778373718, total regularisd loss (sum of batches): 69506.9218750000\n",
      "obs A loss: 4.4569128118, pde A loss: 84.4643503428\n",
      "obs B loss: 12.7101391554, pde B loss: 57.1225161552\n",
      "obs C loss: 2.2751651928, pde C loss: 0.9622429628\n",
      "obs D loss: 1163.6054553986, pde D loss: 39.4234945178\n",
      "obs E loss: 146.5061087608, pde E loss: 15.0641137660\n",
      "obs F loss: 45.4920766354, pde F loss: 7.5952362791\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.67s\n",
      "\n",
      "Start of epoch 77\n",
      "Training observations acc over epoch: 225.9938201904\n",
      "total loss: 1599.2917003632, total regularisd loss (sum of batches): 70370.0769042969\n",
      "obs A loss: 4.8444062844, pde A loss: 80.4527969956\n",
      "obs B loss: 12.5572811067, pde B loss: 52.4875497222\n",
      "obs C loss: 2.3480237834, pde C loss: 1.3197915172\n",
      "obs D loss: 1151.2557659149, pde D loss: 86.5907313973\n",
      "obs E loss: 138.9828007221, pde E loss: 15.8740497380\n",
      "obs F loss: 45.9747289419, pde F loss: 6.6037686393\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.51s\n",
      "\n",
      "Start of epoch 78\n",
      "Training observations acc over epoch: 223.5532836914\n",
      "total loss: 1542.4085025787, total regularisd loss (sum of batches): 67860.7740478516\n",
      "obs A loss: 4.9281824231, pde A loss: 77.9513702989\n",
      "obs B loss: 12.4031601548, pde B loss: 53.0897979736\n",
      "obs C loss: 2.3358355202, pde C loss: 1.3950246777\n",
      "obs D loss: 1135.8396739960, pde D loss: 50.0778649598\n",
      "obs E loss: 139.6083245277, pde E loss: 12.8792633489\n",
      "obs F loss: 46.2045421004, pde F loss: 5.6954679154\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.90s\n",
      "\n",
      "Start of epoch 79\n",
      "Training observations acc over epoch: 236.7381134033\n",
      "total loss: 1746.9194278717, total regularisd loss (sum of batches): 76872.3519287109\n",
      "obs A loss: 4.2064264286, pde A loss: 132.8964527249\n",
      "obs B loss: 12.7216453552, pde B loss: 94.5827383399\n",
      "obs C loss: 2.7194313034, pde C loss: 1.5863475185\n",
      "obs D loss: 1194.6204261780, pde D loss: 54.0722177327\n",
      "obs E loss: 158.0117361546, pde E loss: 21.7810877264\n",
      "obs F loss: 48.1490750313, pde F loss: 21.5718533024\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.01s\n",
      "\n",
      "Start of epoch 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 248.2764892578\n",
      "total loss: 1759.8759422302, total regularisd loss (sum of batches): 77428.6905517578\n",
      "obs A loss: 3.4020778164, pde A loss: 123.9641950130\n",
      "obs B loss: 12.5964190662, pde B loss: 72.7968094349\n",
      "obs C loss: 3.2307459339, pde C loss: 0.8441131013\n",
      "obs D loss: 1239.8146953583, pde D loss: 32.6207558811\n",
      "obs E loss: 181.5707590580, pde E loss: 14.9237542748\n",
      "obs F loss: 49.0444320440, pde F loss: 25.0671658516\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.50s\n",
      "\n",
      "Start of epoch 81\n",
      "Training observations acc over epoch: 230.3729705811\n",
      "total loss: 1556.7029705048, total regularisd loss (sum of batches): 68494.6018066406\n",
      "obs A loss: 4.2484540679, pde A loss: 82.4198513031\n",
      "obs B loss: 12.1931602657, pde B loss: 51.6023733020\n",
      "obs C loss: 2.4511453509, pde C loss: 0.6971413065\n",
      "obs D loss: 1158.7566547394, pde D loss: 26.0987794399\n",
      "obs E loss: 158.8898968697, pde E loss: 7.7500337809\n",
      "obs F loss: 45.6986930966, pde F loss: 5.8967953436\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.33s\n",
      "\n",
      "Start of epoch 82\n",
      "Training observations acc over epoch: 226.1405792236\n",
      "total loss: 1561.0935306549, total regularisd loss (sum of batches): 68683.3612060547\n",
      "obs A loss: 4.7563914321, pde A loss: 81.9180912971\n",
      "obs B loss: 11.8273865730, pde B loss: 41.4446005523\n",
      "obs C loss: 2.2577206232, pde C loss: 1.1167402919\n",
      "obs D loss: 1150.2074241638, pde D loss: 63.0846921504\n",
      "obs E loss: 142.7964322567, pde E loss: 12.4503636807\n",
      "obs F loss: 44.9979755282, pde F loss: 4.2357196845\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.86s\n",
      "\n",
      "Start of epoch 83\n",
      "Training observations acc over epoch: 231.2162628174\n",
      "total loss: 1605.1136665344, total regularisd loss (sum of batches): 70619.8266601562\n",
      "obs A loss: 4.8882614709, pde A loss: 88.9500913620\n",
      "obs B loss: 11.9402574450, pde B loss: 45.9956654310\n",
      "obs C loss: 2.1687237620, pde C loss: 1.2044368926\n",
      "obs D loss: 1180.8059024811, pde D loss: 62.3491239250\n",
      "obs E loss: 141.5534443855, pde E loss: 13.5577273369\n",
      "obs F loss: 45.9410086870, pde F loss: 5.7590234578\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 68.71s\n",
      "\n",
      "Start of epoch 84\n",
      "Training observations acc over epoch: 233.4611511230\n",
      "total loss: 1664.2412109375, total regularisd loss (sum of batches): 73229.0113525391\n",
      "obs A loss: 4.5356549397, pde A loss: 113.8964568973\n",
      "obs B loss: 12.1379486173, pde B loss: 52.4229556024\n",
      "obs C loss: 2.4004182518, pde C loss: 1.4855721695\n",
      "obs D loss: 1193.5159893036, pde D loss: 63.1362803280\n",
      "obs E loss: 141.2818524837, pde E loss: 18.0406176448\n",
      "obs F loss: 46.8950186372, pde F loss: 14.4924417175\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.52s\n",
      "\n",
      "Start of epoch 85\n",
      "Training observations acc over epoch: 224.1282043457\n",
      "total loss: 1523.3922195435, total regularisd loss (sum of batches): 67041.7357177734\n",
      "obs A loss: 4.8132044412, pde A loss: 79.2219967246\n",
      "obs B loss: 12.1066349149, pde B loss: 37.2996931374\n",
      "obs C loss: 2.2446089312, pde C loss: 1.1118506221\n",
      "obs D loss: 1139.5290641785, pde D loss: 42.8508943021\n",
      "obs E loss: 140.1319677830, pde E loss: 12.7073763162\n",
      "obs F loss: 45.9437024593, pde F loss: 5.4312309753\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.80s\n",
      "\n",
      "Start of epoch 86\n",
      "Training observations acc over epoch: 220.8939514160\n",
      "total loss: 1494.9598293304, total regularisd loss (sum of batches): 65789.3771972656\n",
      "obs A loss: 4.9629383236, pde A loss: 66.3839318156\n",
      "obs B loss: 11.9424819350, pde B loss: 27.2888915837\n",
      "obs C loss: 2.4090354182, pde C loss: 2.0650602123\n",
      "obs D loss: 1124.7647647858, pde D loss: 56.1543151438\n",
      "obs E loss: 134.9814879894, pde E loss: 12.5773575902\n",
      "obs F loss: 46.3031355739, pde F loss: 5.1264167242\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.85s\n",
      "\n",
      "Start of epoch 87\n",
      "Training observations acc over epoch: 221.5925750732\n",
      "total loss: 1526.7649574280, total regularisd loss (sum of batches): 67180.8691406250\n",
      "obs A loss: 4.7275062166, pde A loss: 75.2271775603\n",
      "obs B loss: 11.9562964290, pde B loss: 33.5631940663\n",
      "obs C loss: 2.4709864408, pde C loss: 1.4565961650\n",
      "obs D loss: 1126.0511970520, pde D loss: 64.7094672322\n",
      "obs E loss: 133.8226025105, pde E loss: 14.9217774346\n",
      "obs F loss: 50.5267814994, pde F loss: 7.3313701972\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.38s\n",
      "\n",
      "Start of epoch 88\n",
      "Training observations acc over epoch: 214.4089355469\n",
      "total loss: 1445.9080677032, total regularisd loss (sum of batches): 63617.5039062500\n",
      "obs A loss: 5.0560744479, pde A loss: 60.8174965978\n",
      "obs B loss: 11.8732223511, pde B loss: 25.6650114059\n",
      "obs C loss: 2.0626118742, pde C loss: 1.0714709442\n",
      "obs D loss: 1090.8576984406, pde D loss: 57.2985863388\n",
      "obs E loss: 129.3592419624, pde E loss: 10.5580156595\n",
      "obs F loss: 47.2448461056, pde F loss: 4.0437858403\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.24s\n",
      "\n",
      "Start of epoch 89\n",
      "Training observations acc over epoch: 206.1196594238\n",
      "total loss: 1386.3981342316, total regularisd loss (sum of batches): 61003.5556640625\n",
      "obs A loss: 5.4545056894, pde A loss: 65.2932453752\n",
      "obs B loss: 11.8636300564, pde B loss: 24.8628011346\n",
      "obs C loss: 2.0874846987, pde C loss: 1.4194416776\n",
      "obs D loss: 1051.2990207672, pde D loss: 39.2898827195\n",
      "obs E loss: 124.7895767689, pde E loss: 15.3014877141\n",
      "obs F loss: 41.2238481641, pde F loss: 3.5131999664\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.62s\n",
      "\n",
      "Start of epoch 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 209.5583953857\n",
      "total loss: 1413.4739398956, total regularisd loss (sum of batches): 62190.3289794922\n",
      "obs A loss: 5.2280475758, pde A loss: 62.0003964901\n",
      "obs B loss: 12.0952921808, pde B loss: 24.7033845782\n",
      "obs C loss: 2.1101588998, pde C loss: 1.4721637368\n",
      "obs D loss: 1071.3824405670, pde D loss: 49.5418102741\n",
      "obs E loss: 122.7678270340, pde E loss: 14.0821017027\n",
      "obs F loss: 43.7665866017, pde F loss: 4.3237289265\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.68s\n",
      "\n",
      "Start of epoch 91\n",
      "Training observations acc over epoch: 214.5519104004\n",
      "total loss: 1447.5563621521, total regularisd loss (sum of batches): 63697.6517333984\n",
      "obs A loss: 5.1906129457, pde A loss: 63.6530179381\n",
      "obs B loss: 11.9437413365, pde B loss: 22.4478121400\n",
      "obs C loss: 2.1664122008, pde C loss: 1.3726210278\n",
      "obs D loss: 1098.9698162079, pde D loss: 51.8472315669\n",
      "obs E loss: 122.8854742050, pde E loss: 14.9437016025\n",
      "obs F loss: 46.1553981900, pde F loss: 5.9805397652\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.41s\n",
      "\n",
      "Start of epoch 92\n",
      "Training observations acc over epoch: 222.0337982178\n",
      "total loss: 1537.2620010376, total regularisd loss (sum of batches): 67636.4986572266\n",
      "obs A loss: 5.0007786416, pde A loss: 88.6800153255\n",
      "obs B loss: 12.2625742555, pde B loss: 30.7439970225\n",
      "obs C loss: 2.2754835188, pde C loss: 1.4481200781\n",
      "obs D loss: 1135.3384628296, pde D loss: 57.3027633429\n",
      "obs E loss: 129.8190073967, pde E loss: 17.6089885384\n",
      "obs F loss: 47.5063049793, pde F loss: 9.2755150422\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.76s\n",
      "\n",
      "Start of epoch 93\n",
      "Training observations acc over epoch: 223.4121551514\n",
      "total loss: 1519.9614200592, total regularisd loss (sum of batches): 66875.6549072266\n",
      "obs A loss: 5.0863016360, pde A loss: 82.2158251107\n",
      "obs B loss: 12.0613729805, pde B loss: 28.5139542669\n",
      "obs C loss: 2.3538408950, pde C loss: 1.5466374783\n",
      "obs D loss: 1143.7136268616, pde D loss: 39.4375145584\n",
      "obs E loss: 130.3247606754, pde E loss: 17.8042939603\n",
      "obs F loss: 46.9331152439, pde F loss: 9.9701676220\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.71s\n",
      "\n",
      "Start of epoch 94\n",
      "Training observations acc over epoch: 229.5406188965\n",
      "total loss: 1569.3159637451, total regularisd loss (sum of batches): 69047.2926025391\n",
      "obs A loss: 4.1982409041, pde A loss: 90.9489370584\n",
      "obs B loss: 11.9557285160, pde B loss: 24.0187225416\n",
      "obs C loss: 2.5993666463, pde C loss: 1.9388106233\n",
      "obs D loss: 1170.2990856171, pde D loss: 47.0186686516\n",
      "obs E loss: 138.8394112587, pde E loss: 17.7135669440\n",
      "obs F loss: 49.3518257737, pde F loss: 10.4335786179\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.87s\n",
      "\n",
      "Start of epoch 95\n",
      "Training observations acc over epoch: 217.9915924072\n",
      "total loss: 1519.3045787811, total regularisd loss (sum of batches): 66840.7618408203\n",
      "obs A loss: 4.9727820456, pde A loss: 66.2536820173\n",
      "obs B loss: 12.0794072002, pde B loss: 31.2762205899\n",
      "obs C loss: 2.4181240276, pde C loss: 1.6271232041\n",
      "obs D loss: 1114.0075759888, pde D loss: 84.8778168857\n",
      "obs E loss: 128.1594698429, pde E loss: 18.6025301963\n",
      "obs F loss: 46.3121398687, pde F loss: 8.7176965401\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.76s\n",
      "\n",
      "Start of epoch 96\n",
      "Training observations acc over epoch: 231.2744445801\n",
      "total loss: 1606.1619815826, total regularisd loss (sum of batches): 70657.5471191406\n",
      "obs A loss: 4.3885629252, pde A loss: 102.3718355298\n",
      "obs B loss: 12.2554865777, pde B loss: 39.3501211703\n",
      "obs C loss: 2.8997015469, pde C loss: 1.7156895706\n",
      "obs D loss: 1181.3377628326, pde D loss: 30.6258272529\n",
      "obs E loss: 136.1436660290, pde E loss: 25.6851008236\n",
      "obs F loss: 50.6215204000, pde F loss: 18.7667003870\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.13s\n",
      "\n",
      "Start of epoch 97\n",
      "Training observations acc over epoch: 219.7319335938\n",
      "total loss: 1524.6665096283, total regularisd loss (sum of batches): 67089.9813232422\n",
      "obs A loss: 4.2857498936, pde A loss: 106.9945110977\n",
      "obs B loss: 12.0741335750, pde B loss: 28.0863992572\n",
      "obs C loss: 2.5593644604, pde C loss: 2.2506610667\n",
      "obs D loss: 1118.8797359467, pde D loss: 40.0866410434\n",
      "obs E loss: 132.2339911461, pde E loss: 20.0794615149\n",
      "obs F loss: 48.3584997654, pde F loss: 8.7773566172\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.55s\n",
      "\n",
      "Start of epoch 98\n",
      "Training observations acc over epoch: 216.6027984619\n",
      "total loss: 1450.9028434753, total regularisd loss (sum of batches): 63839.0339355469\n",
      "obs A loss: 4.7174033523, pde A loss: 67.8930981755\n",
      "obs B loss: 12.0703950524, pde B loss: 19.9392921329\n",
      "obs C loss: 2.4565629251, pde C loss: 1.8001238480\n",
      "obs D loss: 1106.4157295227, pde D loss: 37.9946199059\n",
      "obs E loss: 127.2093219757, pde E loss: 17.8242320120\n",
      "obs F loss: 46.7472438812, pde F loss: 5.8348123543\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 99\n",
      "Training observations acc over epoch: 213.1900634766\n",
      "total loss: 1548.7906017303, total regularisd loss (sum of batches): 68174.5759277344\n",
      "obs A loss: 5.0311267916, pde A loss: 141.7903121412\n",
      "obs B loss: 12.0908401757, pde B loss: 41.2503630221\n",
      "obs C loss: 2.7879925631, pde C loss: 2.6091795312\n",
      "obs D loss: 1085.9467906952, pde D loss: 44.5218846947\n",
      "obs E loss: 126.0353436470, pde E loss: 29.1263063997\n",
      "obs F loss: 47.2482273579, pde F loss: 10.3522295952\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 67.84s\n",
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 251.6719818115\n",
      "total loss: 1753.8895149231, total regularisd loss (sum of batches): 77166.0455322266\n",
      "obs A loss: 4.2166731954, pde A loss: 91.8050742149\n",
      "obs B loss: 13.3136768937, pde B loss: 71.6772925854\n",
      "obs C loss: 2.8666094989, pde C loss: 1.0842846893\n",
      "obs D loss: 1289.0511951447, pde D loss: 25.8084376156\n",
      "obs E loss: 147.6184897423, pde E loss: 29.8232476711\n",
      "obs F loss: 52.9649277925, pde F loss: 23.6596146226\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.93s\n",
      "\n",
      "Start of epoch 1\n",
      "Training observations acc over epoch: 231.8827362061\n",
      "total loss: 1532.5499763489, total regularisd loss (sum of batches): 67433.8452148438\n",
      "obs A loss: 4.0011344627, pde A loss: 61.1061365604\n",
      "obs B loss: 12.9695834219, pde B loss: 43.2867525220\n",
      "obs C loss: 2.6078360677, pde C loss: 0.8736458737\n",
      "obs D loss: 1176.1746044159, pde D loss: 9.1896662489\n",
      "obs E loss: 144.5196456909, pde E loss: 14.5279250443\n",
      "obs F loss: 51.0234729052, pde F loss: 12.2695898786\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.80s\n",
      "\n",
      "Start of epoch 2\n",
      "Training observations acc over epoch: 217.8620605469\n",
      "total loss: 1360.6934967041, total regularisd loss (sum of batches): 59867.3209228516\n",
      "obs A loss: 4.6252907813, pde A loss: 19.3211859167\n",
      "obs B loss: 12.0924682617, pde B loss: 16.1295128912\n",
      "obs C loss: 2.2557117902, pde C loss: 0.8607280403\n",
      "obs D loss: 1103.5430450439, pde D loss: 4.6943975762\n",
      "obs E loss: 138.4924478531, pde E loss: 9.3188235015\n",
      "obs F loss: 46.1632359624, pde F loss: 3.1966435835\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 3\n",
      "Training observations acc over epoch: 205.9832611084\n",
      "total loss: 1280.1917457581, total regularisd loss (sum of batches): 56326.1894531250\n",
      "obs A loss: 4.6068675369, pde A loss: 16.0678891838\n",
      "obs B loss: 11.5581361949, pde B loss: 8.2988447100\n",
      "obs C loss: 2.2043736652, pde C loss: 1.0462684836\n",
      "obs D loss: 1044.4103012085, pde D loss: 3.9836797044\n",
      "obs E loss: 131.2351622581, pde E loss: 11.5460208654\n",
      "obs F loss: 41.8847610354, pde F loss: 3.3494322710\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 4\n",
      "Training observations acc over epoch: 198.4188842773\n",
      "total loss: 1237.9843311310, total regularisd loss (sum of batches): 54476.8841552734\n",
      "obs A loss: 4.4920428246, pde A loss: 17.2977025211\n",
      "obs B loss: 11.3404859304, pde B loss: 6.3550021052\n",
      "obs C loss: 2.2602331899, pde C loss: 1.3344397265\n",
      "obs D loss: 1007.2794113159, pde D loss: 3.5672200881\n",
      "obs E loss: 125.8037409782, pde E loss: 14.1214431226\n",
      "obs F loss: 39.3374931216, pde F loss: 4.7951199636\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 5\n",
      "Training observations acc over epoch: 194.4395141602\n",
      "total loss: 1218.9746131897, total regularisd loss (sum of batches): 53635.7244873047\n",
      "obs A loss: 4.4595497921, pde A loss: 18.6413863301\n",
      "obs B loss: 11.2504845113, pde B loss: 6.2005061805\n",
      "obs C loss: 2.2712652609, pde C loss: 1.6232717615\n",
      "obs D loss: 988.4148235321, pde D loss: 3.9765891656\n",
      "obs E loss: 122.2888069153, pde E loss: 16.3464621603\n",
      "obs F loss: 37.9522258043, pde F loss: 5.5492374226\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.73s\n",
      "\n",
      "Start of epoch 6\n",
      "Training observations acc over epoch: 191.8770599365\n",
      "total loss: 1205.7716274261, total regularisd loss (sum of batches): 53048.6895751953\n",
      "obs A loss: 4.4346800894, pde A loss: 18.9665356278\n",
      "obs B loss: 11.2429673821, pde B loss: 6.4573008567\n",
      "obs C loss: 2.2738005780, pde C loss: 1.8287655003\n",
      "obs D loss: 975.7960243225, pde D loss: 3.8551030532\n",
      "obs E loss: 120.2836179733, pde E loss: 17.9594396353\n",
      "obs F loss: 37.2315765619, pde F loss: 5.4418060631\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 7\n",
      "Training observations acc over epoch: 190.3945159912\n",
      "total loss: 1197.8555278778, total regularisd loss (sum of batches): 52705.7921142578\n",
      "obs A loss: 4.4213213772, pde A loss: 18.7287768424\n",
      "obs B loss: 11.2389234751, pde B loss: 6.5934952646\n",
      "obs C loss: 2.2812165879, pde C loss: 2.0124608912\n",
      "obs D loss: 968.9616565704, pde D loss: 3.9898267984\n",
      "obs E loss: 118.7978980541, pde E loss: 19.1976260543\n",
      "obs F loss: 36.6661242843, pde F loss: 4.9661985859\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 8\n",
      "Training observations acc over epoch: 189.0654602051\n",
      "total loss: 1191.1769618988, total regularisd loss (sum of batches): 52416.6968994141\n",
      "obs A loss: 4.3940331489, pde A loss: 18.7600333989\n",
      "obs B loss: 11.2110474855, pde B loss: 6.6865729839\n",
      "obs C loss: 2.2851523422, pde C loss: 2.1890897416\n",
      "obs D loss: 962.3973350525, pde D loss: 4.1146100014\n",
      "obs E loss: 117.9645000696, pde E loss: 20.4918459952\n",
      "obs F loss: 36.1406682730, pde F loss: 4.5420813784\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 9\n",
      "Training observations acc over epoch: 187.8674926758\n",
      "total loss: 1185.1733951569, total regularisd loss (sum of batches): 52149.5997314453\n",
      "obs A loss: 4.3914140016, pde A loss: 18.7185011208\n",
      "obs B loss: 11.2095839828, pde B loss: 6.7864822447\n",
      "obs C loss: 2.2934592627, pde C loss: 2.3369164281\n",
      "obs D loss: 956.1746788025, pde D loss: 4.7929152101\n",
      "obs E loss: 117.3078410625, pde E loss: 21.2558630109\n",
      "obs F loss: 35.8279928565, pde F loss: 4.0777576938\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.13s\n",
      "\n",
      "Start of epoch 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 186.8585357666\n",
      "total loss: 1179.7650108337, total regularisd loss (sum of batches): 51909.0634765625\n",
      "obs A loss: 4.3919029608, pde A loss: 18.6664979756\n",
      "obs B loss: 11.1944387257, pde B loss: 6.8801741302\n",
      "obs C loss: 2.3147704639, pde C loss: 2.5032823198\n",
      "obs D loss: 950.9889259338, pde D loss: 4.7737030387\n",
      "obs E loss: 116.5947499275, pde E loss: 22.0547413528\n",
      "obs F loss: 35.6663809419, pde F loss: 3.7354522273\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 11\n",
      "Training observations acc over epoch: 185.5496826172\n",
      "total loss: 1171.8985404968, total regularisd loss (sum of batches): 51563.4638671875\n",
      "obs A loss: 4.4920257777, pde A loss: 18.6332007647\n",
      "obs B loss: 11.1654279679, pde B loss: 7.0099068433\n",
      "obs C loss: 2.3177280761, pde C loss: 2.6570128985\n",
      "obs D loss: 944.0652599335, pde D loss: 4.1361836046\n",
      "obs E loss: 115.9655740261, pde E loss: 22.6176270247\n",
      "obs F loss: 35.2918492556, pde F loss: 3.5467468277\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.53s\n",
      "\n",
      "Start of epoch 12\n",
      "Training observations acc over epoch: 184.8892822266\n",
      "total loss: 1167.8391399384, total regularisd loss (sum of batches): 51386.7620849609\n",
      "obs A loss: 4.5589443818, pde A loss: 18.7162685394\n",
      "obs B loss: 11.1310161799, pde B loss: 6.8938284069\n",
      "obs C loss: 2.3313279860, pde C loss: 2.7399478257\n",
      "obs D loss: 940.4340915680, pde D loss: 4.3563211709\n",
      "obs E loss: 115.6851871014, pde E loss: 22.5069596171\n",
      "obs F loss: 35.1951202154, pde F loss: 3.2901274040\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.39s\n",
      "\n",
      "Start of epoch 13\n",
      "Training observations acc over epoch: 184.4568634033\n",
      "total loss: 1165.1891422272, total regularisd loss (sum of batches): 51267.9097900391\n",
      "obs A loss: 4.5924385637, pde A loss: 18.3275840580\n",
      "obs B loss: 11.1078691632, pde B loss: 6.8766864687\n",
      "obs C loss: 2.3304491453, pde C loss: 2.8254288249\n",
      "obs D loss: 938.0980873108, pde D loss: 4.9136439785\n",
      "obs E loss: 115.4888043404, pde E loss: 22.3710624874\n",
      "obs F loss: 35.1237891316, pde F loss: 3.1332987472\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.36s\n",
      "\n",
      "Start of epoch 14\n",
      "Training observations acc over epoch: 183.5540008545\n",
      "total loss: 1158.8161220551, total regularisd loss (sum of batches): 50990.3773193359\n",
      "obs A loss: 4.6173486486, pde A loss: 18.4667867124\n",
      "obs B loss: 11.0949951708, pde B loss: 6.8102902174\n",
      "obs C loss: 2.3291823454, pde C loss: 2.8796007782\n",
      "obs D loss: 933.1634273529, pde D loss: 4.2385550365\n",
      "obs E loss: 115.1126201153, pde E loss: 22.1505261362\n",
      "obs F loss: 35.0062748790, pde F loss: 2.9465148225\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 15\n",
      "Training observations acc over epoch: 182.9736938477\n",
      "total loss: 1154.2338790894, total regularisd loss (sum of batches): 50786.1478271484\n",
      "obs A loss: 4.6477754489, pde A loss: 17.9390674233\n",
      "obs B loss: 11.0861123800, pde B loss: 6.7876323909\n",
      "obs C loss: 2.3281725347, pde C loss: 2.9459380060\n",
      "obs D loss: 930.1910037994, pde D loss: 3.7944049984\n",
      "obs E loss: 114.7659482956, pde E loss: 22.1660960913\n",
      "obs F loss: 34.8233187795, pde F loss: 2.7584225759\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 16\n",
      "Training observations acc over epoch: 182.4839782715\n",
      "total loss: 1151.4502544403, total regularisd loss (sum of batches): 50667.5550537109\n",
      "obs A loss: 4.7508413643, pde A loss: 17.7225431502\n",
      "obs B loss: 11.0713562518, pde B loss: 6.7697458416\n",
      "obs C loss: 2.2801118344, pde C loss: 2.9220667407\n",
      "obs D loss: 927.9259471893, pde D loss: 4.6895349771\n",
      "obs E loss: 114.4882700443, pde E loss: 21.9610846639\n",
      "obs F loss: 34.3873057961, pde F loss: 2.4814439565\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.40s\n",
      "\n",
      "Start of epoch 17\n",
      "Training observations acc over epoch: 181.7897033691\n",
      "total loss: 1147.3720512390, total regularisd loss (sum of batches): 50480.3299560547\n",
      "obs A loss: 4.8267197460, pde A loss: 17.8463936448\n",
      "obs B loss: 11.0989805162, pde B loss: 6.9230727106\n",
      "obs C loss: 2.2294996865, pde C loss: 2.8259013183\n",
      "obs D loss: 924.5553207397, pde D loss: 5.0307169408\n",
      "obs E loss: 114.2360332012, pde E loss: 21.7834997177\n",
      "obs F loss: 33.7916230559, pde F loss: 2.2243016139\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 18\n",
      "Training observations acc over epoch: 181.1097717285\n",
      "total loss: 1142.3803176880, total regularisd loss (sum of batches): 50266.1420898438\n",
      "obs A loss: 4.8822595775, pde A loss: 18.1266913116\n",
      "obs B loss: 11.0856858641, pde B loss: 6.9626007825\n",
      "obs C loss: 2.2210703380, pde C loss: 2.7523345090\n",
      "obs D loss: 921.2336063385, pde D loss: 4.6524205729\n",
      "obs E loss: 113.7023823261, pde E loss: 21.1566865146\n",
      "obs F loss: 33.5335870385, pde F loss: 2.0710022487\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 19\n",
      "Training observations acc over epoch: 180.5909118652\n",
      "total loss: 1139.4416618347, total regularisd loss (sum of batches): 50131.4608154297\n",
      "obs A loss: 4.9014000297, pde A loss: 18.6764920652\n",
      "obs B loss: 11.0578252673, pde B loss: 6.9671684951\n",
      "obs C loss: 2.2033368796, pde C loss: 2.6971474215\n",
      "obs D loss: 918.5725650787, pde D loss: 5.0461432412\n",
      "obs E loss: 113.4725785255, pde E loss: 20.6446343660\n",
      "obs F loss: 33.3377189636, pde F loss: 1.8646491915\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 179.6217041016\n",
      "total loss: 1130.0256748199, total regularisd loss (sum of batches): 49726.1679077148\n",
      "obs A loss: 4.8968520388, pde A loss: 17.6298200488\n",
      "obs B loss: 11.0388778746, pde B loss: 6.7997896820\n",
      "obs C loss: 2.1830167454, pde C loss: 2.5857592933\n",
      "obs D loss: 913.7999343872, pde D loss: 3.8417031392\n",
      "obs E loss: 112.8358001709, pde E loss: 19.7827449143\n",
      "obs F loss: 32.9756001830, pde F loss: 1.6557647400\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.41s\n",
      "\n",
      "Start of epoch 21\n",
      "Training observations acc over epoch: 179.0033111572\n",
      "total loss: 1125.1995449066, total regularisd loss (sum of batches): 49507.2661132812\n",
      "obs A loss: 4.9105774090, pde A loss: 18.0207757652\n",
      "obs B loss: 11.0642632395, pde B loss: 6.6416336149\n",
      "obs C loss: 2.2099935859, pde C loss: 2.4192644097\n",
      "obs D loss: 910.9473972321, pde D loss: 3.8171028085\n",
      "obs E loss: 112.3692293167, pde E loss: 18.7486774623\n",
      "obs F loss: 32.5183457136, pde F loss: 1.5322922748\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.28s\n",
      "\n",
      "Start of epoch 22\n",
      "Training observations acc over epoch: 178.3321838379\n",
      "total loss: 1120.1657295227, total regularisd loss (sum of batches): 49289.5764770508\n",
      "obs A loss: 4.9317643046, pde A loss: 17.5599371493\n",
      "obs B loss: 11.1328445375, pde B loss: 6.8108974248\n",
      "obs C loss: 2.1542473175, pde C loss: 2.3177532777\n",
      "obs D loss: 907.7259311676, pde D loss: 4.0157441720\n",
      "obs E loss: 111.8790283203, pde E loss: 18.0816844702\n",
      "obs F loss: 32.1693295240, pde F loss: 1.3865770455\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 23\n",
      "Training observations acc over epoch: 177.5896453857\n",
      "total loss: 1113.7827720642, total regularisd loss (sum of batches): 49006.3500366211\n",
      "obs A loss: 4.9629063085, pde A loss: 16.9695724547\n",
      "obs B loss: 11.1451238990, pde B loss: 6.7893165648\n",
      "obs C loss: 2.1218939573, pde C loss: 2.1883827038\n",
      "obs D loss: 903.8506469727, pde D loss: 3.6328939274\n",
      "obs E loss: 111.6497271061, pde E loss: 17.3619628251\n",
      "obs F loss: 31.8076480627, pde F loss: 1.3026942369\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 24\n",
      "Training observations acc over epoch: 177.2227783203\n",
      "total loss: 1111.1045818329, total regularisd loss (sum of batches): 48881.6123657227\n",
      "obs A loss: 4.9583380744, pde A loss: 17.2787370384\n",
      "obs B loss: 11.1755098104, pde B loss: 6.9427243173\n",
      "obs C loss: 2.0818576403, pde C loss: 2.0891096406\n",
      "obs D loss: 902.3971252441, pde D loss: 3.5888617337\n",
      "obs E loss: 111.2771227360, pde E loss: 16.6832756698\n",
      "obs F loss: 31.4467357993, pde F loss: 1.1851857956\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 25\n",
      "Training observations acc over epoch: 176.8410797119\n",
      "total loss: 1108.0312156677, total regularisd loss (sum of batches): 48759.0697021484\n",
      "obs A loss: 4.9856097698, pde A loss: 16.7807922661\n",
      "obs B loss: 11.1917014718, pde B loss: 6.9128559977\n",
      "obs C loss: 2.0489275083, pde C loss: 1.9601459727\n",
      "obs D loss: 900.7142562866, pde D loss: 4.2093474828\n",
      "obs E loss: 110.9135121107, pde E loss: 16.0016356111\n",
      "obs F loss: 31.1924118996, pde F loss: 1.1200166941\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 26\n",
      "Training observations acc over epoch: 176.2705535889\n",
      "total loss: 1103.7705993652, total regularisd loss (sum of batches): 48561.8949584961\n",
      "obs A loss: 4.9792364016, pde A loss: 16.5630474985\n",
      "obs B loss: 11.2076508701, pde B loss: 6.8989074826\n",
      "obs C loss: 2.0204365253, pde C loss: 1.8937959857\n",
      "obs D loss: 898.1198787689, pde D loss: 4.0041933171\n",
      "obs E loss: 110.6521239281, pde E loss: 15.6920482814\n",
      "obs F loss: 30.6438540816, pde F loss: 1.0954165999\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.77s\n",
      "\n",
      "Start of epoch 27\n",
      "Training observations acc over epoch: 175.8705749512\n",
      "total loss: 1100.6364231110, total regularisd loss (sum of batches): 48424.7834472656\n",
      "obs A loss: 4.9933644682, pde A loss: 16.8523397148\n",
      "obs B loss: 11.1882721186, pde B loss: 6.9763499647\n",
      "obs C loss: 1.9979042970, pde C loss: 1.7836097032\n",
      "obs D loss: 896.2206840515, pde D loss: 3.7387294471\n",
      "obs E loss: 110.5945714712, pde E loss: 15.0515862405\n",
      "obs F loss: 30.2286154628, pde F loss: 1.0103991367\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 28\n",
      "Training observations acc over epoch: 175.2353515625\n",
      "total loss: 1095.4921836853, total regularisd loss (sum of batches): 48198.6899414062\n",
      "obs A loss: 4.9921963885, pde A loss: 16.0193766952\n",
      "obs B loss: 11.2104405463, pde B loss: 6.8361334950\n",
      "obs C loss: 1.9750529751, pde C loss: 1.6785050295\n",
      "obs D loss: 893.2893886566, pde D loss: 4.0720300749\n",
      "obs E loss: 110.1150872707, pde E loss: 14.5337083340\n",
      "obs F loss: 29.8299750090, pde F loss: 0.9402927849\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 29\n",
      "Training observations acc over epoch: 174.5948181152\n",
      "total loss: 1091.1959609985, total regularisd loss (sum of batches): 48009.4874267578\n",
      "obs A loss: 4.9938657358, pde A loss: 16.1022161245\n",
      "obs B loss: 11.2201392353, pde B loss: 6.8289682865\n",
      "obs C loss: 1.9495209083, pde C loss: 1.6108593382\n",
      "obs D loss: 890.3591327667, pde D loss: 3.8646213450\n",
      "obs E loss: 109.8319051266, pde E loss: 14.2707478404\n",
      "obs F loss: 29.2144358754, pde F loss: 0.9495421648\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 174.3974914551\n",
      "total loss: 1089.6629447937, total regularisd loss (sum of batches): 47950.2233276367\n",
      "obs A loss: 5.0090035051, pde A loss: 16.2533881068\n",
      "obs B loss: 11.2387525588, pde B loss: 6.7953820229\n",
      "obs C loss: 1.9397296347, pde C loss: 1.4890861586\n",
      "obs D loss: 889.8789901733, pde D loss: 4.2880542837\n",
      "obs E loss: 109.5173103809, pde E loss: 13.5575493574\n",
      "obs F loss: 28.8012290597, pde F loss: 0.8944569500\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.76s\n",
      "\n",
      "Start of epoch 31\n",
      "Training observations acc over epoch: 173.9852142334\n",
      "total loss: 1086.6128330231, total regularisd loss (sum of batches): 47817.8834838867\n",
      "obs A loss: 4.9983987883, pde A loss: 15.8945536911\n",
      "obs B loss: 11.2394377291, pde B loss: 6.5946191102\n",
      "obs C loss: 1.9280053489, pde C loss: 1.3776863050\n",
      "obs D loss: 887.9694747925, pde D loss: 5.1093311571\n",
      "obs E loss: 109.3625409603, pde E loss: 12.8740044385\n",
      "obs F loss: 28.4136145115, pde F loss: 0.8511761874\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 32\n",
      "Training observations acc over epoch: 173.2113189697\n",
      "total loss: 1078.2486476898, total regularisd loss (sum of batches): 47439.7432250977\n",
      "obs A loss: 4.9627855420, pde A loss: 14.9476601481\n",
      "obs B loss: 11.2426972538, pde B loss: 6.3479398638\n",
      "obs C loss: 1.9188554119, pde C loss: 1.2778997198\n",
      "obs D loss: 884.1638679504, pde D loss: 3.4800765216\n",
      "obs E loss: 109.1487920284, pde E loss: 12.1064568013\n",
      "obs F loss: 27.8309594989, pde F loss: 0.8206691667\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 33\n",
      "Training observations acc over epoch: 172.7223510742\n",
      "total loss: 1074.3569660187, total regularisd loss (sum of batches): 47275.0791625977\n",
      "obs A loss: 4.9432303905, pde A loss: 15.0431996286\n",
      "obs B loss: 11.2528782636, pde B loss: 6.2907004058\n",
      "obs C loss: 1.9100723825, pde C loss: 1.1996346768\n",
      "obs D loss: 881.9832401276, pde D loss: 3.1824408956\n",
      "obs E loss: 108.8166589737, pde E loss: 11.4923422188\n",
      "obs F loss: 27.4277830720, pde F loss: 0.8147975337\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 34\n",
      "Training observations acc over epoch: 172.4488983154\n",
      "total loss: 1072.0013446808, total regularisd loss (sum of batches): 47166.6198120117\n",
      "obs A loss: 4.9087117836, pde A loss: 15.1286657155\n",
      "obs B loss: 11.2657202929, pde B loss: 6.2096066698\n",
      "obs C loss: 1.9017747212, pde C loss: 1.1091925502\n",
      "obs D loss: 881.0282936096, pde D loss: 3.2757969052\n",
      "obs E loss: 108.6453644037, pde E loss: 10.7935895026\n",
      "obs F loss: 26.9436804056, pde F loss: 0.7909506196\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 35\n",
      "Training observations acc over epoch: 171.6945037842\n",
      "total loss: 1065.2643165588, total regularisd loss (sum of batches): 46871.9281005859\n",
      "obs A loss: 4.8926264569, pde A loss: 14.1851272583\n",
      "obs B loss: 11.2812074423, pde B loss: 6.0484289154\n",
      "obs C loss: 1.8957330529, pde C loss: 1.0593431965\n",
      "obs D loss: 877.2629394531, pde D loss: 2.9059517458\n",
      "obs E loss: 108.4095563889, pde E loss: 10.1152165085\n",
      "obs F loss: 26.4250041842, pde F loss: 0.7831888376\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 36\n",
      "Training observations acc over epoch: 171.4494476318\n",
      "total loss: 1065.5439453125, total regularisd loss (sum of batches): 46887.6160278320\n",
      "obs A loss: 4.8733208999, pde A loss: 14.8274378181\n",
      "obs B loss: 11.2660486251, pde B loss: 5.9796273932\n",
      "obs C loss: 1.8912010919, pde C loss: 0.9868951906\n",
      "obs D loss: 876.5068321228, pde D loss: 4.8293671608\n",
      "obs E loss: 108.2448084354, pde E loss: 9.4413582534\n",
      "obs F loss: 25.9143927097, pde F loss: 0.7826466709\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 37\n",
      "Training observations acc over epoch: 171.4031829834\n",
      "total loss: 1065.7145919800, total regularisd loss (sum of batches): 46890.6441040039\n",
      "obs A loss: 4.8627003282, pde A loss: 15.8439932466\n",
      "obs B loss: 11.3073347062, pde B loss: 6.1072885543\n",
      "obs C loss: 1.8852130417, pde C loss: 0.9440359920\n",
      "obs D loss: 876.9506320953, pde D loss: 4.8416739404\n",
      "obs E loss: 107.9401900768, pde E loss: 8.8149924725\n",
      "obs F loss: 25.4732578397, pde F loss: 0.7432889026\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 38\n",
      "Training observations acc over epoch: 170.6879119873\n",
      "total loss: 1056.6531257629, total regularisd loss (sum of batches): 46492.7900390625\n",
      "obs A loss: 4.8170326650, pde A loss: 13.6538390219\n",
      "obs B loss: 11.2945205867, pde B loss: 5.6386591271\n",
      "obs C loss: 1.8832631148, pde C loss: 0.8669294696\n",
      "obs D loss: 873.4726428986, pde D loss: 3.6953022555\n",
      "obs E loss: 107.7470569611, pde E loss: 7.9281364679\n",
      "obs F loss: 24.9129844308, pde F loss: 0.7427517585\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 39\n",
      "Training observations acc over epoch: 170.4178161621\n",
      "total loss: 1060.1897525787, total regularisd loss (sum of batches): 46650.3809204102\n",
      "obs A loss: 4.8162114993, pde A loss: 17.4378668666\n",
      "obs B loss: 11.3172382563, pde B loss: 6.1321137697\n",
      "obs C loss: 1.8822227065, pde C loss: 0.8793166149\n",
      "obs D loss: 872.6458740234, pde D loss: 4.9135781191\n",
      "obs E loss: 107.4454514980, pde E loss: 7.5776062906\n",
      "obs F loss: 24.4001547098, pde F loss: 0.7421121169\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 169.9483184814\n",
      "total loss: 1054.9059162140, total regularisd loss (sum of batches): 46417.9827880859\n",
      "obs A loss: 4.7960465848, pde A loss: 16.6031980217\n",
      "obs B loss: 11.3494672030, pde B loss: 5.8386679813\n",
      "obs C loss: 1.8784512635, pde C loss: 0.8636439359\n",
      "obs D loss: 870.7367420197, pde D loss: 4.1410834603\n",
      "obs E loss: 107.1392612457, pde E loss: 7.0003267676\n",
      "obs F loss: 23.7900462151, pde F loss: 0.7689836193\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 41\n",
      "Training observations acc over epoch: 169.5982818604\n",
      "total loss: 1050.0123596191, total regularisd loss (sum of batches): 46199.1846313477\n",
      "obs A loss: 4.7234098613, pde A loss: 15.2153041661\n",
      "obs B loss: 11.3708969504, pde B loss: 5.4217573926\n",
      "obs C loss: 1.8814404998, pde C loss: 0.8487208113\n",
      "obs D loss: 870.0515251160, pde D loss: 4.1026311330\n",
      "obs E loss: 107.0385789871, pde E loss: 6.0657613724\n",
      "obs F loss: 22.5237159133, pde F loss: 0.7686048178\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.53s\n",
      "\n",
      "Start of epoch 42\n",
      "Training observations acc over epoch: 169.7051849365\n",
      "total loss: 1060.4542236328, total regularisd loss (sum of batches): 46654.6088867188\n",
      "obs A loss: 4.7746242732, pde A loss: 20.1620418131\n",
      "obs B loss: 11.4187153131, pde B loss: 5.9048416913\n",
      "obs C loss: 1.8830064293, pde C loss: 1.1085367342\n",
      "obs D loss: 871.1706008911, pde D loss: 6.8520346284\n",
      "obs E loss: 106.8386023045, pde E loss: 7.3716078401\n",
      "obs F loss: 22.1455778778, pde F loss: 0.8240251057\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 43\n",
      "Training observations acc over epoch: 168.6542968750\n",
      "total loss: 1042.2119255066, total regularisd loss (sum of batches): 45852.7512207031\n",
      "obs A loss: 4.6218866631, pde A loss: 13.2063696235\n",
      "obs B loss: 11.3961972743, pde B loss: 4.8272451907\n",
      "obs C loss: 1.8840168864, pde C loss: 0.8091007527\n",
      "obs D loss: 866.3534603119, pde D loss: 5.3031092361\n",
      "obs E loss: 106.7731707096, pde E loss: 5.4415678754\n",
      "obs F loss: 20.8971654177, pde F loss: 0.6986272940\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 44\n",
      "Training observations acc over epoch: 168.1909332275\n",
      "total loss: 1039.9574661255, total regularisd loss (sum of batches): 45756.9683227539\n",
      "obs A loss: 4.5850340575, pde A loss: 14.9495803565\n",
      "obs B loss: 11.3837707490, pde B loss: 4.9001122639\n",
      "obs C loss: 1.8832719158, pde C loss: 0.8296595486\n",
      "obs D loss: 864.6074066162, pde D loss: 3.9072117470\n",
      "obs E loss: 106.6554038525, pde E loss: 5.5526532084\n",
      "obs F loss: 20.0306332111, pde F loss: 0.6727326252\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 45\n",
      "Training observations acc over epoch: 167.8295440674\n",
      "total loss: 1038.6668663025, total regularisd loss (sum of batches): 45697.9367065430\n",
      "obs A loss: 4.5701825172, pde A loss: 15.4031979144\n",
      "obs B loss: 11.4048418403, pde B loss: 4.9017433226\n",
      "obs C loss: 1.8822230585, pde C loss: 0.8487752825\n",
      "obs D loss: 862.9870738983, pde D loss: 4.1325431988\n",
      "obs E loss: 106.5875709057, pde E loss: 5.7332760915\n",
      "obs F loss: 19.5452853441, pde F loss: 0.6701455154\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 46\n",
      "Training observations acc over epoch: 167.3338165283\n",
      "total loss: 1031.2786331177, total regularisd loss (sum of batches): 45374.9611816406\n",
      "obs A loss: 4.4918359965, pde A loss: 13.5583517551\n",
      "obs B loss: 11.3996290267, pde B loss: 4.4158869535\n",
      "obs C loss: 1.8817038182, pde C loss: 0.7779902853\n",
      "obs D loss: 860.7293567657, pde D loss: 2.6034642458\n",
      "obs E loss: 106.4808385372, pde E loss: 5.2829091921\n",
      "obs F loss: 19.0194528103, pde F loss: 0.6372121302\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 47\n",
      "Training observations acc over epoch: 167.4788818359\n",
      "total loss: 1040.9062232971, total regularisd loss (sum of batches): 45798.7343750000\n",
      "obs A loss: 4.5715783760, pde A loss: 19.0246783495\n",
      "obs B loss: 11.4220374525, pde B loss: 5.3279614896\n",
      "obs C loss: 1.8834470678, pde C loss: 0.9021670436\n",
      "obs D loss: 861.7646350861, pde D loss: 3.9688175954\n",
      "obs E loss: 106.4416718483, pde E loss: 6.1110828966\n",
      "obs F loss: 18.7898138762, pde F loss: 0.6983288052\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 48\n",
      "Training observations acc over epoch: 167.5349731445\n",
      "total loss: 1036.9285030365, total regularisd loss (sum of batches): 45624.8469848633\n",
      "obs A loss: 4.4673219398, pde A loss: 16.3365806043\n",
      "obs B loss: 11.4221771359, pde B loss: 4.6090155244\n",
      "obs C loss: 1.8824462648, pde C loss: 0.7302827388\n",
      "obs D loss: 862.1963367462, pde D loss: 4.1953005157\n",
      "obs E loss: 106.6277536154, pde E loss: 5.2348064035\n",
      "obs F loss: 18.6138283014, pde F loss: 0.6126562422\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 49\n",
      "Training observations acc over epoch: 166.9277496338\n",
      "total loss: 1027.1097850800, total regularisd loss (sum of batches): 45189.4371948242\n",
      "obs A loss: 4.3725951388, pde A loss: 12.2777873278\n",
      "obs B loss: 11.4082766175, pde B loss: 3.8207083046\n",
      "obs C loss: 1.8814582024, pde C loss: 0.6531022247\n",
      "obs D loss: 859.6931781769, pde D loss: 3.8270080611\n",
      "obs E loss: 106.3109333515, pde E loss: 4.3568459749\n",
      "obs F loss: 17.9001074135, pde F loss: 0.6077829916\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 166.5635833740\n",
      "total loss: 1028.4370956421, total regularisd loss (sum of batches): 45248.8238525391\n",
      "obs A loss: 4.3641933128, pde A loss: 14.6462965459\n",
      "obs B loss: 11.4061972052, pde B loss: 4.2928863987\n",
      "obs C loss: 1.8840343654, pde C loss: 0.7055462264\n",
      "obs D loss: 857.9156455994, pde D loss: 3.8225485384\n",
      "obs E loss: 106.3549844027, pde E loss: 4.9658076316\n",
      "obs F loss: 17.4565336108, pde F loss: 0.6224217359\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.53s\n",
      "\n",
      "Start of epoch 51\n",
      "Training observations acc over epoch: 166.2489624023\n",
      "total loss: 1026.8917388916, total regularisd loss (sum of batches): 45183.0566406250\n",
      "obs A loss: 4.3246010914, pde A loss: 13.9132716656\n",
      "obs B loss: 11.4110005647, pde B loss: 3.9237597883\n",
      "obs C loss: 1.8855815195, pde C loss: 0.6532482635\n",
      "obs D loss: 856.2558403015, pde D loss: 5.7467778102\n",
      "obs E loss: 106.4238951206, pde E loss: 4.5657856017\n",
      "obs F loss: 17.1928915977, pde F loss: 0.5950783119\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 52\n",
      "Training observations acc over epoch: 165.8297271729\n",
      "total loss: 1021.3575420380, total regularisd loss (sum of batches): 44943.3342895508\n",
      "obs A loss: 4.2633297518, pde A loss: 12.6308909506\n",
      "obs B loss: 11.3878747523, pde B loss: 3.6618191525\n",
      "obs C loss: 1.8826624881, pde C loss: 0.6177558070\n",
      "obs D loss: 854.5973663330, pde D loss: 4.6410877854\n",
      "obs E loss: 106.1784460545, pde E loss: 4.2412437126\n",
      "obs F loss: 16.6686277688, pde F loss: 0.5864211349\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 53\n",
      "Training observations acc over epoch: 165.6467742920\n",
      "total loss: 1021.5367393494, total regularisd loss (sum of batches): 44952.5432739258\n",
      "obs A loss: 4.2542726323, pde A loss: 13.8577369750\n",
      "obs B loss: 11.3928373903, pde B loss: 3.8190814480\n",
      "obs C loss: 1.8827443980, pde C loss: 0.6162757464\n",
      "obs D loss: 853.8239936829, pde D loss: 4.3596310169\n",
      "obs E loss: 106.2480962276, pde E loss: 4.4152330533\n",
      "obs F loss: 16.2788092494, pde F loss: 0.5880198833\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 54\n",
      "Training observations acc over epoch: 165.7152709961\n",
      "total loss: 1023.0166511536, total regularisd loss (sum of batches): 45013.8541870117\n",
      "obs A loss: 4.2314171046, pde A loss: 13.7683134973\n",
      "obs B loss: 11.3818556070, pde B loss: 3.7609922253\n",
      "obs C loss: 1.8828580994, pde C loss: 0.6127214823\n",
      "obs D loss: 854.3229866028, pde D loss: 5.6467164271\n",
      "obs E loss: 106.4314537048, pde E loss: 4.3345909864\n",
      "obs F loss: 16.0410727561, pde F loss: 0.6016761661\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 55\n",
      "Training observations acc over epoch: 165.4810791016\n",
      "total loss: 1020.9916019440, total regularisd loss (sum of batches): 44920.8856811523\n",
      "obs A loss: 4.1990571544, pde A loss: 14.8711964339\n",
      "obs B loss: 11.3747415990, pde B loss: 3.6453680135\n",
      "obs C loss: 1.8831708133, pde C loss: 0.5882453537\n",
      "obs D loss: 853.3364791870, pde D loss: 4.1714366116\n",
      "obs E loss: 106.3791842461, pde E loss: 4.2284776047\n",
      "obs F loss: 15.7136798203, pde F loss: 0.6005558101\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 56\n",
      "Training observations acc over epoch: 164.9613952637\n",
      "total loss: 1015.5650882721, total regularisd loss (sum of batches): 44686.4246215820\n",
      "obs A loss: 4.1703667119, pde A loss: 13.7003425360\n",
      "obs B loss: 11.3793331534, pde B loss: 3.6124398932\n",
      "obs C loss: 1.8805274852, pde C loss: 0.5764330961\n",
      "obs D loss: 850.5890197754, pde D loss: 3.1768192127\n",
      "obs E loss: 106.2149524689, pde E loss: 4.1568864286\n",
      "obs F loss: 15.5341331065, pde F loss: 0.5738374712\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 57\n",
      "Training observations acc over epoch: 164.9072875977\n",
      "total loss: 1014.9477634430, total regularisd loss (sum of batches): 44661.1057128906\n",
      "obs A loss: 4.1307769120, pde A loss: 12.9713025391\n",
      "obs B loss: 11.3714937270, pde B loss: 3.4269945137\n",
      "obs C loss: 1.8823057394, pde C loss: 0.5480064154\n",
      "obs D loss: 850.6064262390, pde D loss: 4.1216852106\n",
      "obs E loss: 106.2956001759, pde E loss: 3.8588996902\n",
      "obs F loss: 15.1572066545, pde F loss: 0.5770690255\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 58\n",
      "Training observations acc over epoch: 164.6149597168\n",
      "total loss: 1018.6736354828, total regularisd loss (sum of batches): 44821.3101806641\n",
      "obs A loss: 4.1320251003, pde A loss: 17.4541418403\n",
      "obs B loss: 11.3653811663, pde B loss: 3.9959291704\n",
      "obs C loss: 1.8810525835, pde C loss: 0.6332749268\n",
      "obs D loss: 849.1248455048, pde D loss: 3.6235183664\n",
      "obs E loss: 106.1982915401, pde E loss: 4.6812774688\n",
      "obs F loss: 14.9881867766, pde F loss: 0.5957050994\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.43s\n",
      "\n",
      "Start of epoch 59\n",
      "Training observations acc over epoch: 164.9807739258\n",
      "total loss: 1020.0907440186, total regularisd loss (sum of batches): 44887.8076171875\n",
      "obs A loss: 4.1983770579, pde A loss: 17.6354287118\n",
      "obs B loss: 11.4152045995, pde B loss: 3.9458940737\n",
      "obs C loss: 1.8819446135, pde C loss: 0.6344759362\n",
      "obs D loss: 850.9084186554, pde D loss: 3.2040265501\n",
      "obs E loss: 106.1836597919, pde E loss: 4.2036392428\n",
      "obs F loss: 15.2970512509, pde F loss: 0.5826277006\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 164.5951385498\n",
      "total loss: 1011.8349514008, total regularisd loss (sum of batches): 44516.3912963867\n",
      "obs A loss: 4.0475454405, pde A loss: 12.6247758120\n",
      "obs B loss: 11.3423648626, pde B loss: 2.9768718556\n",
      "obs C loss: 1.8793291878, pde C loss: 0.4662716724\n",
      "obs D loss: 849.5368118286, pde D loss: 4.4244070537\n",
      "obs E loss: 106.2099455595, pde E loss: 3.2251099460\n",
      "obs F loss: 14.5550646782, pde F loss: 0.5464488873\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 61\n",
      "Training observations acc over epoch: 164.2776489258\n",
      "total loss: 1014.1034069061, total regularisd loss (sum of batches): 44617.9472656250\n",
      "obs A loss: 4.0316258296, pde A loss: 14.5898044109\n",
      "obs B loss: 11.3416495472, pde B loss: 3.2140792683\n",
      "obs C loss: 1.8830020092, pde C loss: 0.5122024808\n",
      "obs D loss: 847.8568935394, pde D loss: 5.8018331677\n",
      "obs E loss: 106.3098425865, pde E loss: 3.7581269443\n",
      "obs F loss: 14.2430657148, pde F loss: 0.5612897435\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.24s\n",
      "\n",
      "Start of epoch 62\n",
      "Training observations acc over epoch: 164.0793609619\n",
      "total loss: 1008.7154922485, total regularisd loss (sum of batches): 44384.3033447266\n",
      "obs A loss: 4.0166868269, pde A loss: 13.0371704102\n",
      "obs B loss: 11.3291419744, pde B loss: 3.0799086764\n",
      "obs C loss: 1.8799816761, pde C loss: 0.4924715459\n",
      "obs D loss: 847.0621051788, pde D loss: 3.6766577624\n",
      "obs E loss: 106.2409911156, pde E loss: 3.4117734283\n",
      "obs F loss: 13.9472508132, pde F loss: 0.5413485393\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.31s\n",
      "\n",
      "Start of epoch 63\n",
      "Training observations acc over epoch: 163.6539611816\n",
      "total loss: 1006.9178352356, total regularisd loss (sum of batches): 44300.2944946289\n",
      "obs A loss: 3.9881549999, pde A loss: 13.6671961546\n",
      "obs B loss: 11.3180956244, pde B loss: 3.1500565261\n",
      "obs C loss: 1.8818981703, pde C loss: 0.5294757187\n",
      "obs D loss: 844.8352336884, pde D loss: 3.5117727630\n",
      "obs E loss: 106.2055873871, pde E loss: 3.5888367072\n",
      "obs F loss: 13.6949539483, pde F loss: 0.5465829624\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.41s\n",
      "\n",
      "Start of epoch 64\n",
      "Training observations acc over epoch: 163.9269256592\n",
      "total loss: 1008.4111614227, total regularisd loss (sum of batches): 44366.9105834961\n",
      "obs A loss: 3.9550866708, pde A loss: 13.3458367139\n",
      "obs B loss: 11.3181761652, pde B loss: 2.9314394481\n",
      "obs C loss: 1.8827692792, pde C loss: 0.5106959259\n",
      "obs D loss: 846.5275678635, pde D loss: 4.1448446698\n",
      "obs E loss: 106.3273584843, pde E loss: 3.3713372797\n",
      "obs F loss: 13.5506546795, pde F loss: 0.5453853365\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 65\n",
      "Training observations acc over epoch: 163.3481292725\n",
      "total loss: 1002.6602497101, total regularisd loss (sum of batches): 44116.4569091797\n",
      "obs A loss: 3.9148908183, pde A loss: 12.4086378068\n",
      "obs B loss: 11.2869703919, pde B loss: 2.8411880210\n",
      "obs C loss: 1.8791098204, pde C loss: 0.4760774728\n",
      "obs D loss: 843.6669960022, pde D loss: 3.0889317505\n",
      "obs E loss: 106.1133011580, pde E loss: 3.2305528820\n",
      "obs F loss: 13.2273747027, pde F loss: 0.5262218183\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 66\n",
      "Training observations acc over epoch: 196.1250000000\n",
      "total loss: 1594.4075622559, total regularisd loss (sum of batches): 70137.0170898438\n",
      "obs A loss: 5.6086445265, pde A loss: 262.9411158562\n",
      "obs B loss: 11.5732882470, pde B loss: 44.4670836143\n",
      "obs C loss: 3.6542508677, pde C loss: 5.4336656807\n",
      "obs D loss: 1002.7659893036, pde D loss: 32.7219811827\n",
      "obs E loss: 112.2609231472, pde E loss: 46.8747013509\n",
      "obs F loss: 40.8867973089, pde F loss: 25.2191208312\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 67\n",
      "Training observations acc over epoch: 187.4235992432\n",
      "total loss: 1161.4085559845, total regularisd loss (sum of batches): 51099.0715332031\n",
      "obs A loss: 3.9672408774, pde A loss: 16.8992597014\n",
      "obs B loss: 11.4635767043, pde B loss: 4.5233528242\n",
      "obs C loss: 2.2412881292, pde C loss: 0.8462503375\n",
      "obs D loss: 960.1337528229, pde D loss: 6.6151547059\n",
      "obs E loss: 111.5958893299, pde E loss: 5.6882960275\n",
      "obs F loss: 35.1397464275, pde F loss: 2.2947590966\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 68\n",
      "Training observations acc over epoch: 181.6464996338\n",
      "total loss: 1116.6145801544, total regularisd loss (sum of batches): 49131.2694702148\n",
      "obs A loss: 3.4821783155, pde A loss: 11.5948521793\n",
      "obs B loss: 11.3051998615, pde B loss: 3.1402880549\n",
      "obs C loss: 1.9226122331, pde C loss: 0.5869041802\n",
      "obs D loss: 931.9601345062, pde D loss: 6.2610512599\n",
      "obs E loss: 110.5245749950, pde E loss: 3.5874280035\n",
      "obs F loss: 30.6843666434, pde F loss: 1.5649788659\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 69\n",
      "Training observations acc over epoch: 178.0161437988\n",
      "total loss: 1094.3073463440, total regularisd loss (sum of batches): 48148.7299194336\n",
      "obs A loss: 3.3278089762, pde A loss: 12.3985167295\n",
      "obs B loss: 11.1065495461, pde B loss: 3.3381816819\n",
      "obs C loss: 1.9366289265, pde C loss: 0.4938717280\n",
      "obs D loss: 913.6911888123, pde D loss: 4.9158395305\n",
      "obs E loss: 109.5092166662, pde E loss: 3.9024518728\n",
      "obs F loss: 28.5253171921, pde F loss: 1.1617793664\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 175.4575195312\n",
      "total loss: 1078.8792152405, total regularisd loss (sum of batches): 47464.9178466797\n",
      "obs A loss: 3.2904714644, pde A loss: 12.4683513343\n",
      "obs B loss: 11.1040548980, pde B loss: 3.7517217174\n",
      "obs C loss: 1.9084805679, pde C loss: 0.4568232000\n",
      "obs D loss: 901.0019950867, pde D loss: 4.3313866258\n",
      "obs E loss: 108.7342442274, pde E loss: 4.2242030799\n",
      "obs F loss: 26.7056205869, pde F loss: 0.9018691871\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 71\n",
      "Training observations acc over epoch: 173.6544952393\n",
      "total loss: 1068.1028060913, total regularisd loss (sum of batches): 46999.6928710938\n",
      "obs A loss: 3.2578379288, pde A loss: 11.9909902662\n",
      "obs B loss: 11.0973290503, pde B loss: 4.0429881737\n",
      "obs C loss: 1.9086422212, pde C loss: 0.5116390120\n",
      "obs D loss: 892.5799942017, pde D loss: 4.4235785902\n",
      "obs E loss: 108.2321321964, pde E loss: 4.3917038888\n",
      "obs F loss: 24.8509833813, pde F loss: 0.8149876716\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 72\n",
      "Training observations acc over epoch: 172.0769348145\n",
      "total loss: 1057.9966621399, total regularisd loss (sum of batches): 46551.2686157227\n",
      "obs A loss: 3.2845453992, pde A loss: 11.2628639340\n",
      "obs B loss: 11.1206389815, pde B loss: 4.5248212665\n",
      "obs C loss: 1.9020304494, pde C loss: 0.5665065888\n",
      "obs D loss: 885.1107749939, pde D loss: 3.9363871254\n",
      "obs E loss: 107.7578735352, pde E loss: 4.5093534142\n",
      "obs F loss: 23.2858808637, pde F loss: 0.7349850358\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.53s\n",
      "\n",
      "Start of epoch 73\n",
      "Training observations acc over epoch: 171.2560272217\n",
      "total loss: 1055.1444129944, total regularisd loss (sum of batches): 46425.9633178711\n",
      "obs A loss: 3.3505446240, pde A loss: 11.2692427188\n",
      "obs B loss: 11.0863484144, pde B loss: 4.8877577931\n",
      "obs C loss: 1.8997646663, pde C loss: 0.6290909890\n",
      "obs D loss: 881.7941455841, pde D loss: 5.4153526649\n",
      "obs E loss: 107.4919285774, pde E loss: 4.6507652923\n",
      "obs F loss: 21.9132471681, pde F loss: 0.7562249387\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 74\n",
      "Training observations acc over epoch: 170.1707611084\n",
      "total loss: 1045.0220298767, total regularisd loss (sum of batches): 45983.6868286133\n",
      "obs A loss: 3.3659410179, pde A loss: 10.1993611753\n",
      "obs B loss: 11.1146327108, pde B loss: 4.9781904370\n",
      "obs C loss: 1.9029015265, pde C loss: 0.5826444468\n",
      "obs D loss: 877.0720233917, pde D loss: 3.1860254556\n",
      "obs E loss: 107.2777758837, pde E loss: 4.2892416865\n",
      "obs F loss: 20.2912652791, pde F loss: 0.7620175146\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 75\n",
      "Training observations acc over epoch: 169.4999084473\n",
      "total loss: 1043.2106571198, total regularisd loss (sum of batches): 45902.1765136719\n",
      "obs A loss: 3.3040020019, pde A loss: 10.9371961206\n",
      "obs B loss: 11.1481632143, pde B loss: 4.9634704441\n",
      "obs C loss: 1.9010758772, pde C loss: 0.5999921225\n",
      "obs D loss: 874.4959926605, pde D loss: 4.4688616246\n",
      "obs E loss: 107.1715326309, pde E loss: 4.5342717692\n",
      "obs F loss: 18.9785542786, pde F loss: 0.7075593648\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 76\n",
      "Training observations acc over epoch: 169.0669403076\n",
      "total loss: 1038.0698299408, total regularisd loss (sum of batches): 45677.2080078125\n",
      "obs A loss: 3.2807655036, pde A loss: 10.0599957854\n",
      "obs B loss: 11.1752067506, pde B loss: 4.8131350130\n",
      "obs C loss: 1.8989935089, pde C loss: 0.5743682450\n",
      "obs D loss: 873.0326156616, pde D loss: 3.3519217931\n",
      "obs E loss: 107.0232791901, pde E loss: 4.2701290101\n",
      "obs F loss: 17.9908079207, pde F loss: 0.5986107532\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 77\n",
      "Training observations acc over epoch: 168.8872375488\n",
      "total loss: 1040.3073196411, total regularisd loss (sum of batches): 45779.2308349609\n",
      "obs A loss: 3.2449806482, pde A loss: 10.8074648529\n",
      "obs B loss: 11.1883942336, pde B loss: 4.7206297293\n",
      "obs C loss: 1.8944631610, pde C loss: 0.6352369897\n",
      "obs D loss: 872.7594604492, pde D loss: 5.6814958900\n",
      "obs E loss: 106.9936161041, pde E loss: 4.5857884586\n",
      "obs F loss: 17.2423700988, pde F loss: 0.5534160677\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 78\n",
      "Training observations acc over epoch: 168.4570770264\n",
      "total loss: 1037.5111579895, total regularisd loss (sum of batches): 45651.2429199219\n",
      "obs A loss: 3.2126396596, pde A loss: 11.0039021522\n",
      "obs B loss: 11.2000716925, pde B loss: 4.4754950851\n",
      "obs C loss: 1.8935516756, pde C loss: 0.6281658281\n",
      "obs D loss: 870.8795661926, pde D loss: 5.7698479369\n",
      "obs E loss: 106.9241726398, pde E loss: 4.3851783127\n",
      "obs F loss: 16.6324482560, pde F loss: 0.5061081545\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 79\n",
      "Training observations acc over epoch: 167.4114837646\n",
      "total loss: 1028.1733665466, total regularisd loss (sum of batches): 45243.8691406250\n",
      "obs A loss: 3.2024397478, pde A loss: 10.1928503364\n",
      "obs B loss: 11.1785111725, pde B loss: 4.3451279402\n",
      "obs C loss: 1.8935284093, pde C loss: 0.6380448872\n",
      "obs D loss: 865.3412094116, pde D loss: 3.6756302454\n",
      "obs E loss: 106.8032286167, pde E loss: 4.4144933224\n",
      "obs F loss: 16.0498031080, pde F loss: 0.4384969422\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.79s\n",
      "\n",
      "Start of epoch 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 167.0957946777\n",
      "total loss: 1024.8385887146, total regularisd loss (sum of batches): 45093.5573120117\n",
      "obs A loss: 3.1813613027, pde A loss: 9.6353645176\n",
      "obs B loss: 11.1774968207, pde B loss: 4.1555604041\n",
      "obs C loss: 1.8924681209, pde C loss: 0.6653889110\n",
      "obs D loss: 864.2107849121, pde D loss: 3.2478316277\n",
      "obs E loss: 106.5856587887, pde E loss: 4.1407566145\n",
      "obs F loss: 15.5272216499, pde F loss: 0.4186888225\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 81\n",
      "Training observations acc over epoch: 166.2180328369\n",
      "total loss: 1019.2479572296, total regularisd loss (sum of batches): 44848.0799560547\n",
      "obs A loss: 3.1854154691, pde A loss: 9.8636666536\n",
      "obs B loss: 11.1742257029, pde B loss: 4.0723819435\n",
      "obs C loss: 1.8919868879, pde C loss: 0.7287296308\n",
      "obs D loss: 859.4679813385, pde D loss: 2.6044177264\n",
      "obs E loss: 106.6164804697, pde E loss: 4.2553898618\n",
      "obs F loss: 14.9722265005, pde F loss: 0.4150600485\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 82\n",
      "Training observations acc over epoch: 166.0148468018\n",
      "total loss: 1017.8831043243, total regularisd loss (sum of batches): 44785.4836425781\n",
      "obs A loss: 3.2154577896, pde A loss: 9.7706370801\n",
      "obs B loss: 11.1603413522, pde B loss: 3.8076508641\n",
      "obs C loss: 1.8930065297, pde C loss: 0.7119537527\n",
      "obs D loss: 858.6459922791, pde D loss: 3.0154970810\n",
      "obs E loss: 106.6255809069, pde E loss: 4.0776750371\n",
      "obs F loss: 14.5488390326, pde F loss: 0.4104774850\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 83\n",
      "Training observations acc over epoch: 165.6565704346\n",
      "total loss: 1015.7776279449, total regularisd loss (sum of batches): 44692.7239990234\n",
      "obs A loss: 3.2080084831, pde A loss: 9.9989458621\n",
      "obs B loss: 11.1721172929, pde B loss: 3.4519382492\n",
      "obs C loss: 1.8927289564, pde C loss: 0.6790797636\n",
      "obs D loss: 856.9758090973, pde D loss: 3.2372181639\n",
      "obs E loss: 106.5923233032, pde E loss: 4.0382781774\n",
      "obs F loss: 14.0985514820, pde F loss: 0.4326240253\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 84\n",
      "Training observations acc over epoch: 165.4177093506\n",
      "total loss: 1014.9078044891, total regularisd loss (sum of batches): 44656.4069213867\n",
      "obs A loss: 3.2574657649, pde A loss: 9.8626573384\n",
      "obs B loss: 11.1359847933, pde B loss: 3.3124243096\n",
      "obs C loss: 1.8924656939, pde C loss: 0.6674061548\n",
      "obs D loss: 855.8364200592, pde D loss: 4.1165272743\n",
      "obs E loss: 106.5523791313, pde E loss: 4.0100052506\n",
      "obs F loss: 13.8315567970, pde F loss: 0.4325078269\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.40s\n",
      "\n",
      "Start of epoch 85\n",
      "Training observations acc over epoch: 164.8725891113\n",
      "total loss: 1011.4026165009, total regularisd loss (sum of batches): 44502.7030029297\n",
      "obs A loss: 3.2410134524, pde A loss: 10.2933000326\n",
      "obs B loss: 11.0994063467, pde B loss: 3.2444750518\n",
      "obs C loss: 1.8927599378, pde C loss: 0.6124464925\n",
      "obs D loss: 852.9151477814, pde D loss: 3.8072591461\n",
      "obs E loss: 106.4992015362, pde E loss: 3.7745418698\n",
      "obs F loss: 13.5879098177, pde F loss: 0.4351504571\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.67s\n",
      "\n",
      "Start of epoch 86\n",
      "Training observations acc over epoch: 164.5430297852\n",
      "total loss: 1008.5707588196, total regularisd loss (sum of batches): 44378.9503784180\n",
      "obs A loss: 3.2436364740, pde A loss: 9.9557154179\n",
      "obs B loss: 11.0570559204, pde B loss: 3.0334600098\n",
      "obs C loss: 1.8944924697, pde C loss: 0.6036707098\n",
      "obs D loss: 851.2812595367, pde D loss: 3.7339873612\n",
      "obs E loss: 106.4628815651, pde E loss: 3.5354782343\n",
      "obs F loss: 13.3188380897, pde F loss: 0.4502727091\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.73s\n",
      "\n",
      "Start of epoch 87\n",
      "Training observations acc over epoch: 164.5272216797\n",
      "total loss: 1010.4880580902, total regularisd loss (sum of batches): 44461.3544921875\n",
      "obs A loss: 3.2568642870, pde A loss: 10.8651282191\n",
      "obs B loss: 11.0400510877, pde B loss: 3.0152334906\n",
      "obs C loss: 1.8973448314, pde C loss: 0.6025087619\n",
      "obs D loss: 851.2713890076, pde D loss: 4.6966978945\n",
      "obs E loss: 106.5631964207, pde E loss: 3.7072320431\n",
      "obs F loss: 13.1346851289, pde F loss: 0.4377327655\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 88\n",
      "Training observations acc over epoch: 164.1407165527\n",
      "total loss: 1007.1814689636, total regularisd loss (sum of batches): 44310.1992187500\n",
      "obs A loss: 3.2794598341, pde A loss: 10.3667928427\n",
      "obs B loss: 11.0455610156, pde B loss: 2.8436710387\n",
      "obs C loss: 1.8955600504, pde C loss: 0.5693187825\n",
      "obs D loss: 849.3650569916, pde D loss: 4.5944888219\n",
      "obs E loss: 106.3757658005, pde E loss: 3.5168942958\n",
      "obs F loss: 12.8830860555, pde F loss: 0.4458047375\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 89\n",
      "Training observations acc over epoch: 163.7668609619\n",
      "total loss: 1003.3182258606, total regularisd loss (sum of batches): 44142.6917114258\n",
      "obs A loss: 3.2780623436, pde A loss: 9.9985329360\n",
      "obs B loss: 11.0220563859, pde B loss: 2.7310045213\n",
      "obs C loss: 1.8951242100, pde C loss: 0.5564189106\n",
      "obs D loss: 847.3119201660, pde D loss: 3.6837550327\n",
      "obs E loss: 106.4573186636, pde E loss: 3.3011266217\n",
      "obs F loss: 12.6367661059, pde F loss: 0.4461409384\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.67s\n",
      "\n",
      "Start of epoch 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 163.9531860352\n",
      "total loss: 1008.3368263245, total regularisd loss (sum of batches): 44360.2069702148\n",
      "obs A loss: 3.3035460562, pde A loss: 12.5589570254\n",
      "obs B loss: 11.0204028636, pde B loss: 3.0334825665\n",
      "obs C loss: 1.8935011476, pde C loss: 0.6294225715\n",
      "obs D loss: 848.7059936523, pde D loss: 3.9025739431\n",
      "obs E loss: 106.2912528515, pde E loss: 4.0437146798\n",
      "obs F loss: 12.5043597519, pde F loss: 0.4496151544\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 91\n",
      "Training observations acc over epoch: 163.5015716553\n",
      "total loss: 1003.2618331909, total regularisd loss (sum of batches): 44149.0148315430\n",
      "obs A loss: 3.2898700982, pde A loss: 10.6669713408\n",
      "obs B loss: 10.9870311618, pde B loss: 2.5533509143\n",
      "obs C loss: 1.8960637636, pde C loss: 0.5264846627\n",
      "obs D loss: 845.9710197449, pde D loss: 4.7792996317\n",
      "obs E loss: 106.4717499018, pde E loss: 3.2658652812\n",
      "obs F loss: 12.3937225938, pde F loss: 0.4603874143\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 92\n",
      "Training observations acc over epoch: 163.3235626221\n",
      "total loss: 1001.8670196533, total regularisd loss (sum of batches): 44079.1583862305\n",
      "obs A loss: 3.2795569003, pde A loss: 10.5243541151\n",
      "obs B loss: 10.9619150609, pde B loss: 2.4734518006\n",
      "obs C loss: 1.8938873857, pde C loss: 0.5388301350\n",
      "obs D loss: 845.4567165375, pde D loss: 4.7464690059\n",
      "obs E loss: 106.2386829853, pde E loss: 3.1802749746\n",
      "obs F loss: 12.1107681990, pde F loss: 0.4621174084\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 93\n",
      "Training observations acc over epoch: 163.2025451660\n",
      "total loss: 1000.9383678436, total regularisd loss (sum of batches): 44038.9339599609\n",
      "obs A loss: 3.2989686057, pde A loss: 11.5229664445\n",
      "obs B loss: 10.9414780438, pde B loss: 2.4962344654\n",
      "obs C loss: 1.8916162234, pde C loss: 0.5411533574\n",
      "obs D loss: 844.8705902100, pde D loss: 3.4642270468\n",
      "obs E loss: 106.2952384949, pde E loss: 3.2090045474\n",
      "obs F loss: 11.9175236523, pde F loss: 0.4893609453\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 94\n",
      "Training observations acc over epoch: 162.8082733154\n",
      "total loss: 996.3346138000, total regularisd loss (sum of batches): 43836.6033325195\n",
      "obs A loss: 3.2897394449, pde A loss: 10.3079765290\n",
      "obs B loss: 10.8995357901, pde B loss: 2.2880769968\n",
      "obs C loss: 1.8915675487, pde C loss: 0.4907270940\n",
      "obs D loss: 842.7085895538, pde D loss: 3.0677535310\n",
      "obs E loss: 106.3313506842, pde E loss: 2.8447140679\n",
      "obs F loss: 11.7289087474, pde F loss: 0.4856735179\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 95\n",
      "Training observations acc over epoch: 162.5418853760\n",
      "total loss: 998.9077491760, total regularisd loss (sum of batches): 43953.3540649414\n",
      "obs A loss: 3.2956288233, pde A loss: 11.8260866404\n",
      "obs B loss: 10.8880282193, pde B loss: 2.4462737888\n",
      "obs C loss: 1.8939516321, pde C loss: 0.5430685747\n",
      "obs D loss: 841.4364700317, pde D loss: 4.7854761556\n",
      "obs E loss: 106.2608032227, pde E loss: 3.5512784384\n",
      "obs F loss: 11.4765432179, pde F loss: 0.5041325446\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 96\n",
      "Training observations acc over epoch: 163.2789154053\n",
      "total loss: 1012.7681407928, total regularisd loss (sum of batches): 44559.3923339844\n",
      "obs A loss: 3.4179999977, pde A loss: 18.5035489649\n",
      "obs B loss: 10.9359237105, pde B loss: 3.2243177257\n",
      "obs C loss: 1.8965135552, pde C loss: 0.7358668167\n",
      "obs D loss: 845.1484928131, pde D loss: 5.0782433636\n",
      "obs E loss: 106.4596790075, pde E loss: 4.9668428749\n",
      "obs F loss: 11.8148343265, pde F loss: 0.5858786860\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 97\n",
      "Training observations acc over epoch: 162.5971374512\n",
      "total loss: 996.2709026337, total regularisd loss (sum of batches): 43840.2966918945\n",
      "obs A loss: 3.3442736715, pde A loss: 11.3763060123\n",
      "obs B loss: 10.8932863027, pde B loss: 2.1387331896\n",
      "obs C loss: 1.8930539042, pde C loss: 0.4839379499\n",
      "obs D loss: 841.6821308136, pde D loss: 3.3801172562\n",
      "obs E loss: 106.2732238770, pde E loss: 2.8397421949\n",
      "obs F loss: 11.4968530089, pde F loss: 0.4692420084\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.35s\n",
      "\n",
      "Start of epoch 98\n",
      "Training observations acc over epoch: 162.0750274658\n",
      "total loss: 989.7508277893, total regularisd loss (sum of batches): 43549.1287841797\n",
      "obs A loss: 3.3160428479, pde A loss: 9.4732138813\n",
      "obs B loss: 10.8436014056, pde B loss: 1.9000098109\n",
      "obs C loss: 1.8915118948, pde C loss: 0.4467585133\n",
      "obs D loss: 838.9493541718, pde D loss: 2.5713575408\n",
      "obs E loss: 106.3244605064, pde E loss: 2.4309976883\n",
      "obs F loss: 11.1253899783, pde F loss: 0.4781366624\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.28s\n",
      "\n",
      "Start of epoch 99\n",
      "Training observations acc over epoch: 161.9860839844\n",
      "total loss: 990.8186531067, total regularisd loss (sum of batches): 43593.1089477539\n",
      "obs A loss: 3.2999641821, pde A loss: 10.4661258906\n",
      "obs B loss: 10.8226467073, pde B loss: 1.9529153332\n",
      "obs C loss: 1.8905679770, pde C loss: 0.4935681010\n",
      "obs D loss: 838.7315998077, pde D loss: 2.6553623900\n",
      "obs E loss: 106.2119542360, pde E loss: 2.8457306176\n",
      "obs F loss: 10.9597683996, pde F loss: 0.4884401755\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 161.9304962158\n",
      "total loss: 994.4847850800, total regularisd loss (sum of batches): 43755.7393188477\n",
      "obs A loss: 3.2968653589, pde A loss: 12.8158820122\n",
      "obs B loss: 10.7975380123, pde B loss: 2.2030059472\n",
      "obs C loss: 1.8936347198, pde C loss: 0.5680120373\n",
      "obs D loss: 838.3590183258, pde D loss: 3.2663586736\n",
      "obs E loss: 106.3957209587, pde E loss: 3.5405750610\n",
      "obs F loss: 10.8402271420, pde F loss: 0.5079637589\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 101\n",
      "Training observations acc over epoch: 170.9565734863\n",
      "total loss: 1228.9525413513, total regularisd loss (sum of batches): 54071.1619262695\n",
      "obs A loss: 3.8388810344, pde A loss: 133.5239180475\n",
      "obs B loss: 10.9487239420, pde B loss: 13.0682352893\n",
      "obs C loss: 2.1172378082, pde C loss: 3.8065811647\n",
      "obs D loss: 883.1126499176, pde D loss: 21.9374802113\n",
      "obs E loss: 110.0439190865, pde E loss: 26.9705096185\n",
      "obs F loss: 15.6782177985, pde F loss: 3.9061902985\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.76s\n",
      "\n",
      "Start of epoch 102\n",
      "Training observations acc over epoch: 183.2661285400\n",
      "total loss: 1135.5948028564, total regularisd loss (sum of batches): 49957.3660888672\n",
      "obs A loss: 4.7571276426, pde A loss: 17.4594284594\n",
      "obs B loss: 11.3143957704, pde B loss: 3.3988335617\n",
      "obs C loss: 2.1047287602, pde C loss: 0.8716428960\n",
      "obs D loss: 940.8530998230, pde D loss: 7.6611068621\n",
      "obs E loss: 116.3374938965, pde E loss: 4.2674475051\n",
      "obs F loss: 24.2299569249, pde F loss: 2.3395323455\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 103\n",
      "Training observations acc over epoch: 173.1754608154\n",
      "total loss: 1061.9561443329, total regularisd loss (sum of batches): 46723.5904541016\n",
      "obs A loss: 3.8607142568, pde A loss: 12.3242337853\n",
      "obs B loss: 10.9545790255, pde B loss: 2.2223459072\n",
      "obs C loss: 1.9266706724, pde C loss: 0.5905031739\n",
      "obs D loss: 892.0065994263, pde D loss: 4.9431353211\n",
      "obs E loss: 111.4774777889, pde E loss: 2.1046002265\n",
      "obs F loss: 18.8267052770, pde F loss: 0.7185874525\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 104\n",
      "Training observations acc over epoch: 168.9679718018\n",
      "total loss: 1037.6487236023, total regularisd loss (sum of batches): 45653.9752197266\n",
      "obs A loss: 3.7899419516, pde A loss: 12.1181474179\n",
      "obs B loss: 10.7756549418, pde B loss: 2.3673660681\n",
      "obs C loss: 1.9003798179, pde C loss: 0.6043252852\n",
      "obs D loss: 871.8739337921, pde D loss: 5.8203233406\n",
      "obs E loss: 109.0517358780, pde E loss: 2.4862226211\n",
      "obs F loss: 16.4162021875, pde F loss: 0.4444907284\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 105\n",
      "Training observations acc over epoch: 166.6958770752\n",
      "total loss: 1023.7358684540, total regularisd loss (sum of batches): 45049.2164306641\n",
      "obs A loss: 3.7786928043, pde A loss: 11.2685142308\n",
      "obs B loss: 10.6989460886, pde B loss: 2.5995267443\n",
      "obs C loss: 1.8839693908, pde C loss: 0.5622083060\n",
      "obs D loss: 860.8680877686, pde D loss: 5.7146511376\n",
      "obs E loss: 107.9274418354, pde E loss: 3.0207193531\n",
      "obs F loss: 15.0183317065, pde F loss: 0.3947764705\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 106\n",
      "Training observations acc over epoch: 165.3971710205\n",
      "total loss: 1013.8613109589, total regularisd loss (sum of batches): 44611.7069702148\n",
      "obs A loss: 3.7445046008, pde A loss: 10.8781381994\n",
      "obs B loss: 10.6634976417, pde B loss: 2.6979833804\n",
      "obs C loss: 1.8923601136, pde C loss: 0.4768917318\n",
      "obs D loss: 854.6524085999, pde D loss: 4.1073189154\n",
      "obs E loss: 107.2910072803, pde E loss: 2.9190693833\n",
      "obs F loss: 14.1391386092, pde F loss: 0.3990012184\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 107\n",
      "Training observations acc over epoch: 164.7023773193\n",
      "total loss: 1009.6241512299, total regularisd loss (sum of batches): 44420.0276489258\n",
      "obs A loss: 3.6960972771, pde A loss: 10.4076788872\n",
      "obs B loss: 10.7076632529, pde B loss: 2.7707651183\n",
      "obs C loss: 1.8963926006, pde C loss: 0.4473760314\n",
      "obs D loss: 851.5550308228, pde D loss: 4.5065357536\n",
      "obs E loss: 107.0193320513, pde E loss: 2.8096959665\n",
      "obs F loss: 13.3398757279, pde F loss: 0.4677089574\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 108\n",
      "Training observations acc over epoch: 163.9029388428\n",
      "total loss: 1003.7238540649, total regularisd loss (sum of batches): 44160.4014282227\n",
      "obs A loss: 3.6473238915, pde A loss: 10.6534273177\n",
      "obs B loss: 10.6806383580, pde B loss: 2.6856142431\n",
      "obs C loss: 1.8970116638, pde C loss: 0.4436230026\n",
      "obs D loss: 847.8754329681, pde D loss: 3.5522491299\n",
      "obs E loss: 106.6795125008, pde E loss: 2.5404655822\n",
      "obs F loss: 12.6378003061, pde F loss: 0.4307519803\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 109\n",
      "Training observations acc over epoch: 163.2606048584\n",
      "total loss: 998.7530002594, total regularisd loss (sum of batches): 43947.5234985352\n",
      "obs A loss: 3.5897351876, pde A loss: 9.6692699343\n",
      "obs B loss: 10.7084492892, pde B loss: 2.4671179876\n",
      "obs C loss: 1.9075419400, pde C loss: 0.4882112676\n",
      "obs D loss: 844.4211406708, pde D loss: 3.4077919163\n",
      "obs E loss: 106.7244532108, pde E loss: 2.6628939658\n",
      "obs F loss: 12.2122922540, pde F loss: 0.4940925399\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.36s\n",
      "\n",
      "Start of epoch 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 163.1923065186\n",
      "total loss: 999.5558872223, total regularisd loss (sum of batches): 43980.0850830078\n",
      "obs A loss: 3.5389176309, pde A loss: 10.2621365041\n",
      "obs B loss: 10.7004379481, pde B loss: 2.4191618562\n",
      "obs C loss: 1.9120355137, pde C loss: 0.4825000400\n",
      "obs D loss: 844.4753189087, pde D loss: 4.0892915614\n",
      "obs E loss: 106.5893596411, pde E loss: 2.6464479454\n",
      "obs F loss: 11.9376906008, pde F loss: 0.5025894232\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 111\n",
      "Training observations acc over epoch: 162.5249938965\n",
      "total loss: 994.4552555084, total regularisd loss (sum of batches): 43765.2066650391\n",
      "obs A loss: 3.5009365603, pde A loss: 9.4170990586\n",
      "obs B loss: 10.6648639143, pde B loss: 2.3314222954\n",
      "obs C loss: 1.9059175663, pde C loss: 0.4759305138\n",
      "obs D loss: 840.8824758530, pde D loss: 3.8883987628\n",
      "obs E loss: 106.5672228336, pde E loss: 2.6892106943\n",
      "obs F loss: 11.6286568493, pde F loss: 0.5031137243\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 112\n",
      "Training observations acc over epoch: 162.4564514160\n",
      "total loss: 994.0093879700, total regularisd loss (sum of batches): 43739.5062866211\n",
      "obs A loss: 3.4640612975, pde A loss: 9.5927359760\n",
      "obs B loss: 10.6244637072, pde B loss: 2.3677425720\n",
      "obs C loss: 1.8964555208, pde C loss: 0.4567825571\n",
      "obs D loss: 840.7573394775, pde D loss: 3.7616518475\n",
      "obs E loss: 106.5380206108, pde E loss: 2.6128596738\n",
      "obs F loss: 11.4584262073, pde F loss: 0.4788521631\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 113\n",
      "Training observations acc over epoch: 162.5357818604\n",
      "total loss: 995.6245555878, total regularisd loss (sum of batches): 43802.1223144531\n",
      "obs A loss: 3.4459121078, pde A loss: 9.7776725888\n",
      "obs B loss: 10.6048122793, pde B loss: 2.2798785232\n",
      "obs C loss: 1.8924009111, pde C loss: 0.4589210590\n",
      "obs D loss: 841.4699783325, pde D loss: 4.8354485147\n",
      "obs E loss: 106.5232183933, pde E loss: 2.5577368774\n",
      "obs F loss: 11.2782201022, pde F loss: 0.5003509661\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 114\n",
      "Training observations acc over epoch: 162.1575164795\n",
      "total loss: 991.9245223999, total regularisd loss (sum of batches): 43646.1525268555\n",
      "obs A loss: 3.4228446409, pde A loss: 9.7933109552\n",
      "obs B loss: 10.5680682659, pde B loss: 2.2472347543\n",
      "obs C loss: 1.8885609321, pde C loss: 0.4400581354\n",
      "obs D loss: 839.5142822266, pde D loss: 3.6078954786\n",
      "obs E loss: 106.4598587751, pde E loss: 2.4128741883\n",
      "obs F loss: 11.0914925337, pde F loss: 0.4780400768\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 115\n",
      "Training observations acc over epoch: 162.2042083740\n",
      "total loss: 994.4860897064, total regularisd loss (sum of batches): 43757.6038208008\n",
      "obs A loss: 3.4030588418, pde A loss: 10.6178512424\n",
      "obs B loss: 10.5554875880, pde B loss: 2.2904619165\n",
      "obs C loss: 1.8880275339, pde C loss: 0.4738618489\n",
      "obs D loss: 839.7792358398, pde D loss: 4.6967388242\n",
      "obs E loss: 106.6263945103, pde E loss: 2.6718385406\n",
      "obs F loss: 10.9728720039, pde F loss: 0.5102718025\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.86s\n",
      "\n",
      "Start of epoch 116\n",
      "Training observations acc over epoch: 161.7704925537\n",
      "total loss: 988.9848003387, total regularisd loss (sum of batches): 43513.0582275391\n",
      "obs A loss: 3.3691605777, pde A loss: 10.0434202701\n",
      "obs B loss: 10.5387953371, pde B loss: 2.1253491826\n",
      "obs C loss: 1.8868809398, pde C loss: 0.4389253184\n",
      "obs D loss: 837.6195220947, pde D loss: 2.9115481526\n",
      "obs E loss: 106.3494989872, pde E loss: 2.3485445641\n",
      "obs F loss: 10.8592340648, pde F loss: 0.4939228222\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.80s\n",
      "\n",
      "Start of epoch 117\n",
      "Training observations acc over epoch: 161.6123962402\n",
      "total loss: 990.0947513580, total regularisd loss (sum of batches): 43569.0857543945\n",
      "obs A loss: 3.3553153798, pde A loss: 10.7140380889\n",
      "obs B loss: 10.4973979592, pde B loss: 2.1293590181\n",
      "obs C loss: 1.8865682073, pde C loss: 0.4606191255\n",
      "obs D loss: 836.8238906860, pde D loss: 4.0536040254\n",
      "obs E loss: 106.4196119308, pde E loss: 2.5736931562\n",
      "obs F loss: 10.6916553378, pde F loss: 0.4889952112\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.94s\n",
      "\n",
      "Start of epoch 118\n",
      "Training observations acc over epoch: 161.3270263672\n",
      "total loss: 987.4789581299, total regularisd loss (sum of batches): 43447.6800537109\n",
      "obs A loss: 3.3475516289, pde A loss: 10.3999425769\n",
      "obs B loss: 10.4654455632, pde B loss: 2.0599773303\n",
      "obs C loss: 1.8869759962, pde C loss: 0.4600759614\n",
      "obs D loss: 835.3299150467, pde D loss: 3.5517574511\n",
      "obs E loss: 106.3928631544, pde E loss: 2.5808845200\n",
      "obs F loss: 10.5396261215, pde F loss: 0.4639290404\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.77s\n",
      "\n",
      "Start of epoch 119\n",
      "Training observations acc over epoch: 161.2041625977\n",
      "total loss: 985.1121273041, total regularisd loss (sum of batches): 43344.2122192383\n",
      "obs A loss: 3.3429259360, pde A loss: 9.6064263582\n",
      "obs B loss: 10.4265905917, pde B loss: 1.9698042981\n",
      "obs C loss: 1.8859509863, pde C loss: 0.4275172986\n",
      "obs D loss: 834.7797489166, pde D loss: 3.1752265394\n",
      "obs E loss: 106.3931571245, pde E loss: 2.2486804388\n",
      "obs F loss: 10.3965201974, pde F loss: 0.4595822785\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 161.2167053223\n",
      "total loss: 989.0432720184, total regularisd loss (sum of batches): 43518.5072021484\n",
      "obs A loss: 3.3349595666, pde A loss: 10.9176454693\n",
      "obs B loss: 10.4055409431, pde B loss: 2.0294847898\n",
      "obs C loss: 1.8851738013, pde C loss: 0.4727079114\n",
      "obs D loss: 834.9005527496, pde D loss: 5.1577830240\n",
      "obs E loss: 106.4604353905, pde E loss: 2.7177384198\n",
      "obs F loss: 10.3136035353, pde F loss: 0.4476356492\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 121\n",
      "Training observations acc over epoch: 161.0585174561\n",
      "total loss: 985.6402854919, total regularisd loss (sum of batches): 43363.8297119141\n",
      "obs A loss: 3.2855541110, pde A loss: 10.4647914916\n",
      "obs B loss: 10.3542707860, pde B loss: 1.9504183903\n",
      "obs C loss: 1.8839592077, pde C loss: 0.4403655967\n",
      "obs D loss: 834.3995418549, pde D loss: 3.7490051910\n",
      "obs E loss: 106.2556350231, pde E loss: 2.2578745037\n",
      "obs F loss: 10.1721346080, pde F loss: 0.4267338868\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 122\n",
      "Training observations acc over epoch: 160.7705993652\n",
      "total loss: 985.2618274689, total regularisd loss (sum of batches): 43355.9789428711\n",
      "obs A loss: 3.2813240811, pde A loss: 11.1652810872\n",
      "obs B loss: 10.3335100114, pde B loss: 1.9669829570\n",
      "obs C loss: 1.8865452297, pde C loss: 0.4629159826\n",
      "obs D loss: 832.7610359192, pde D loss: 4.1700976603\n",
      "obs E loss: 106.3331239223, pde E loss: 2.4543732479\n",
      "obs F loss: 10.0280166268, pde F loss: 0.4186201748\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.53s\n",
      "\n",
      "Start of epoch 123\n",
      "Training observations acc over epoch: 160.7573394775\n",
      "total loss: 987.3183956146, total regularisd loss (sum of batches): 43441.5080566406\n",
      "obs A loss: 3.2714143842, pde A loss: 12.4873939753\n",
      "obs B loss: 10.3140162379, pde B loss: 1.9948745035\n",
      "obs C loss: 1.8862414919, pde C loss: 0.4735171944\n",
      "obs D loss: 832.8193855286, pde D loss: 4.6340992898\n",
      "obs E loss: 106.3938441277, pde E loss: 2.7295213379\n",
      "obs F loss: 9.8591828197, pde F loss: 0.4548901264\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 124\n",
      "Training observations acc over epoch: 160.9743957520\n",
      "total loss: 985.7838745117, total regularisd loss (sum of batches): 43371.7233886719\n",
      "obs A loss: 3.2854683623, pde A loss: 11.2886117250\n",
      "obs B loss: 10.3297878057, pde B loss: 1.9006739929\n",
      "obs C loss: 1.8845881596, pde C loss: 0.4416181785\n",
      "obs D loss: 834.3481912613, pde D loss: 3.4585949406\n",
      "obs E loss: 106.2248289585, pde E loss: 2.4008814618\n",
      "obs F loss: 9.7733184546, pde F loss: 0.4473114284\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 125\n",
      "Training observations acc over epoch: 160.8092193604\n",
      "total loss: 991.9995040894, total regularisd loss (sum of batches): 43643.7923583984\n",
      "obs A loss: 3.3080879301, pde A loss: 15.2671532035\n",
      "obs B loss: 10.3087109625, pde B loss: 2.3791413307\n",
      "obs C loss: 1.8833429553, pde C loss: 0.6395664234\n",
      "obs D loss: 833.2659721375, pde D loss: 4.5609849952\n",
      "obs E loss: 106.2924087048, pde E loss: 3.8711136207\n",
      "obs F loss: 9.7967555225, pde F loss: 0.4262666157\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 126\n",
      "Training observations acc over epoch: 160.4937286377\n",
      "total loss: 982.1229400635, total regularisd loss (sum of batches): 43208.9630737305\n",
      "obs A loss: 3.2944927663, pde A loss: 10.8534655422\n",
      "obs B loss: 10.3039533943, pde B loss: 1.7759792879\n",
      "obs C loss: 1.8856939077, pde C loss: 0.4241340365\n",
      "obs D loss: 831.4280586243, pde D loss: 3.2464743778\n",
      "obs E loss: 106.3991436958, pde E loss: 2.4560567141\n",
      "obs F loss: 9.6512381583, pde F loss: 0.4042505086\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 127\n",
      "Training observations acc over epoch: 160.2996826172\n",
      "total loss: 979.0081062317, total regularisd loss (sum of batches): 43077.5092163086\n",
      "obs A loss: 3.2731894031, pde A loss: 9.7596459538\n",
      "obs B loss: 10.2717919201, pde B loss: 1.6528540049\n",
      "obs C loss: 1.8878892977, pde C loss: 0.3735602642\n",
      "obs D loss: 830.5949726105, pde D loss: 3.1405469663\n",
      "obs E loss: 106.2733672857, pde E loss: 1.8957451601\n",
      "obs F loss: 9.4970191121, pde F loss: 0.3875230812\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 128\n",
      "Training observations acc over epoch: 160.4444580078\n",
      "total loss: 984.2839355469, total regularisd loss (sum of batches): 43313.2078247070\n",
      "obs A loss: 3.2667749971, pde A loss: 11.7163116783\n",
      "obs B loss: 10.2704777867, pde B loss: 1.9113168605\n",
      "obs C loss: 1.8865827546, pde C loss: 0.4381745313\n",
      "obs D loss: 831.5838413239, pde D loss: 4.5719267353\n",
      "obs E loss: 106.2440582514, pde E loss: 2.5777217299\n",
      "obs F loss: 9.4150744528, pde F loss: 0.4016756518\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 129\n",
      "Training observations acc over epoch: 160.3278656006\n",
      "total loss: 989.5392112732, total regularisd loss (sum of batches): 43536.9518432617\n",
      "obs A loss: 3.3511772752, pde A loss: 16.2428413630\n",
      "obs B loss: 10.2778391838, pde B loss: 2.3074684888\n",
      "obs C loss: 1.8920626249, pde C loss: 0.6387192775\n",
      "obs D loss: 830.6724948883, pde D loss: 4.2927822098\n",
      "obs E loss: 106.2967462540, pde E loss: 3.6596377082\n",
      "obs F loss: 9.4768692553, pde F loss: 0.4305645060\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.23s\n",
      "\n",
      "Start of epoch 130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 160.5983581543\n",
      "total loss: 990.6482410431, total regularisd loss (sum of batches): 43590.3626708984\n",
      "obs A loss: 3.3944501206, pde A loss: 16.0044905990\n",
      "obs B loss: 10.2832103670, pde B loss: 2.3295393847\n",
      "obs C loss: 1.8845632393, pde C loss: 0.5552195031\n",
      "obs D loss: 832.2298545837, pde D loss: 4.4801956341\n",
      "obs E loss: 106.2789490223, pde E loss: 3.2897122465\n",
      "obs F loss: 9.5190686435, pde F loss: 0.3989876006\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.29s\n",
      "\n",
      "Start of epoch 131\n",
      "Training observations acc over epoch: 160.2909698486\n",
      "total loss: 982.5289115906, total regularisd loss (sum of batches): 43232.4026489258\n",
      "obs A loss: 3.3171011806, pde A loss: 11.4216159880\n",
      "obs B loss: 10.2347830087, pde B loss: 1.7447085455\n",
      "obs C loss: 1.8879110254, pde C loss: 0.4043035079\n",
      "obs D loss: 830.7270851135, pde D loss: 4.5795901194\n",
      "obs E loss: 106.2295492887, pde E loss: 2.2932181954\n",
      "obs F loss: 9.3492633402, pde F loss: 0.3397871153\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.35s\n",
      "\n",
      "Start of epoch 132\n",
      "Training observations acc over epoch: 159.8778381348\n",
      "total loss: 980.1711463928, total regularisd loss (sum of batches): 43133.2568969727\n",
      "obs A loss: 3.2760258690, pde A loss: 11.4025641680\n",
      "obs B loss: 10.2284202874, pde B loss: 1.7705328930\n",
      "obs C loss: 1.8912372217, pde C loss: 0.4016011786\n",
      "obs D loss: 828.4371194839, pde D loss: 4.8159603700\n",
      "obs E loss: 106.2238006592, pde E loss: 2.1427104212\n",
      "obs F loss: 9.2104892880, pde F loss: 0.3706885329\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.39s\n",
      "\n",
      "Start of epoch 133\n",
      "Training observations acc over epoch: 159.7780151367\n",
      "total loss: 978.8355426788, total regularisd loss (sum of batches): 43065.5919189453\n",
      "obs A loss: 3.2486668229, pde A loss: 10.7675005198\n",
      "obs B loss: 10.2084249556, pde B loss: 1.7289845236\n",
      "obs C loss: 1.8900759537, pde C loss: 0.3839050638\n",
      "obs D loss: 827.9110298157, pde D loss: 4.9345822409\n",
      "obs E loss: 106.2820141315, pde E loss: 2.0280261114\n",
      "obs F loss: 9.1281019300, pde F loss: 0.3242182289\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.27s\n",
      "\n",
      "Start of epoch 134\n",
      "Training observations acc over epoch: 159.5170440674\n",
      "total loss: 974.1098747253, total regularisd loss (sum of batches): 42863.4457397461\n",
      "obs A loss: 3.2201522738, pde A loss: 9.7309987992\n",
      "obs B loss: 10.1894158721, pde B loss: 1.6426684950\n",
      "obs C loss: 1.8951647207, pde C loss: 0.3531223857\n",
      "obs D loss: 826.5747776031, pde D loss: 3.2915462628\n",
      "obs E loss: 106.2157440186, pde E loss: 1.6851273663\n",
      "obs F loss: 9.0068543851, pde F loss: 0.3042960521\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 135\n",
      "Training observations acc over epoch: 159.4286346436\n",
      "total loss: 976.4242668152, total regularisd loss (sum of batches): 42958.6364135742\n",
      "obs A loss: 3.2163863257, pde A loss: 10.9052595049\n",
      "obs B loss: 10.1973584890, pde B loss: 1.7801719829\n",
      "obs C loss: 1.8985950388, pde C loss: 0.3989741448\n",
      "obs D loss: 826.1162071228, pde D loss: 4.4665441662\n",
      "obs E loss: 106.2280099392, pde E loss: 1.9940438382\n",
      "obs F loss: 8.9153333604, pde F loss: 0.3073846381\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 136\n",
      "Training observations acc over epoch: 159.1644287109\n",
      "total loss: 977.6442756653, total regularisd loss (sum of batches): 43019.2380981445\n",
      "obs A loss: 3.2510222718, pde A loss: 13.6685748100\n",
      "obs B loss: 10.1795643270, pde B loss: 2.2854417507\n",
      "obs C loss: 1.8959152959, pde C loss: 0.5139704589\n",
      "obs D loss: 824.5257873535, pde D loss: 3.2355466671\n",
      "obs E loss: 106.2636954784, pde E loss: 2.6430195887\n",
      "obs F loss: 8.8706049025, pde F loss: 0.3111214554\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.21s\n",
      "\n",
      "Start of epoch 137\n",
      "Training observations acc over epoch: 159.1872253418\n",
      "total loss: 979.0825557709, total regularisd loss (sum of batches): 43080.2297363281\n",
      "obs A loss: 3.2572037429, pde A loss: 13.7113834769\n",
      "obs B loss: 10.1715911478, pde B loss: 2.1907780915\n",
      "obs C loss: 1.8939480297, pde C loss: 0.4892920768\n",
      "obs D loss: 824.5622577667, pde D loss: 4.6704527475\n",
      "obs E loss: 106.3619394302, pde E loss: 2.5874544289\n",
      "obs F loss: 8.8763035387, pde F loss: 0.3099499471\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 138\n",
      "Training observations acc over epoch: 158.9751281738\n",
      "total loss: 972.3535041809, total regularisd loss (sum of batches): 42782.1618041992\n",
      "obs A loss: 3.2285222560, pde A loss: 11.2389571667\n",
      "obs B loss: 10.1494768411, pde B loss: 1.8614899796\n",
      "obs C loss: 1.8919486403, pde C loss: 0.3849333702\n",
      "obs D loss: 823.5556221008, pde D loss: 2.9127569646\n",
      "obs E loss: 106.2511355877, pde E loss: 1.8219592050\n",
      "obs F loss: 8.7739984393, pde F loss: 0.2827043333\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 139\n",
      "Training observations acc over epoch: 169.5537719727\n",
      "total loss: 1384.5112380981, total regularisd loss (sum of batches): 60919.4632568359\n",
      "obs A loss: 4.0389009714, pde A loss: 249.6292143166\n",
      "obs B loss: 10.4609538913, pde B loss: 24.6600574553\n",
      "obs C loss: 2.3773562964, pde C loss: 5.0376880709\n",
      "obs D loss: 874.2500276566, pde D loss: 29.3950034007\n",
      "obs E loss: 109.6018048525, pde E loss: 45.3632474504\n",
      "obs F loss: 16.5934861898, pde F loss: 13.1034952141\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 186.2278442383\n",
      "total loss: 1184.2225914001, total regularisd loss (sum of batches): 52107.5021972656\n",
      "obs A loss: 5.0804557651, pde A loss: 21.8084228337\n",
      "obs B loss: 10.9147438854, pde B loss: 4.8070080802\n",
      "obs C loss: 2.4760176539, pde C loss: 2.6250036843\n",
      "obs D loss: 952.0403575897, pde D loss: 13.7480634600\n",
      "obs E loss: 117.7959616184, pde E loss: 10.4164544046\n",
      "obs F loss: 29.0594586730, pde F loss: 13.4506450966\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 141\n",
      "Training observations acc over epoch: 176.9323272705\n",
      "total loss: 1088.7940139771, total regularisd loss (sum of batches): 47909.8676147461\n",
      "obs A loss: 4.1339481100, pde A loss: 12.4193945527\n",
      "obs B loss: 10.6123358160, pde B loss: 1.7448528558\n",
      "obs C loss: 2.1927155219, pde C loss: 0.9778638901\n",
      "obs D loss: 908.3453369141, pde D loss: 5.8967179433\n",
      "obs E loss: 115.2443306446, pde E loss: 4.2306750454\n",
      "obs F loss: 21.0652429163, pde F loss: 1.9305975698\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.31s\n",
      "\n",
      "Start of epoch 142\n",
      "Training observations acc over epoch: 173.0889739990\n",
      "total loss: 1059.4793434143, total regularisd loss (sum of batches): 46623.7127075195\n",
      "obs A loss: 3.5881528184, pde A loss: 10.7845668793\n",
      "obs B loss: 10.4655713439, pde B loss: 1.5655783862\n",
      "obs C loss: 2.1161013059, pde C loss: 0.6173164984\n",
      "obs D loss: 890.8696269989, pde D loss: 4.2935716957\n",
      "obs E loss: 113.4097459316, pde E loss: 2.6078732014\n",
      "obs F loss: 18.0848334432, pde F loss: 1.0764013939\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 143\n",
      "Training observations acc over epoch: 170.9112243652\n",
      "total loss: 1046.1758766174, total regularisd loss (sum of batches): 46031.3526611328\n",
      "obs A loss: 3.3402892500, pde A loss: 9.8071123511\n",
      "obs B loss: 10.2982167751, pde B loss: 1.4819195494\n",
      "obs C loss: 1.9783256762, pde C loss: 0.5049455408\n",
      "obs D loss: 881.5676651001, pde D loss: 5.7398226559\n",
      "obs E loss: 111.9096084833, pde E loss: 2.4693498313\n",
      "obs F loss: 16.3731482923, pde F loss: 0.7054691277\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 144\n",
      "Training observations acc over epoch: 168.0083007812\n",
      "total loss: 1027.8306331635, total regularisd loss (sum of batches): 45223.8503417969\n",
      "obs A loss: 3.1466234252, pde A loss: 9.4338844866\n",
      "obs B loss: 10.1618615836, pde B loss: 1.3424139563\n",
      "obs C loss: 1.9177373759, pde C loss: 0.4321869081\n",
      "obs D loss: 867.0829830170, pde D loss: 5.7383138090\n",
      "obs E loss: 110.9767425060, pde E loss: 2.1978395469\n",
      "obs F loss: 14.7638786435, pde F loss: 0.6361676063\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 145\n",
      "Training observations acc over epoch: 166.2476348877\n",
      "total loss: 1016.2001495361, total regularisd loss (sum of batches): 44709.0809326172\n",
      "obs A loss: 3.0242433175, pde A loss: 9.1239390224\n",
      "obs B loss: 10.1886955649, pde B loss: 1.4896074645\n",
      "obs C loss: 1.9006289486, pde C loss: 0.4294299018\n",
      "obs D loss: 858.9897499084, pde D loss: 5.2972357124\n",
      "obs E loss: 109.8823649883, pde E loss: 1.8819285408\n",
      "obs F loss: 13.5003663898, pde F loss: 0.4919628724\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 146\n",
      "Training observations acc over epoch: 165.1157226562\n",
      "total loss: 1008.7777919769, total regularisd loss (sum of batches): 44385.0310668945\n",
      "obs A loss: 2.9231473766, pde A loss: 8.8553729057\n",
      "obs B loss: 10.0113538802, pde B loss: 1.7651024014\n",
      "obs C loss: 1.8959682006, pde C loss: 0.4052314018\n",
      "obs D loss: 854.0462303162, pde D loss: 4.8961350881\n",
      "obs E loss: 109.2529329062, pde E loss: 1.8116329759\n",
      "obs F loss: 12.5646688640, pde F loss: 0.3500093571\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 147\n",
      "Training observations acc over epoch: 163.9800567627\n",
      "total loss: 1001.6804809570, total regularisd loss (sum of batches): 44068.2459716797\n",
      "obs A loss: 2.8790853955, pde A loss: 8.9081436247\n",
      "obs B loss: 9.8829568923, pde B loss: 1.7735868860\n",
      "obs C loss: 1.9021780360, pde C loss: 0.3843482393\n",
      "obs D loss: 848.9739627838, pde D loss: 4.5986467749\n",
      "obs E loss: 108.4612169266, pde E loss: 1.8267851993\n",
      "obs F loss: 11.7808998376, pde F loss: 0.3086655154\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 148\n",
      "Training observations acc over epoch: 162.7996520996\n",
      "total loss: 993.7595672607, total regularisd loss (sum of batches): 43728.3162841797\n",
      "obs A loss: 2.8341444097, pde A loss: 9.0421442240\n",
      "obs B loss: 9.9216676950, pde B loss: 1.6196884252\n",
      "obs C loss: 1.8989659026, pde C loss: 0.3269778802\n",
      "obs D loss: 843.1364669800, pde D loss: 3.8849801905\n",
      "obs E loss: 107.8005428314, pde E loss: 1.7651191130\n",
      "obs F loss: 11.2059568763, pde F loss: 0.3229135266\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 149\n",
      "Training observations acc over epoch: 162.4223480225\n",
      "total loss: 992.6494083405, total regularisd loss (sum of batches): 43673.7155151367\n",
      "obs A loss: 2.8368863575, pde A loss: 9.5022102892\n",
      "obs B loss: 9.8701835126, pde B loss: 1.6663411241\n",
      "obs C loss: 1.8985585235, pde C loss: 0.3213157216\n",
      "obs D loss: 841.6391439438, pde D loss: 4.5165103041\n",
      "obs E loss: 107.4875658751, pde E loss: 1.7907151803\n",
      "obs F loss: 10.8018489033, pde F loss: 0.3181102546\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 161.8643646240\n",
      "total loss: 988.7272129059, total regularisd loss (sum of batches): 43497.1043090820\n",
      "obs A loss: 2.8278433383, pde A loss: 8.8336077332\n",
      "obs B loss: 9.8189572096, pde B loss: 1.5323658325\n",
      "obs C loss: 1.9052570388, pde C loss: 0.3186611589\n",
      "obs D loss: 838.8952474594, pde D loss: 4.6852162741\n",
      "obs E loss: 107.2777082920, pde E loss: 1.8532450888\n",
      "obs F loss: 10.4613684863, pde F loss: 0.3177238130\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 151\n",
      "Training observations acc over epoch: 161.6845703125\n",
      "total loss: 986.7818717957, total regularisd loss (sum of batches): 43417.9545898438\n",
      "obs A loss: 2.8347148001, pde A loss: 9.4709295332\n",
      "obs B loss: 9.8006419092, pde B loss: 1.5160632059\n",
      "obs C loss: 1.9024072774, pde C loss: 0.3025573744\n",
      "obs D loss: 838.3182773590, pde D loss: 3.4580314495\n",
      "obs E loss: 107.0363019705, pde E loss: 1.6226021089\n",
      "obs F loss: 10.2150777876, pde F loss: 0.3042675918\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 152\n",
      "Training observations acc over epoch: 161.4240570068\n",
      "total loss: 987.3141059875, total regularisd loss (sum of batches): 43444.6992797852\n",
      "obs A loss: 2.8275036439, pde A loss: 10.3865283579\n",
      "obs B loss: 9.7824306339, pde B loss: 1.5423061792\n",
      "obs C loss: 1.8992446624, pde C loss: 0.3309330205\n",
      "obs D loss: 837.0611324310, pde D loss: 4.3056478910\n",
      "obs E loss: 106.9972929955, pde E loss: 1.8835338783\n",
      "obs F loss: 9.9767470658, pde F loss: 0.3207990229\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 153\n",
      "Training observations acc over epoch: 161.1358337402\n",
      "total loss: 983.2095546722, total regularisd loss (sum of batches): 43258.5771484375\n",
      "obs A loss: 2.8202434406, pde A loss: 8.7809647024\n",
      "obs B loss: 9.7664514482, pde B loss: 1.4003521055\n",
      "obs C loss: 1.8951537572, pde C loss: 0.2834794801\n",
      "obs D loss: 835.8302803040, pde D loss: 4.1564606652\n",
      "obs E loss: 106.7198377848, pde E loss: 1.5138895586\n",
      "obs F loss: 9.7830790579, pde F loss: 0.2593530337\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 154\n",
      "Training observations acc over epoch: 160.7801818848\n",
      "total loss: 980.0619201660, total regularisd loss (sum of batches): 43123.4057006836\n",
      "obs A loss: 2.8197744340, pde A loss: 8.7639880031\n",
      "obs B loss: 9.7501833886, pde B loss: 1.4332741406\n",
      "obs C loss: 1.8954259809, pde C loss: 0.2775408044\n",
      "obs D loss: 833.9185600281, pde D loss: 3.2069907226\n",
      "obs E loss: 106.7308229208, pde E loss: 1.4455883596\n",
      "obs F loss: 9.5662870854, pde F loss: 0.2534862384\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 155\n",
      "Training observations acc over epoch: 160.5738067627\n",
      "total loss: 979.6987094879, total regularisd loss (sum of batches): 43107.4109497070\n",
      "obs A loss: 2.8192816228, pde A loss: 8.9783782661\n",
      "obs B loss: 9.7250130773, pde B loss: 1.4369220119\n",
      "obs C loss: 1.8997286502, pde C loss: 0.2896708352\n",
      "obs D loss: 832.7204208374, pde D loss: 3.7991363630\n",
      "obs E loss: 106.8860293627, pde E loss: 1.5109126028\n",
      "obs F loss: 9.3922866434, pde F loss: 0.2409403012\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 156\n",
      "Training observations acc over epoch: 160.2179107666\n",
      "total loss: 977.6910648346, total regularisd loss (sum of batches): 43020.2363281250\n",
      "obs A loss: 2.8106708191, pde A loss: 8.8660183698\n",
      "obs B loss: 9.7196212411, pde B loss: 1.3875735048\n",
      "obs C loss: 1.8991960771, pde C loss: 0.2896722737\n",
      "obs D loss: 830.8472843170, pde D loss: 4.0762077607\n",
      "obs E loss: 106.7867226601, pde E loss: 1.5137991011\n",
      "obs F loss: 9.2437868714, pde F loss: 0.2505266494\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 157\n",
      "Training observations acc over epoch: 160.1956176758\n",
      "total loss: 978.6527347565, total regularisd loss (sum of batches): 43062.0388183594\n",
      "obs A loss: 2.7973537073, pde A loss: 9.8854410350\n",
      "obs B loss: 9.6885545254, pde B loss: 1.3787147440\n",
      "obs C loss: 1.8986245506, pde C loss: 0.2943126610\n",
      "obs D loss: 830.9683341980, pde D loss: 4.0517511740\n",
      "obs E loss: 106.6693282127, pde E loss: 1.6432114486\n",
      "obs F loss: 9.1514675468, pde F loss: 0.2256382520\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.76s\n",
      "\n",
      "Start of epoch 158\n",
      "Training observations acc over epoch: 159.9643859863\n",
      "total loss: 975.9034252167, total regularisd loss (sum of batches): 42938.3752441406\n",
      "obs A loss: 2.7976129763, pde A loss: 8.7342532724\n",
      "obs B loss: 9.6866488159, pde B loss: 1.3676782679\n",
      "obs C loss: 1.8962367401, pde C loss: 0.2746054656\n",
      "obs D loss: 829.7537822723, pde D loss: 4.0293014087\n",
      "obs E loss: 106.6158427000, pde E loss: 1.4899895340\n",
      "obs F loss: 9.0362962931, pde F loss: 0.2211755528\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 159\n",
      "Training observations acc over epoch: 160.9077911377\n",
      "total loss: 992.7746944427, total regularisd loss (sum of batches): 43674.7771606445\n",
      "obs A loss: 2.7839158587, pde A loss: 12.2921169847\n",
      "obs B loss: 9.6666375399, pde B loss: 1.5194634218\n",
      "obs C loss: 1.8940786384, pde C loss: 0.3590398575\n",
      "obs D loss: 835.3231697083, pde D loss: 10.4193505943\n",
      "obs E loss: 106.7473654747, pde E loss: 2.4411477372\n",
      "obs F loss: 9.0315471292, pde F loss: 0.2968572658\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.37s\n",
      "\n",
      "Start of epoch 160\n",
      "Training observations acc over epoch: 160.4155120850\n",
      "total loss: 986.2567939758, total regularisd loss (sum of batches): 43392.4754638672\n",
      "obs A loss: 2.8091751188, pde A loss: 11.0469962955\n",
      "obs B loss: 9.6670162827, pde B loss: 1.5256855506\n",
      "obs C loss: 1.8943925742, pde C loss: 0.3282966474\n",
      "obs D loss: 832.5628147125, pde D loss: 8.4470265880\n",
      "obs E loss: 106.6014187336, pde E loss: 2.1474061869\n",
      "obs F loss: 8.9583142698, pde F loss: 0.2682363731\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 159.8217010498\n",
      "total loss: 975.4020061493, total regularisd loss (sum of batches): 42921.6115112305\n",
      "obs A loss: 2.7865974419, pde A loss: 9.3111628741\n",
      "obs B loss: 9.6452003419, pde B loss: 1.3749759477\n",
      "obs C loss: 1.8953574002, pde C loss: 0.3106247820\n",
      "obs D loss: 829.1381893158, pde D loss: 3.6225747652\n",
      "obs E loss: 106.5954477787, pde E loss: 1.6394141968\n",
      "obs F loss: 8.8694374561, pde F loss: 0.2130252074\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 162\n",
      "Training observations acc over epoch: 159.4893646240\n",
      "total loss: 973.3112583160, total regularisd loss (sum of batches): 42828.9124145508\n",
      "obs A loss: 2.7804152966, pde A loss: 9.3070748746\n",
      "obs B loss: 9.6369062662, pde B loss: 1.4120879676\n",
      "obs C loss: 1.8942594118, pde C loss: 0.2888667034\n",
      "obs D loss: 827.2963657379, pde D loss: 3.6360773593\n",
      "obs E loss: 106.5330311060, pde E loss: 1.5120235495\n",
      "obs F loss: 8.7949894369, pde F loss: 0.2191662255\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 163\n",
      "Training observations acc over epoch: 159.3729400635\n",
      "total loss: 972.8167800903, total regularisd loss (sum of batches): 42804.6298828125\n",
      "obs A loss: 2.7554898560, pde A loss: 9.8618742377\n",
      "obs B loss: 9.6314353198, pde B loss: 1.4533384442\n",
      "obs C loss: 1.8941833396, pde C loss: 0.2995183021\n",
      "obs D loss: 826.7782735825, pde D loss: 3.2331770994\n",
      "obs E loss: 106.4464261532, pde E loss: 1.5181119721\n",
      "obs F loss: 8.7317234576, pde F loss: 0.2132345005\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 164\n",
      "Training observations acc over epoch: 159.6410217285\n",
      "total loss: 975.3130264282, total regularisd loss (sum of batches): 42916.0432128906\n",
      "obs A loss: 2.7514029816, pde A loss: 9.9459713697\n",
      "obs B loss: 9.6210827082, pde B loss: 1.5663533863\n",
      "obs C loss: 1.8986047357, pde C loss: 0.3080946435\n",
      "obs D loss: 828.3951702118, pde D loss: 3.9182527624\n",
      "obs E loss: 106.4731600285, pde E loss: 1.5067279059\n",
      "obs F loss: 8.7067013234, pde F loss: 0.2214966463\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.81s\n",
      "\n",
      "Start of epoch 165\n",
      "Training observations acc over epoch: 158.9237518311\n",
      "total loss: 970.3395156860, total regularisd loss (sum of batches): 42692.3391723633\n",
      "obs A loss: 2.7415800169, pde A loss: 9.8143933266\n",
      "obs B loss: 9.6198669076, pde B loss: 1.6144238058\n",
      "obs C loss: 1.8994171098, pde C loss: 0.3481420404\n",
      "obs D loss: 824.2736816406, pde D loss: 3.2121803798\n",
      "obs E loss: 106.3761646748, pde E loss: 1.5900519956\n",
      "obs F loss: 8.6317207962, pde F loss: 0.2178900142\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.81s\n",
      "\n",
      "Start of epoch 166\n",
      "Training observations acc over epoch: 158.5592803955\n",
      "total loss: 966.8506813049, total regularisd loss (sum of batches): 42545.8175048828\n",
      "obs A loss: 2.7040137388, pde A loss: 8.5833463818\n",
      "obs B loss: 9.6247414798, pde B loss: 1.5767875072\n",
      "obs C loss: 1.9028914273, pde C loss: 0.3277740777\n",
      "obs D loss: 822.1755170822, pde D loss: 3.3873000704\n",
      "obs E loss: 106.4153952599, pde E loss: 1.3954400662\n",
      "obs F loss: 8.5330453664, pde F loss: 0.2244293960\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 167\n",
      "Training observations acc over epoch: 158.5088653564\n",
      "total loss: 969.7611675262, total regularisd loss (sum of batches): 42669.5159301758\n",
      "obs A loss: 2.6688118763, pde A loss: 10.2447963357\n",
      "obs B loss: 9.6653920263, pde B loss: 1.7759822384\n",
      "obs C loss: 1.9081123173, pde C loss: 0.4442299642\n",
      "obs D loss: 821.8005943298, pde D loss: 4.3734746315\n",
      "obs E loss: 106.5055506229, pde E loss: 1.6211085077\n",
      "obs F loss: 8.5045647621, pde F loss: 0.2485510637\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 168\n",
      "Training observations acc over epoch: 158.6115112305\n",
      "total loss: 975.8489151001, total regularisd loss (sum of batches): 42935.7184448242\n",
      "obs A loss: 2.6801131144, pde A loss: 13.1144191772\n",
      "obs B loss: 9.6574177742, pde B loss: 2.1666522361\n",
      "obs C loss: 1.9094026927, pde C loss: 0.4631179655\n",
      "obs D loss: 822.4047794342, pde D loss: 6.1138420552\n",
      "obs E loss: 106.5121275187, pde E loss: 2.0234351326\n",
      "obs F loss: 8.5052708089, pde F loss: 0.2983354856\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 169\n",
      "Training observations acc over epoch: 158.1463470459\n",
      "total loss: 967.4809761047, total regularisd loss (sum of batches): 42566.9848632812\n",
      "obs A loss: 2.6484541148, pde A loss: 10.5844474435\n",
      "obs B loss: 9.6193017960, pde B loss: 1.9205270372\n",
      "obs C loss: 1.9036905263, pde C loss: 0.4283550624\n",
      "obs D loss: 819.8963088989, pde D loss: 3.7991545349\n",
      "obs E loss: 106.3457223177, pde E loss: 1.6175052002\n",
      "obs F loss: 8.4647639394, pde F loss: 0.2527396907\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 170\n",
      "Training observations acc over epoch: 158.0259246826\n",
      "total loss: 967.7275981903, total regularisd loss (sum of batches): 42579.8636474609\n",
      "obs A loss: 2.6270808168, pde A loss: 10.9467380345\n",
      "obs B loss: 9.6027026922, pde B loss: 2.0638092440\n",
      "obs C loss: 1.9038704541, pde C loss: 0.4400595054\n",
      "obs D loss: 819.3236541748, pde D loss: 4.1234294511\n",
      "obs E loss: 106.2829866409, pde E loss: 1.7438123561\n",
      "obs F loss: 8.4152358621, pde F loss: 0.2542289374\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.35s\n",
      "\n",
      "Start of epoch 171\n",
      "Training observations acc over epoch: 157.8799743652\n",
      "total loss: 964.4692840576, total regularisd loss (sum of batches): 42439.9810791016\n",
      "obs A loss: 2.6175276190, pde A loss: 9.8093508035\n",
      "obs B loss: 9.5857512802, pde B loss: 1.9467636757\n",
      "obs C loss: 1.8969016839, pde C loss: 0.3751805797\n",
      "obs D loss: 818.4631595612, pde D loss: 3.3405785896\n",
      "obs E loss: 106.3303099871, pde E loss: 1.4644487407\n",
      "obs F loss: 8.3861036152, pde F loss: 0.2532163355\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 157.8504333496\n",
      "total loss: 968.3785057068, total regularisd loss (sum of batches): 42605.1993408203\n",
      "obs A loss: 2.5862900503, pde A loss: 12.1595507115\n",
      "obs B loss: 9.5547942966, pde B loss: 2.2713046242\n",
      "obs C loss: 1.8931290545, pde C loss: 0.4318422703\n",
      "obs D loss: 818.5763435364, pde D loss: 4.4022449777\n",
      "obs E loss: 106.1393550634, pde E loss: 1.7379640844\n",
      "obs F loss: 8.3528461605, pde F loss: 0.2728446843\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 173\n",
      "Training observations acc over epoch: 157.6852264404\n",
      "total loss: 966.1360244751, total regularisd loss (sum of batches): 42509.7227172852\n",
      "obs A loss: 2.6251344196, pde A loss: 11.3391910642\n",
      "obs B loss: 9.5455968976, pde B loss: 2.1422283519\n",
      "obs C loss: 1.8906806912, pde C loss: 0.4158940073\n",
      "obs D loss: 817.3672676086, pde D loss: 4.1138885915\n",
      "obs E loss: 106.3477609158, pde E loss: 1.7459139898\n",
      "obs F loss: 8.3352029920, pde F loss: 0.2672576113\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.86s\n",
      "\n",
      "Start of epoch 174\n",
      "Training observations acc over epoch: 157.7467041016\n",
      "total loss: 966.3888931274, total regularisd loss (sum of batches): 42517.8950195312\n",
      "obs A loss: 2.6076433063, pde A loss: 11.1985652596\n",
      "obs B loss: 9.5288567245, pde B loss: 2.1990156993\n",
      "obs C loss: 1.8891305383, pde C loss: 0.4122476433\n",
      "obs D loss: 817.9493198395, pde D loss: 4.2530576512\n",
      "obs E loss: 106.1855247021, pde E loss: 1.5851085708\n",
      "obs F loss: 8.3198522180, pde F loss: 0.2605704260\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 175\n",
      "Training observations acc over epoch: 248.4578704834\n",
      "total loss: 2664.7672767639, total regularisd loss (sum of batches): 117210.6643066406\n",
      "obs A loss: 4.4000454079, pde A loss: 616.2099642456\n",
      "obs B loss: 11.8481523693, pde B loss: 192.7525776252\n",
      "obs C loss: 2.4863264188, pde C loss: 12.7819456011\n",
      "obs D loss: 1294.6603622437, pde D loss: 116.6717512906\n",
      "obs E loss: 132.9973543882, pde E loss: 197.3422479462\n",
      "obs F loss: 44.3550324738, pde F loss: 38.2614871967\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 176\n",
      "Training observations acc over epoch: 245.1892242432\n",
      "total loss: 1810.2979202271, total regularisd loss (sum of batches): 79651.1081542969\n",
      "obs A loss: 4.7535771504, pde A loss: 115.1772999763\n",
      "obs B loss: 12.7318421304, pde B loss: 75.5436365604\n",
      "obs C loss: 2.3299020007, pde C loss: 3.6805408597\n",
      "obs D loss: 1263.3793334961, pde D loss: 15.1854786724\n",
      "obs E loss: 143.1906208992, pde E loss: 100.4614171982\n",
      "obs F loss: 44.7499318123, pde F loss: 29.1143456101\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 177\n",
      "Training observations acc over epoch: 237.9870147705\n",
      "total loss: 1733.6499671936, total regularisd loss (sum of batches): 76280.5922851562\n",
      "obs A loss: 4.6378677636, pde A loss: 122.0231089592\n",
      "obs B loss: 12.8572098911, pde B loss: 65.3980913162\n",
      "obs C loss: 2.2680234499, pde C loss: 4.0595944151\n",
      "obs D loss: 1221.1320858002, pde D loss: 9.2409483939\n",
      "obs E loss: 141.6803617477, pde E loss: 76.2564123869\n",
      "obs F loss: 45.3466666341, pde F loss: 28.7495548129\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 178\n",
      "Training observations acc over epoch: 234.2528381348\n",
      "total loss: 1701.5467948914, total regularisd loss (sum of batches): 74872.2546386719\n",
      "obs A loss: 4.5346347019, pde A loss: 128.7863786221\n",
      "obs B loss: 12.8937539756, pde B loss: 62.9442673922\n",
      "obs C loss: 2.2134824395, pde C loss: 3.6344787329\n",
      "obs D loss: 1198.4973011017, pde D loss: 7.6867497414\n",
      "obs E loss: 141.6029689312, pde E loss: 67.1159474850\n",
      "obs F loss: 45.7749680877, pde F loss: 25.8618482351\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 179\n",
      "Training observations acc over epoch: 232.3591156006\n",
      "total loss: 1681.9197082520, total regularisd loss (sum of batches): 73998.5385742188\n",
      "obs A loss: 4.5172973797, pde A loss: 134.4456949234\n",
      "obs B loss: 12.9672218263, pde B loss: 60.9531683922\n",
      "obs C loss: 2.2933837399, pde C loss: 3.3158247545\n",
      "obs D loss: 1185.8768615723, pde D loss: 5.3155302405\n",
      "obs E loss: 141.4652504921, pde E loss: 59.5370024443\n",
      "obs F loss: 47.0347690582, pde F loss: 24.1976958215\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 180\n",
      "Training observations acc over epoch: 230.8417816162\n",
      "total loss: 1667.6675529480, total regularisd loss (sum of batches): 73377.9287109375\n",
      "obs A loss: 4.5365547985, pde A loss: 138.2843811512\n",
      "obs B loss: 13.0297544301, pde B loss: 59.7609752417\n",
      "obs C loss: 2.4169888273, pde C loss: 2.8756403700\n",
      "obs D loss: 1176.5008220673, pde D loss: 5.0845748410\n",
      "obs E loss: 140.6395301819, pde E loss: 54.2412596941\n",
      "obs F loss: 47.9268356562, pde F loss: 22.3702492118\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 181\n",
      "Training observations acc over epoch: 229.3580474854\n",
      "total loss: 1651.6806221008, total regularisd loss (sum of batches): 72678.8707275391\n",
      "obs A loss: 4.5881971344, pde A loss: 140.5201311111\n",
      "obs B loss: 13.0872133374, pde B loss: 57.7745161057\n",
      "obs C loss: 2.6055872031, pde C loss: 2.3964242488\n",
      "obs D loss: 1166.5693321228, pde D loss: 5.2334212661\n",
      "obs E loss: 140.0110683441, pde E loss: 48.8442997932\n",
      "obs F loss: 49.2869626284, pde F loss: 20.7634778023\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.37s\n",
      "\n",
      "Start of epoch 182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 228.3336181641\n",
      "total loss: 1638.8057899475, total regularisd loss (sum of batches): 72106.9838867188\n",
      "obs A loss: 4.6040442511, pde A loss: 141.9371306896\n",
      "obs B loss: 13.1257552505, pde B loss: 55.7581348419\n",
      "obs C loss: 2.7740585618, pde C loss: 2.0261172242\n",
      "obs D loss: 1159.1788768768, pde D loss: 4.5686451569\n",
      "obs E loss: 139.8328185081, pde E loss: 44.1792172790\n",
      "obs F loss: 50.4862800837, pde F loss: 20.3347167969\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 183\n",
      "Training observations acc over epoch: 227.4454040527\n",
      "total loss: 1625.7119216919, total regularisd loss (sum of batches): 71529.8084716797\n",
      "obs A loss: 4.7102343217, pde A loss: 141.0363528728\n",
      "obs B loss: 13.1785394549, pde B loss: 53.2705790997\n",
      "obs C loss: 2.7582676820, pde C loss: 1.8519209959\n",
      "obs D loss: 1153.5784034729, pde D loss: 4.6731204316\n",
      "obs E loss: 139.2482547760, pde E loss: 40.4534169436\n",
      "obs F loss: 51.1986520290, pde F loss: 19.7541862726\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 184\n",
      "Training observations acc over epoch: 226.7333984375\n",
      "total loss: 1610.0444679260, total regularisd loss (sum of batches): 70840.4545898438\n",
      "obs A loss: 4.7299958244, pde A loss: 136.5935854912\n",
      "obs B loss: 13.2237840593, pde B loss: 51.4089736938\n",
      "obs C loss: 2.9326675013, pde C loss: 1.3749693278\n",
      "obs D loss: 1148.3540573120, pde D loss: 5.7575542182\n",
      "obs E loss: 139.0582053661, pde E loss: 35.3018736243\n",
      "obs F loss: 52.1014618874, pde F loss: 19.2073481083\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 185\n",
      "Training observations acc over epoch: 225.6969604492\n",
      "total loss: 1576.5675277710, total regularisd loss (sum of batches): 69368.9134521484\n",
      "obs A loss: 4.7024305910, pde A loss: 122.8843984604\n",
      "obs B loss: 13.2780760229, pde B loss: 46.4670963883\n",
      "obs C loss: 2.8534125946, pde C loss: 0.9808996357\n",
      "obs D loss: 1142.4324779510, pde D loss: 5.5934305787\n",
      "obs E loss: 138.7388448715, pde E loss: 29.5130442977\n",
      "obs F loss: 52.1768863201, pde F loss: 16.9465483725\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 186\n",
      "Training observations acc over epoch: 223.3358154297\n",
      "total loss: 1484.2131462097, total regularisd loss (sum of batches): 65305.8575439453\n",
      "obs A loss: 4.7987769693, pde A loss: 75.2916578054\n",
      "obs B loss: 13.1659004092, pde B loss: 31.7645006776\n",
      "obs C loss: 2.5214901865, pde C loss: 0.5913018454\n",
      "obs D loss: 1131.4548797607, pde D loss: 6.2391309068\n",
      "obs E loss: 137.1493344307, pde E loss: 19.3782266676\n",
      "obs F loss: 50.9245491028, pde F loss: 10.9333795011\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 187\n",
      "Training observations acc over epoch: 218.5112152100\n",
      "total loss: 1384.7467880249, total regularisd loss (sum of batches): 60925.7784423828\n",
      "obs A loss: 5.1414593831, pde A loss: 34.8505601883\n",
      "obs B loss: 12.8732785583, pde B loss: 18.1417667866\n",
      "obs C loss: 2.2859028913, pde C loss: 0.4609616734\n",
      "obs D loss: 1107.6620044708, pde D loss: 5.4971435815\n",
      "obs E loss: 134.0016138554, pde E loss: 9.6391605735\n",
      "obs F loss: 49.1029221416, pde F loss: 5.0900172591\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 188\n",
      "Training observations acc over epoch: 211.4284820557\n",
      "total loss: 1315.0773410797, total regularisd loss (sum of batches): 57859.8100585938\n",
      "obs A loss: 5.3751384467, pde A loss: 23.0163516998\n",
      "obs B loss: 12.6131443679, pde B loss: 8.9639807642\n",
      "obs C loss: 2.1238213088, pde C loss: 0.4084753431\n",
      "obs D loss: 1071.9670162201, pde D loss: 5.9831356555\n",
      "obs E loss: 130.0522525311, pde E loss: 5.7771261409\n",
      "obs F loss: 46.4395163059, pde F loss: 2.3573839590\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 189\n",
      "Training observations acc over epoch: 204.2109985352\n",
      "total loss: 1264.0039024353, total regularisd loss (sum of batches): 55616.1988525391\n",
      "obs A loss: 5.4239699990, pde A loss: 21.9821301997\n",
      "obs B loss: 12.5728649795, pde B loss: 5.0191495046\n",
      "obs C loss: 2.0074866824, pde C loss: 0.4142901897\n",
      "obs D loss: 1035.3717155457, pde D loss: 5.1888639107\n",
      "obs E loss: 126.6610260010, pde E loss: 4.9446690455\n",
      "obs F loss: 43.2290303707, pde F loss: 1.1886931602\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 190\n",
      "Training observations acc over epoch: 197.9759826660\n",
      "total loss: 1224.3165569305, total regularisd loss (sum of batches): 53870.1782226562\n",
      "obs A loss: 5.4819066375, pde A loss: 21.1882333457\n",
      "obs B loss: 12.4637740552, pde B loss: 2.7784498446\n",
      "obs C loss: 1.9285906591, pde C loss: 0.4331994541\n",
      "obs D loss: 1006.2924461365, pde D loss: 5.8829795234\n",
      "obs E loss: 123.1881856918, pde E loss: 5.4578849748\n",
      "obs F loss: 38.5010154247, pde F loss: 0.7198899575\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 191\n",
      "Training observations acc over epoch: 192.4583129883\n",
      "total loss: 1188.9860630035, total regularisd loss (sum of batches): 52313.2918701172\n",
      "obs A loss: 5.6541516632, pde A loss: 20.8153519928\n",
      "obs B loss: 12.1560749263, pde B loss: 2.5444459766\n",
      "obs C loss: 1.9240661133, pde C loss: 0.4392887009\n",
      "obs D loss: 980.3940868378, pde D loss: 4.5047154389\n",
      "obs E loss: 120.9508287907, pde E loss: 5.2183145881\n",
      "obs F loss: 33.6707360148, pde F loss: 0.7140052840\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 188.9470062256\n",
      "total loss: 1165.4852905273, total regularisd loss (sum of batches): 51287.1520996094\n",
      "obs A loss: 5.7388763726, pde A loss: 19.3304222822\n",
      "obs B loss: 12.0585134923, pde B loss: 2.2390657961\n",
      "obs C loss: 1.8996147178, pde C loss: 0.3849271466\n",
      "obs D loss: 965.1416568756, pde D loss: 4.3907966800\n",
      "obs E loss: 118.3435859680, pde E loss: 4.7915627807\n",
      "obs F loss: 30.4996030331, pde F loss: 0.6666688658\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 193\n",
      "Training observations acc over epoch: 185.2388000488\n",
      "total loss: 1142.4502220154, total regularisd loss (sum of batches): 50268.9658203125\n",
      "obs A loss: 5.7060695216, pde A loss: 18.3960551023\n",
      "obs B loss: 12.0926102102, pde B loss: 2.2664975300\n",
      "obs C loss: 1.9051705059, pde C loss: 0.3948265356\n",
      "obs D loss: 946.9186115265, pde D loss: 4.9180374779\n",
      "obs E loss: 116.5418785810, pde E loss: 4.3938987330\n",
      "obs F loss: 28.2686758637, pde F loss: 0.6478958679\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 194\n",
      "Training observations acc over epoch: 181.9897308350\n",
      "total loss: 1121.8865585327, total regularisd loss (sum of batches): 49369.8092651367\n",
      "obs A loss: 5.8063181937, pde A loss: 17.5454539955\n",
      "obs B loss: 12.0391547382, pde B loss: 2.4277138002\n",
      "obs C loss: 1.8968336470, pde C loss: 0.3640308175\n",
      "obs D loss: 930.9815673828, pde D loss: 4.7131639570\n",
      "obs E loss: 114.8791850805, pde E loss: 4.2671552077\n",
      "obs F loss: 26.3354477286, pde F loss: 0.6305265678\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.24s\n",
      "\n",
      "Start of epoch 195\n",
      "Training observations acc over epoch: 180.0849151611\n",
      "total loss: 1108.9968757629, total regularisd loss (sum of batches): 48794.0865478516\n",
      "obs A loss: 5.5689899474, pde A loss: 15.7536098957\n",
      "obs B loss: 12.0858195126, pde B loss: 2.5443978161\n",
      "obs C loss: 1.8849482965, pde C loss: 0.3479742156\n",
      "obs D loss: 922.5656890869, pde D loss: 5.1511157528\n",
      "obs E loss: 113.7069633007, pde E loss: 4.1267242283\n",
      "obs F loss: 24.6971853375, pde F loss: 0.5634526508\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 196\n",
      "Training observations acc over epoch: 178.2390594482\n",
      "total loss: 1095.0154037476, total regularisd loss (sum of batches): 48177.6043090820\n",
      "obs A loss: 5.5877158195, pde A loss: 14.6745175421\n",
      "obs B loss: 11.9950425625, pde B loss: 2.6480254568\n",
      "obs C loss: 1.8841221929, pde C loss: 0.3045928194\n",
      "obs D loss: 913.5306434631, pde D loss: 3.7240424566\n",
      "obs E loss: 112.9613502026, pde E loss: 3.6941909119\n",
      "obs F loss: 23.4757521749, pde F loss: 0.5354027115\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 197\n",
      "Training observations acc over epoch: 177.0391540527\n",
      "total loss: 1087.3815422058, total regularisd loss (sum of batches): 47848.3490600586\n",
      "obs A loss: 5.5696618408, pde A loss: 13.4902394712\n",
      "obs B loss: 11.8947788775, pde B loss: 2.4541421384\n",
      "obs C loss: 1.8824784551, pde C loss: 0.2871909817\n",
      "obs D loss: 908.1587047577, pde D loss: 4.9103181362\n",
      "obs E loss: 112.4365944862, pde E loss: 3.5160666332\n",
      "obs F loss: 22.2928194404, pde F loss: 0.4885560013\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 198\n",
      "Training observations acc over epoch: 175.9045257568\n",
      "total loss: 1081.0600280762, total regularisd loss (sum of batches): 47567.4122924805\n",
      "obs A loss: 5.4873715267, pde A loss: 13.9451022446\n",
      "obs B loss: 11.7682936341, pde B loss: 2.3685895056\n",
      "obs C loss: 1.8805190884, pde C loss: 0.2888533990\n",
      "obs D loss: 903.0957164764, pde D loss: 5.1712429821\n",
      "obs E loss: 112.0897163153, pde E loss: 3.3464143723\n",
      "obs F loss: 21.1056547165, pde F loss: 0.5125473198\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.40s\n",
      "\n",
      "Start of epoch 199\n",
      "Training observations acc over epoch: 174.0388793945\n",
      "total loss: 1069.0432052612, total regularisd loss (sum of batches): 47037.0614624023\n",
      "obs A loss: 5.4772122428, pde A loss: 13.5431678593\n",
      "obs B loss: 11.6158143878, pde B loss: 2.4224847667\n",
      "obs C loss: 1.8823232614, pde C loss: 0.2976913415\n",
      "obs D loss: 893.3732185364, pde D loss: 4.6229229569\n",
      "obs E loss: 111.7094082832, pde E loss: 3.3563894629\n",
      "obs F loss: 20.1752218604, pde F loss: 0.5673572477\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.24s\n",
      "\n",
      "Start of epoch 200\n",
      "Training observations acc over epoch: 173.1801147461\n",
      "total loss: 1065.1699924469, total regularisd loss (sum of batches): 46865.0982055664\n",
      "obs A loss: 5.5675097033, pde A loss: 14.5644028932\n",
      "obs B loss: 11.6010574400, pde B loss: 2.5822925121\n",
      "obs C loss: 1.8857270684, pde C loss: 0.3277739077\n",
      "obs D loss: 889.1888027191, pde D loss: 4.7563225478\n",
      "obs E loss: 111.3788733482, pde E loss: 3.3074223399\n",
      "obs F loss: 19.4585506618, pde F loss: 0.5512643270\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 201\n",
      "Training observations acc over epoch: 171.8677368164\n",
      "total loss: 1055.6112480164, total regularisd loss (sum of batches): 46439.9288940430\n",
      "obs A loss: 5.4547106251, pde A loss: 13.4775198698\n",
      "obs B loss: 11.6162810922, pde B loss: 2.4105776399\n",
      "obs C loss: 1.8844003342, pde C loss: 0.3185227644\n",
      "obs D loss: 882.5429058075, pde D loss: 4.4904141128\n",
      "obs E loss: 110.9643719196, pde E loss: 3.1801489815\n",
      "obs F loss: 18.7438733876, pde F loss: 0.5275183329\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 171.4180450439\n",
      "total loss: 1051.2992744446, total regularisd loss (sum of batches): 46256.1542968750\n",
      "obs A loss: 5.3283826262, pde A loss: 12.1863909960\n",
      "obs B loss: 11.5897859782, pde B loss: 2.1790192574\n",
      "obs C loss: 1.8801555149, pde C loss: 0.2867722376\n",
      "obs D loss: 881.0535411835, pde D loss: 4.8500874266\n",
      "obs E loss: 110.5264577866, pde E loss: 2.8139374927\n",
      "obs F loss: 18.1299756169, pde F loss: 0.4747808822\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 203\n",
      "Training observations acc over epoch: 170.3587799072\n",
      "total loss: 1044.4059886932, total regularisd loss (sum of batches): 45952.4140014648\n",
      "obs A loss: 5.1510904729, pde A loss: 12.6698782742\n",
      "obs B loss: 11.5306115597, pde B loss: 2.0294256546\n",
      "obs C loss: 1.8837631717, pde C loss: 0.3105181186\n",
      "obs D loss: 875.7714214325, pde D loss: 3.8080558144\n",
      "obs E loss: 110.2825759649, pde E loss: 2.9628931880\n",
      "obs F loss: 17.5333967507, pde F loss: 0.4723543301\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 204\n",
      "Training observations acc over epoch: 169.9043731689\n",
      "total loss: 1041.7495136261, total regularisd loss (sum of batches): 45836.3088989258\n",
      "obs A loss: 4.9404175133, pde A loss: 13.3989714533\n",
      "obs B loss: 11.4625083506, pde B loss: 1.8503661640\n",
      "obs C loss: 1.8854066245, pde C loss: 0.2838413827\n",
      "obs D loss: 874.1836357117, pde D loss: 3.6295797266\n",
      "obs E loss: 110.0062646866, pde E loss: 2.7184140384\n",
      "obs F loss: 16.9480144083, pde F loss: 0.4420986157\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 205\n",
      "Training observations acc over epoch: 169.0423889160\n",
      "total loss: 1034.9217491150, total regularisd loss (sum of batches): 45532.9328002930\n",
      "obs A loss: 4.8097856119, pde A loss: 12.4169835150\n",
      "obs B loss: 11.3620669395, pde B loss: 1.7234568484\n",
      "obs C loss: 1.8843612559, pde C loss: 0.2782046017\n",
      "obs D loss: 870.0491008759, pde D loss: 3.2604521103\n",
      "obs E loss: 109.7546139956, pde E loss: 2.5595073402\n",
      "obs F loss: 16.3944798410, pde F loss: 0.4287432991\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 206\n",
      "Training observations acc over epoch: 168.6770172119\n",
      "total loss: 1035.6543579102, total regularisd loss (sum of batches): 45567.1799926758\n",
      "obs A loss: 4.7352496013, pde A loss: 13.8995241672\n",
      "obs B loss: 11.2632135451, pde B loss: 1.6994004641\n",
      "obs C loss: 1.8834265564, pde C loss: 0.3098362745\n",
      "obs D loss: 868.7162227631, pde D loss: 4.4947194569\n",
      "obs E loss: 109.5452952385, pde E loss: 2.7696491517\n",
      "obs F loss: 15.9187424481, pde F loss: 0.4190733097\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 207\n",
      "Training observations acc over epoch: 168.3534393311\n",
      "total loss: 1031.2303428650, total regularisd loss (sum of batches): 45375.5740966797\n",
      "obs A loss: 4.6382793933, pde A loss: 11.5514240861\n",
      "obs B loss: 11.1442812234, pde B loss: 1.6142255962\n",
      "obs C loss: 1.8839642145, pde C loss: 0.3010417563\n",
      "obs D loss: 867.9992790222, pde D loss: 4.5991209410\n",
      "obs E loss: 109.0661699772, pde E loss: 2.5955849551\n",
      "obs F loss: 15.3886627555, pde F loss: 0.4483075533\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 208\n",
      "Training observations acc over epoch: 167.5314636230\n",
      "total loss: 1025.3094425201, total regularisd loss (sum of batches): 45112.1448974609\n",
      "obs A loss: 4.5263141841, pde A loss: 11.2008319795\n",
      "obs B loss: 11.0218489617, pde B loss: 1.5580958948\n",
      "obs C loss: 1.8849665392, pde C loss: 0.2885626592\n",
      "obs D loss: 864.1092491150, pde D loss: 4.1661482453\n",
      "obs E loss: 108.8523881435, pde E loss: 2.4644159488\n",
      "obs F loss: 14.7941616774, pde F loss: 0.4424661938\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.76s\n",
      "\n",
      "Start of epoch 209\n",
      "Training observations acc over epoch: 166.9124450684\n",
      "total loss: 1021.6676845551, total regularisd loss (sum of batches): 44951.0872192383\n",
      "obs A loss: 4.4360096157, pde A loss: 11.6723628491\n",
      "obs B loss: 10.9207798392, pde B loss: 1.4443711154\n",
      "obs C loss: 1.8845748641, pde C loss: 0.2816065210\n",
      "obs D loss: 861.3787975311, pde D loss: 4.0240277238\n",
      "obs E loss: 108.6389698982, pde E loss: 2.4530071057\n",
      "obs F loss: 14.2155151367, pde F loss: 0.3176710149\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 210\n",
      "Training observations acc over epoch: 166.4081420898\n",
      "total loss: 1019.6234893799, total regularisd loss (sum of batches): 44860.8223876953\n",
      "obs A loss: 4.3447484896, pde A loss: 11.5821686387\n",
      "obs B loss: 10.9043461978, pde B loss: 1.3878062833\n",
      "obs C loss: 1.8828151766, pde C loss: 0.2716595256\n",
      "obs D loss: 859.2283096313, pde D loss: 5.2062914670\n",
      "obs E loss: 108.4040037394, pde E loss: 2.4037434980\n",
      "obs F loss: 13.6846959293, pde F loss: 0.3229097100\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 211\n",
      "Training observations acc over epoch: 165.9725341797\n",
      "total loss: 1017.1411895752, total regularisd loss (sum of batches): 44752.9739990234\n",
      "obs A loss: 4.3136960492, pde A loss: 12.6336955428\n",
      "obs B loss: 10.8850079477, pde B loss: 1.3678627443\n",
      "obs C loss: 1.8830005154, pde C loss: 0.2989726709\n",
      "obs D loss: 857.4501132965, pde D loss: 4.0462040752\n",
      "obs E loss: 107.9904557467, pde E loss: 2.6274975874\n",
      "obs F loss: 13.3131284714, pde F loss: 0.3315575426\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 165.6756439209\n",
      "total loss: 1016.0761814117, total regularisd loss (sum of batches): 44709.5680541992\n",
      "obs A loss: 4.2436590716, pde A loss: 13.2199171335\n",
      "obs B loss: 10.8618337959, pde B loss: 1.3843961861\n",
      "obs C loss: 1.8846511859, pde C loss: 0.3018949665\n",
      "obs D loss: 856.0725002289, pde D loss: 4.1609528475\n",
      "obs E loss: 108.0869138241, pde E loss: 2.6098847724\n",
      "obs F loss: 12.9044465721, pde F loss: 0.3451190279\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 213\n",
      "Training observations acc over epoch: 165.3027496338\n",
      "total loss: 1013.3230190277, total regularisd loss (sum of batches): 44588.5724487305\n",
      "obs A loss: 4.2004495487, pde A loss: 11.5813318938\n",
      "obs B loss: 10.8309591115, pde B loss: 1.3503622692\n",
      "obs C loss: 1.8838736583, pde C loss: 0.3143744809\n",
      "obs D loss: 854.5708580017, pde D loss: 5.2299469560\n",
      "obs E loss: 107.8606636524, pde E loss: 2.5990765728\n",
      "obs F loss: 12.4697272778, pde F loss: 0.4313921779\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 214\n",
      "Training observations acc over epoch: 164.5874938965\n",
      "total loss: 1010.8463649750, total regularisd loss (sum of batches): 44481.8121337891\n",
      "obs A loss: 4.1815839484, pde A loss: 13.9505875707\n",
      "obs B loss: 10.7907179296, pde B loss: 1.4479834773\n",
      "obs C loss: 1.8840834312, pde C loss: 0.3256724779\n",
      "obs D loss: 850.8995037079, pde D loss: 4.5195111930\n",
      "obs E loss: 107.6602206230, pde E loss: 2.6173180863\n",
      "obs F loss: 12.1090084314, pde F loss: 0.4601775808\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 215\n",
      "Training observations acc over epoch: 164.3544616699\n",
      "total loss: 1008.7858161926, total regularisd loss (sum of batches): 44388.5880126953\n",
      "obs A loss: 4.1447860599, pde A loss: 13.7845730335\n",
      "obs B loss: 10.7650510073, pde B loss: 1.5769041143\n",
      "obs C loss: 1.8824019469, pde C loss: 0.3170253066\n",
      "obs D loss: 849.7887668610, pde D loss: 4.0028724298\n",
      "obs E loss: 107.7886635065, pde E loss: 2.5121028163\n",
      "obs F loss: 11.7572238147, pde F loss: 0.4654459180\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 216\n",
      "Training observations acc over epoch: 163.7485809326\n",
      "total loss: 1006.1674137115, total regularisd loss (sum of batches): 44271.3526000977\n",
      "obs A loss: 4.0952871740, pde A loss: 12.1005700231\n",
      "obs B loss: 10.6895809621, pde B loss: 1.4357272051\n",
      "obs C loss: 1.8843463324, pde C loss: 0.3132644626\n",
      "obs D loss: 846.9656677246, pde D loss: 6.7800542116\n",
      "obs E loss: 107.4251496792, pde E loss: 2.6219939180\n",
      "obs F loss: 11.4315879196, pde F loss: 0.4241680396\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 217\n",
      "Training observations acc over epoch: 163.4542236328\n",
      "total loss: 1000.9955062866, total regularisd loss (sum of batches): 44040.5616455078\n",
      "obs A loss: 4.0631440505, pde A loss: 11.3553479165\n",
      "obs B loss: 10.6245883256, pde B loss: 1.3704019655\n",
      "obs C loss: 1.8834775016, pde C loss: 0.3181468584\n",
      "obs D loss: 845.7831077576, pde D loss: 4.4833373055\n",
      "obs E loss: 107.3050069809, pde E loss: 2.3796523251\n",
      "obs F loss: 11.0659000725, pde F loss: 0.3633944816\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 218\n",
      "Training observations acc over epoch: 168.4333190918\n",
      "total loss: 1255.6025657654, total regularisd loss (sum of batches): 55250.5742797852\n",
      "obs A loss: 4.4664419033, pde A loss: 173.9630564600\n",
      "obs B loss: 10.7976191789, pde B loss: 13.6752186716\n",
      "obs C loss: 1.9969597887, pde C loss: 3.1093917070\n",
      "obs D loss: 870.6819496155, pde D loss: 24.2553814538\n",
      "obs E loss: 108.5525516272, pde E loss: 28.0657502376\n",
      "obs F loss: 14.1044487655, pde F loss: 1.9337979779\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 219\n",
      "Training observations acc over epoch: 181.3160400391\n",
      "total loss: 1145.9787120819, total regularisd loss (sum of batches): 50420.4515991211\n",
      "obs A loss: 5.1408257931, pde A loss: 25.0504997671\n",
      "obs B loss: 11.4537033290, pde B loss: 6.4187333733\n",
      "obs C loss: 2.5177878588, pde C loss: 1.4143579416\n",
      "obs D loss: 925.5026550293, pde D loss: 12.9999834374\n",
      "obs E loss: 113.8086683750, pde E loss: 9.5336271226\n",
      "obs F loss: 29.4725986719, pde F loss: 2.6652630996\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 220\n",
      "Training observations acc over epoch: 174.4148864746\n",
      "total loss: 1067.8922519684, total regularisd loss (sum of batches): 46992.5324707031\n",
      "obs A loss: 4.9537523314, pde A loss: 9.7817892134\n",
      "obs B loss: 10.9725297391, pde B loss: 1.5341002066\n",
      "obs C loss: 1.9997754227, pde C loss: 0.5029543857\n",
      "obs D loss: 897.5869178772, pde D loss: 6.2487482987\n",
      "obs E loss: 111.0725342035, pde E loss: 2.7314889431\n",
      "obs F loss: 19.9040266573, pde F loss: 0.6036310252\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 221\n",
      "Training observations acc over epoch: 171.1414031982\n",
      "total loss: 1042.6272869110, total regularisd loss (sum of batches): 45873.4749145508\n",
      "obs A loss: 4.8108384535, pde A loss: 7.6842569411\n",
      "obs B loss: 10.7067030221, pde B loss: 1.1739017218\n",
      "obs C loss: 1.9047217630, pde C loss: 0.3066460867\n",
      "obs D loss: 883.2355327606, pde D loss: 4.0396548323\n",
      "obs E loss: 109.4665434361, pde E loss: 2.1887416057\n",
      "obs F loss: 16.7242601812, pde F loss: 0.3854704658\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 169.0679321289\n",
      "total loss: 1029.5175189972, total regularisd loss (sum of batches): 45299.5723876953\n",
      "obs A loss: 4.5379570127, pde A loss: 7.9906317741\n",
      "obs B loss: 10.4722027481, pde B loss: 1.0421941634\n",
      "obs C loss: 1.8823851906, pde C loss: 0.2783908299\n",
      "obs D loss: 873.9440708160, pde D loss: 3.0172777623\n",
      "obs E loss: 108.5971355438, pde E loss: 2.4471028671\n",
      "obs F loss: 14.9737017155, pde F loss: 0.3344732579\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 223\n",
      "Training observations acc over epoch: 167.5706176758\n",
      "total loss: 1020.4679679871, total regularisd loss (sum of batches): 44899.8549804688\n",
      "obs A loss: 4.3746040240, pde A loss: 7.7905650586\n",
      "obs B loss: 10.3153543919, pde B loss: 1.0110075530\n",
      "obs C loss: 1.8783768024, pde C loss: 0.2794329091\n",
      "obs D loss: 866.6849918365, pde D loss: 3.2809429541\n",
      "obs E loss: 108.0798540115, pde E loss: 2.2959326990\n",
      "obs F loss: 14.0906434059, pde F loss: 0.3862537406\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 224\n",
      "Training observations acc over epoch: 166.5974578857\n",
      "total loss: 1015.2855587006, total regularisd loss (sum of batches): 44676.3415527344\n",
      "obs A loss: 4.3074580953, pde A loss: 8.4703420401\n",
      "obs B loss: 10.2577702105, pde B loss: 1.0098351054\n",
      "obs C loss: 1.8810955118, pde C loss: 0.2752226479\n",
      "obs D loss: 861.6781692505, pde D loss: 3.3684867769\n",
      "obs E loss: 107.9864413738, pde E loss: 2.1949967779\n",
      "obs F loss: 13.4738017023, pde F loss: 0.3819461693\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 225\n",
      "Training observations acc over epoch: 166.0256042480\n",
      "total loss: 1011.5604343414, total regularisd loss (sum of batches): 44508.5717773438\n",
      "obs A loss: 4.2794532329, pde A loss: 8.4270724207\n",
      "obs B loss: 10.2413066626, pde B loss: 1.0322331749\n",
      "obs C loss: 1.8856850863, pde C loss: 0.2809512406\n",
      "obs D loss: 858.9146137238, pde D loss: 3.2371850628\n",
      "obs E loss: 107.7565817833, pde E loss: 2.0544713475\n",
      "obs F loss: 13.0761135221, pde F loss: 0.3747756346\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.67s\n",
      "\n",
      "Start of epoch 226\n",
      "Training observations acc over epoch: 165.7760162354\n",
      "total loss: 1012.0846233368, total regularisd loss (sum of batches): 44533.6901245117\n",
      "obs A loss: 4.2520860061, pde A loss: 8.7928705066\n",
      "obs B loss: 10.2031456679, pde B loss: 0.9841589835\n",
      "obs C loss: 1.8910610266, pde C loss: 0.2708365042\n",
      "obs D loss: 857.9240894318, pde D loss: 4.9787140600\n",
      "obs E loss: 107.7321747541, pde E loss: 2.0465022363\n",
      "obs F loss: 12.6535831392, pde F loss: 0.3554059397\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 227\n",
      "Training observations acc over epoch: 164.8209838867\n",
      "total loss: 1006.1339378357, total regularisd loss (sum of batches): 44269.8037719727\n",
      "obs A loss: 4.1936909184, pde A loss: 8.8316039443\n",
      "obs B loss: 10.1814272851, pde B loss: 0.9287326336\n",
      "obs C loss: 1.8941679429, pde C loss: 0.2608815599\n",
      "obs D loss: 853.0831527710, pde D loss: 4.9403728880\n",
      "obs E loss: 107.4290030003, pde E loss: 1.9114039652\n",
      "obs F loss: 12.1442764997, pde F loss: 0.3352199639\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 228\n",
      "Training observations acc over epoch: 164.2575073242\n",
      "total loss: 1001.6362895966, total regularisd loss (sum of batches): 44069.1295166016\n",
      "obs A loss: 4.1012622789, pde A loss: 9.2443974763\n",
      "obs B loss: 10.1325969994, pde B loss: 1.0283155832\n",
      "obs C loss: 1.8922391254, pde C loss: 0.2873968240\n",
      "obs D loss: 850.3834457397, pde D loss: 3.3890247680\n",
      "obs E loss: 107.3617812395, pde E loss: 1.8448097445\n",
      "obs F loss: 11.6736510843, pde F loss: 0.2973710415\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 229\n",
      "Training observations acc over epoch: 163.5786285400\n",
      "total loss: 998.0216007233, total regularisd loss (sum of batches): 43912.3797607422\n",
      "obs A loss: 3.9962162152, pde A loss: 9.1593723893\n",
      "obs B loss: 10.0916731060, pde B loss: 1.1407551691\n",
      "obs C loss: 1.8867883198, pde C loss: 0.3154556770\n",
      "obs D loss: 846.9691581726, pde D loss: 3.7663413212\n",
      "obs E loss: 107.2052586079, pde E loss: 1.8743158169\n",
      "obs F loss: 11.3226434588, pde F loss: 0.2936312612\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.83s\n",
      "\n",
      "Start of epoch 230\n",
      "Training observations acc over epoch: 163.3011932373\n",
      "total loss: 998.3145351410, total regularisd loss (sum of batches): 43925.4953613281\n",
      "obs A loss: 3.9506855831, pde A loss: 10.0568644255\n",
      "obs B loss: 10.0243313462, pde B loss: 1.3032708205\n",
      "obs C loss: 1.8805725835, pde C loss: 0.3322173343\n",
      "obs D loss: 845.8100538254, pde D loss: 4.3752720430\n",
      "obs E loss: 107.0720709562, pde E loss: 2.1399243549\n",
      "obs F loss: 11.0693668127, pde F loss: 0.2999124648\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 231\n",
      "Training observations acc over epoch: 162.6107025146\n",
      "total loss: 994.7327213287, total regularisd loss (sum of batches): 43768.1133422852\n",
      "obs A loss: 3.9862211496, pde A loss: 10.6306219846\n",
      "obs B loss: 9.9892131388, pde B loss: 1.4068598226\n",
      "obs C loss: 1.8819592129, pde C loss: 0.3455894594\n",
      "obs D loss: 842.1331863403, pde D loss: 4.0631249845\n",
      "obs E loss: 106.8288879395, pde E loss: 2.2987987027\n",
      "obs F loss: 10.8447880000, pde F loss: 0.3234680672\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.53s\n",
      "\n",
      "Start of epoch 232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 162.5189971924\n",
      "total loss: 991.5218830109, total regularisd loss (sum of batches): 43626.3918457031\n",
      "obs A loss: 3.9649017453, pde A loss: 9.4601896107\n",
      "obs B loss: 9.9666887075, pde B loss: 1.2991479859\n",
      "obs C loss: 1.8806768730, pde C loss: 0.3125565159\n",
      "obs D loss: 841.7492008209, pde D loss: 3.1240225621\n",
      "obs E loss: 106.9185034037, pde E loss: 1.9049712531\n",
      "obs F loss: 10.6340323389, pde F loss: 0.3069902183\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 233\n",
      "Training observations acc over epoch: 162.2485809326\n",
      "total loss: 990.5963249207, total regularisd loss (sum of batches): 43589.0662231445\n",
      "obs A loss: 3.9506379887, pde A loss: 9.9459772855\n",
      "obs B loss: 9.9485000074, pde B loss: 1.2969060335\n",
      "obs C loss: 1.8802113943, pde C loss: 0.3090080344\n",
      "obs D loss: 840.3727817535, pde D loss: 3.3267019689\n",
      "obs E loss: 106.8888596296, pde E loss: 1.9058529325\n",
      "obs F loss: 10.4505153298, pde F loss: 0.3203665689\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 234\n",
      "Training observations acc over epoch: 161.8911895752\n",
      "total loss: 994.6379222870, total regularisd loss (sum of batches): 43762.1441040039\n",
      "obs A loss: 3.9562920928, pde A loss: 13.4833303243\n",
      "obs B loss: 9.9331113249, pde B loss: 1.3981293067\n",
      "obs C loss: 1.8804407828, pde C loss: 0.3510663835\n",
      "obs D loss: 838.3431777954, pde D loss: 5.3116993494\n",
      "obs E loss: 106.9121670723, pde E loss: 2.4057564326\n",
      "obs F loss: 10.3220372945, pde F loss: 0.3407170749\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 235\n",
      "Training observations acc over epoch: 161.8486480713\n",
      "total loss: 989.4723911285, total regularisd loss (sum of batches): 43536.7318725586\n",
      "obs A loss: 3.9131101817, pde A loss: 11.4606966525\n",
      "obs B loss: 9.9109949321, pde B loss: 1.3026762567\n",
      "obs C loss: 1.8784322236, pde C loss: 0.2963925162\n",
      "obs D loss: 838.4062614441, pde D loss: 3.0741945729\n",
      "obs E loss: 106.7760192156, pde E loss: 1.9318311736\n",
      "obs F loss: 10.2070203125, pde F loss: 0.3147601211\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.26s\n",
      "\n",
      "Start of epoch 236\n",
      "Training observations acc over epoch: 161.2944488525\n",
      "total loss: 984.6117057800, total regularisd loss (sum of batches): 43315.6448974609\n",
      "obs A loss: 3.8090698123, pde A loss: 9.6496625990\n",
      "obs B loss: 9.8596630543, pde B loss: 1.2343791369\n",
      "obs C loss: 1.8795634732, pde C loss: 0.3039167938\n",
      "obs D loss: 835.5409240723, pde D loss: 3.5149445161\n",
      "obs E loss: 106.7366698980, pde E loss: 1.7936425693\n",
      "obs F loss: 9.9408670366, pde F loss: 0.3483937518\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 237\n",
      "Training observations acc over epoch: 169.8714294434\n",
      "total loss: 1354.7541084290, total regularisd loss (sum of batches): 59598.7633056641\n",
      "obs A loss: 4.5832575709, pde A loss: 241.2851824015\n",
      "obs B loss: 10.5085280985, pde B loss: 21.9887143951\n",
      "obs C loss: 1.9571910165, pde C loss: 4.8420172012\n",
      "obs D loss: 879.5366859436, pde D loss: 21.1002781838\n",
      "obs E loss: 108.1609208584, pde E loss: 44.0250799749\n",
      "obs F loss: 14.4819821119, pde F loss: 2.2842581552\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 238\n",
      "Training observations acc over epoch: 181.6552734375\n",
      "total loss: 1147.6661014557, total regularisd loss (sum of batches): 50489.2107543945\n",
      "obs A loss: 4.8717578575, pde A loss: 26.0580449700\n",
      "obs B loss: 11.3181904703, pde B loss: 5.4796129465\n",
      "obs C loss: 2.4402216338, pde C loss: 1.5866824519\n",
      "obs D loss: 933.0710411072, pde D loss: 12.4874370918\n",
      "obs E loss: 110.7577090263, pde E loss: 10.3047447354\n",
      "obs F loss: 27.4726872742, pde F loss: 1.8179780245\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 239\n",
      "Training observations acc over epoch: 173.8287353516\n",
      "total loss: 1065.4774322510, total regularisd loss (sum of batches): 46887.2643432617\n",
      "obs A loss: 4.3011989966, pde A loss: 12.2915714234\n",
      "obs B loss: 10.7393838316, pde B loss: 1.3409988526\n",
      "obs C loss: 1.9606859908, pde C loss: 0.3765556794\n",
      "obs D loss: 897.8024826050, pde D loss: 5.0118346736\n",
      "obs E loss: 108.6110092402, pde E loss: 2.9897174761\n",
      "obs F loss: 19.5575719774, pde F loss: 0.4944137670\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 240\n",
      "Training observations acc over epoch: 170.1870574951\n",
      "total loss: 1039.7895660400, total regularisd loss (sum of batches): 45752.2775268555\n",
      "obs A loss: 4.2620516941, pde A loss: 10.4089850038\n",
      "obs B loss: 10.3846208900, pde B loss: 1.5266273730\n",
      "obs C loss: 1.9159035310, pde C loss: 0.3528590156\n",
      "obs D loss: 879.3870716095, pde D loss: 3.2323440388\n",
      "obs E loss: 108.1613659859, pde E loss: 2.7478801943\n",
      "obs F loss: 17.0113019347, pde F loss: 0.3985549747\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 241\n",
      "Training observations acc over epoch: 167.8158721924\n",
      "total loss: 1027.0779190063, total regularisd loss (sum of batches): 45187.6754150391\n",
      "obs A loss: 4.1861415505, pde A loss: 10.7876172215\n",
      "obs B loss: 10.2200018913, pde B loss: 1.7962949462\n",
      "obs C loss: 1.8814205807, pde C loss: 0.3757543024\n",
      "obs D loss: 867.7893600464, pde D loss: 4.1501002386\n",
      "obs E loss: 107.7159519196, pde E loss: 2.7092906348\n",
      "obs F loss: 15.1022952497, pde F loss: 0.3637034437\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 166.3031463623\n",
      "total loss: 1015.9294605255, total regularisd loss (sum of batches): 44702.3461303711\n",
      "obs A loss: 4.1558917910, pde A loss: 9.7520251274\n",
      "obs B loss: 10.1467395574, pde B loss: 1.6467264313\n",
      "obs C loss: 1.8900234457, pde C loss: 0.3389644749\n",
      "obs D loss: 860.5405082703, pde D loss: 3.8510397375\n",
      "obs E loss: 107.4700658321, pde E loss: 2.1985868178\n",
      "obs F loss: 13.6155231893, pde F loss: 0.3233685358\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 243\n",
      "Training observations acc over epoch: 165.4581146240\n",
      "total loss: 1010.9548301697, total regularisd loss (sum of batches): 44480.6801757812\n",
      "obs A loss: 4.0586531013, pde A loss: 9.7192518860\n",
      "obs B loss: 10.1099714339, pde B loss: 1.4724205509\n",
      "obs C loss: 1.8950686529, pde C loss: 0.3565377430\n",
      "obs D loss: 857.0288295746, pde D loss: 4.0738377981\n",
      "obs E loss: 107.1628025770, pde E loss: 2.2686207220\n",
      "obs F loss: 12.4933319092, pde F loss: 0.3155040187\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 244\n",
      "Training observations acc over epoch: 164.7991943359\n",
      "total loss: 1009.0802764893, total regularisd loss (sum of batches): 44405.3316040039\n",
      "obs A loss: 3.9739070758, pde A loss: 10.3019934893\n",
      "obs B loss: 10.0679027289, pde B loss: 1.4803697485\n",
      "obs C loss: 1.8924260288, pde C loss: 0.4005853552\n",
      "obs D loss: 853.7373676300, pde D loss: 5.0645249598\n",
      "obs E loss: 107.2173167467, pde E loss: 2.6705681048\n",
      "obs F loss: 11.9061923921, pde F loss: 0.3671222785\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.79s\n",
      "\n",
      "Start of epoch 245\n",
      "Training observations acc over epoch: 163.8847961426\n",
      "total loss: 1000.3972511292, total regularisd loss (sum of batches): 44016.5996093750\n",
      "obs A loss: 3.9369910061, pde A loss: 9.5551853478\n",
      "obs B loss: 9.9934265614, pde B loss: 1.4428143539\n",
      "obs C loss: 1.8900461625, pde C loss: 0.3554189429\n",
      "obs D loss: 849.0249862671, pde D loss: 3.2387680523\n",
      "obs E loss: 107.0016087294, pde E loss: 2.1451744214\n",
      "obs F loss: 11.4618313015, pde F loss: 0.3510099142\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 246\n",
      "Training observations acc over epoch: 163.5227050781\n",
      "total loss: 999.0562553406, total regularisd loss (sum of batches): 43962.5066528320\n",
      "obs A loss: 3.8748760223, pde A loss: 9.2859784365\n",
      "obs B loss: 9.9454009235, pde B loss: 1.3749830350\n",
      "obs C loss: 1.8890697118, pde C loss: 0.3566681119\n",
      "obs D loss: 847.3668956757, pde D loss: 4.2483073398\n",
      "obs E loss: 106.9860042334, pde E loss: 2.2961189933\n",
      "obs F loss: 11.0739647448, pde F loss: 0.3580084969\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 247\n",
      "Training observations acc over epoch: 162.9427337646\n",
      "total loss: 994.1897487640, total regularisd loss (sum of batches): 43743.3107910156\n",
      "obs A loss: 3.7739790082, pde A loss: 8.7642706782\n",
      "obs B loss: 9.8652107716, pde B loss: 1.3315016367\n",
      "obs C loss: 1.8884435222, pde C loss: 0.3408626956\n",
      "obs D loss: 844.5632762909, pde D loss: 3.7426969334\n",
      "obs E loss: 106.8515253067, pde E loss: 1.9810379334\n",
      "obs F loss: 10.7139685750, pde F loss: 0.3729732353\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 248\n",
      "Training observations acc over epoch: 162.5714263916\n",
      "total loss: 991.2105541229, total regularisd loss (sum of batches): 43616.3893432617\n",
      "obs A loss: 3.6757398918, pde A loss: 8.7271017730\n",
      "obs B loss: 9.7935611606, pde B loss: 1.2521154676\n",
      "obs C loss: 1.8888509423, pde C loss: 0.3458139389\n",
      "obs D loss: 842.9071063995, pde D loss: 3.2435134575\n",
      "obs E loss: 106.8541723490, pde E loss: 1.8570763208\n",
      "obs F loss: 10.3092151135, pde F loss: 0.3562799660\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 249\n",
      "Training observations acc over epoch: 161.8773193359\n",
      "total loss: 987.8234939575, total regularisd loss (sum of batches): 43463.5447387695\n",
      "obs A loss: 3.6653050259, pde A loss: 9.0431703478\n",
      "obs B loss: 9.7391187698, pde B loss: 1.1033602506\n",
      "obs C loss: 1.8913182188, pde C loss: 0.3387209508\n",
      "obs D loss: 839.1335105896, pde D loss: 3.8365235552\n",
      "obs E loss: 106.8125617504, pde E loss: 1.8797317743\n",
      "obs F loss: 10.0220818967, pde F loss: 0.3580791336\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 250\n",
      "Training observations acc over epoch: 161.3485717773\n",
      "total loss: 985.5569667816, total regularisd loss (sum of batches): 43361.9179077148\n",
      "obs A loss: 3.5277143866, pde A loss: 9.0603542030\n",
      "obs B loss: 9.6795428991, pde B loss: 1.1289973482\n",
      "obs C loss: 1.8860292025, pde C loss: 0.3584512938\n",
      "obs D loss: 836.5392894745, pde D loss: 4.4478131570\n",
      "obs E loss: 106.6614116430, pde E loss: 2.1200909950\n",
      "obs F loss: 9.7974514812, pde F loss: 0.3498120098\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 251\n",
      "Training observations acc over epoch: 161.2882537842\n",
      "total loss: 984.9505386353, total regularisd loss (sum of batches): 43338.7079467773\n",
      "obs A loss: 3.4780318365, pde A loss: 9.6074134260\n",
      "obs B loss: 9.6287714839, pde B loss: 1.1228126679\n",
      "obs C loss: 1.8847298957, pde C loss: 0.3312550653\n",
      "obs D loss: 836.4222545624, pde D loss: 3.8631627783\n",
      "obs E loss: 106.6849834919, pde E loss: 1.9635154195\n",
      "obs F loss: 9.6309373230, pde F loss: 0.3326824885\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 160.9740600586\n",
      "total loss: 984.7402496338, total regularisd loss (sum of batches): 43332.0504760742\n",
      "obs A loss: 3.4392542988, pde A loss: 10.8860705495\n",
      "obs B loss: 9.5846987069, pde B loss: 1.2122396454\n",
      "obs C loss: 1.8840695694, pde C loss: 0.3774638781\n",
      "obs D loss: 834.7599105835, pde D loss: 3.8277376927\n",
      "obs E loss: 106.7141995430, pde E loss: 2.2716052495\n",
      "obs F loss: 9.4623523802, pde F loss: 0.3206458348\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 253\n",
      "Training observations acc over epoch: 160.4000701904\n",
      "total loss: 980.2975597382, total regularisd loss (sum of batches): 43133.1913452148\n",
      "obs A loss: 3.4170276597, pde A loss: 9.8402188569\n",
      "obs B loss: 9.5504595935, pde B loss: 1.1830170602\n",
      "obs C loss: 1.8850101102, pde C loss: 0.3509456404\n",
      "obs D loss: 831.5653991699, pde D loss: 4.0829559453\n",
      "obs E loss: 106.6795463562, pde E loss: 2.1097182892\n",
      "obs F loss: 9.3030419350, pde F loss: 0.3302186709\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.81s\n",
      "\n",
      "Start of epoch 254\n",
      "Training observations acc over epoch: 160.6266937256\n",
      "total loss: 983.1484146118, total regularisd loss (sum of batches): 43254.4882812500\n",
      "obs A loss: 3.4298123717, pde A loss: 11.3096986562\n",
      "obs B loss: 9.5416801423, pde B loss: 1.1449582390\n",
      "obs C loss: 1.8853740077, pde C loss: 0.3872393835\n",
      "obs D loss: 833.1582527161, pde D loss: 3.7483772337\n",
      "obs E loss: 106.5438369513, pde E loss: 2.4708283693\n",
      "obs F loss: 9.2011474967, pde F loss: 0.3272176790\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 255\n",
      "Training observations acc over epoch: 159.7245330811\n",
      "total loss: 974.1621189117, total regularisd loss (sum of batches): 42864.1030273438\n",
      "obs A loss: 3.3444017917, pde A loss: 9.2729494572\n",
      "obs B loss: 9.5104830414, pde B loss: 1.1147112604\n",
      "obs C loss: 1.8873300552, pde C loss: 0.3513219682\n",
      "obs D loss: 828.0109577179, pde D loss: 3.0159667842\n",
      "obs E loss: 106.5288623571, pde E loss: 1.7356422320\n",
      "obs F loss: 9.0652764142, pde F loss: 0.3242205214\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 256\n",
      "Training observations acc over epoch: 159.5870361328\n",
      "total loss: 974.9860382080, total regularisd loss (sum of batches): 42902.4061279297\n",
      "obs A loss: 3.2803786322, pde A loss: 10.1005090475\n",
      "obs B loss: 9.5039952844, pde B loss: 1.1330958549\n",
      "obs C loss: 1.8867064286, pde C loss: 0.3514658553\n",
      "obs D loss: 827.3081474304, pde D loss: 3.7187363021\n",
      "obs E loss: 106.5712947845, pde E loss: 1.8137967661\n",
      "obs F loss: 8.9717614949, pde F loss: 0.3461541594\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 257\n",
      "Training observations acc over epoch: 159.5456237793\n",
      "total loss: 976.0374145508, total regularisd loss (sum of batches): 42945.6260986328\n",
      "obs A loss: 3.1936481521, pde A loss: 10.7327561975\n",
      "obs B loss: 9.5026306510, pde B loss: 1.1976184007\n",
      "obs C loss: 1.8826042041, pde C loss: 0.3597695869\n",
      "obs D loss: 827.1675262451, pde D loss: 4.3063459657\n",
      "obs E loss: 106.6063488722, pde E loss: 1.8280170579\n",
      "obs F loss: 8.9208985269, pde F loss: 0.3392503825\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 258\n",
      "Training observations acc over epoch: 159.1059265137\n",
      "total loss: 975.3890380859, total regularisd loss (sum of batches): 42918.8226928711\n",
      "obs A loss: 3.1424169838, pde A loss: 12.9871025831\n",
      "obs B loss: 9.4930102229, pde B loss: 1.3934505191\n",
      "obs C loss: 1.8835541960, pde C loss: 0.3872627122\n",
      "obs D loss: 824.9783363342, pde D loss: 3.6689382717\n",
      "obs E loss: 106.3343883753, pde E loss: 1.9811063930\n",
      "obs F loss: 8.8038040549, pde F loss: 0.3356693415\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 259\n",
      "Training observations acc over epoch: 159.0223999023\n",
      "total loss: 973.3493976593, total regularisd loss (sum of batches): 42828.8419799805\n",
      "obs A loss: 3.1042172387, pde A loss: 11.0269963145\n",
      "obs B loss: 9.4778732657, pde B loss: 1.2924641594\n",
      "obs C loss: 1.8863067385, pde C loss: 0.3830068642\n",
      "obs D loss: 824.3788051605, pde D loss: 4.3294703774\n",
      "obs E loss: 106.5596663952, pde E loss: 1.8634109106\n",
      "obs F loss: 8.7275363207, pde F loss: 0.3196442979\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.27s\n",
      "\n",
      "Start of epoch 260\n",
      "Training observations acc over epoch: 158.9526824951\n",
      "total loss: 974.3166370392, total regularisd loss (sum of batches): 42878.9136962891\n",
      "obs A loss: 3.0622665286, pde A loss: 11.3119056076\n",
      "obs B loss: 9.4348963201, pde B loss: 1.3032016996\n",
      "obs C loss: 1.8875492103, pde C loss: 0.4694197224\n",
      "obs D loss: 824.2202529907, pde D loss: 4.9858423807\n",
      "obs E loss: 106.4672123194, pde E loss: 2.2131463736\n",
      "obs F loss: 8.6439290047, pde F loss: 0.3170112777\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.41s\n",
      "\n",
      "Start of epoch 261\n",
      "Training observations acc over epoch: 158.5607604980\n",
      "total loss: 969.9553413391, total regularisd loss (sum of batches): 42679.6273803711\n",
      "obs A loss: 3.0669742189, pde A loss: 10.6859744787\n",
      "obs B loss: 9.4007921070, pde B loss: 1.2868653927\n",
      "obs C loss: 1.8864725772, pde C loss: 0.3741712151\n",
      "obs D loss: 821.9971532822, pde D loss: 4.1972078383\n",
      "obs E loss: 106.4915527105, pde E loss: 1.7428247966\n",
      "obs F loss: 8.5214711279, pde F loss: 0.3038767027\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.37s\n",
      "\n",
      "Start of epoch 262\n",
      "Training observations acc over epoch: 158.1978302002\n",
      "total loss: 967.6772289276, total regularisd loss (sum of batches): 42579.8087158203\n",
      "obs A loss: 3.0372130871, pde A loss: 10.7285396904\n",
      "obs B loss: 9.3235474974, pde B loss: 1.3051127829\n",
      "obs C loss: 1.8973620646, pde C loss: 0.3876369158\n",
      "obs D loss: 820.0566978455, pde D loss: 4.1197414473\n",
      "obs E loss: 106.4695446491, pde E loss: 1.6475401409\n",
      "obs F loss: 8.4025936425, pde F loss: 0.3016920043\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.43s\n",
      "\n",
      "Start of epoch 263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 157.9136505127\n",
      "total loss: 969.3195419312, total regularisd loss (sum of batches): 42648.7169189453\n",
      "obs A loss: 3.0697260574, pde A loss: 13.4453629255\n",
      "obs B loss: 9.3021243811, pde B loss: 1.5354915839\n",
      "obs C loss: 1.8942469265, pde C loss: 0.4206498661\n",
      "obs D loss: 818.2953386307, pde D loss: 4.0666960143\n",
      "obs E loss: 106.5459281206, pde E loss: 2.0605348572\n",
      "obs F loss: 8.3746019006, pde F loss: 0.3088398627\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 264\n",
      "Training observations acc over epoch: 158.1315460205\n",
      "total loss: 969.7244796753, total regularisd loss (sum of batches): 42669.1481933594\n",
      "obs A loss: 3.1191353165, pde A loss: 13.5266495198\n",
      "obs B loss: 9.2860472053, pde B loss: 1.4891921617\n",
      "obs C loss: 1.8921198193, pde C loss: 0.4407531302\n",
      "obs D loss: 819.6649045944, pde D loss: 3.1041813642\n",
      "obs E loss: 106.4682428837, pde E loss: 2.0853908118\n",
      "obs F loss: 8.3586541265, pde F loss: 0.2891986100\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 265\n",
      "Training observations acc over epoch: 157.8650054932\n",
      "total loss: 968.5197296143, total regularisd loss (sum of batches): 42610.0797729492\n",
      "obs A loss: 3.0922236890, pde A loss: 12.9820014834\n",
      "obs B loss: 9.2519234717, pde B loss: 1.4111464359\n",
      "obs C loss: 1.8926234767, pde C loss: 0.3694991288\n",
      "obs D loss: 818.0972213745, pde D loss: 4.5277211778\n",
      "obs E loss: 106.5337481499, pde E loss: 1.7598146927\n",
      "obs F loss: 8.3223693818, pde F loss: 0.2794315950\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.35s\n",
      "\n",
      "Start of epoch 266\n",
      "Training observations acc over epoch: 158.6387939453\n",
      "total loss: 1160.7214565277, total regularisd loss (sum of batches): 51119.6018676758\n",
      "obs A loss: 3.4182798099, pde A loss: 157.5071283132\n",
      "obs B loss: 9.3224277794, pde B loss: 16.7447401397\n",
      "obs C loss: 1.8971960563, pde C loss: 2.7783932262\n",
      "obs D loss: 822.1695804596, pde D loss: 10.3718562052\n",
      "obs E loss: 106.6425404549, pde E loss: 20.8323490042\n",
      "obs F loss: 8.3828454465, pde F loss: 0.6541229570\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.27s\n",
      "\n",
      "Start of epoch 267\n",
      "Training observations acc over epoch: 190.5448608398\n",
      "total loss: 1339.3584213257, total regularisd loss (sum of batches): 58920.2613525391\n",
      "obs A loss: 4.1770563982, pde A loss: 102.9868037105\n",
      "obs B loss: 11.4570930302, pde B loss: 22.4258111380\n",
      "obs C loss: 2.6179231256, pde C loss: 3.9682896212\n",
      "obs D loss: 978.2286872864, pde D loss: 28.8777325451\n",
      "obs E loss: 115.7382547855, pde E loss: 34.2095544785\n",
      "obs F loss: 31.0503477752, pde F loss: 3.6208759826\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 268\n",
      "Training observations acc over epoch: 181.6304779053\n",
      "total loss: 1122.2768688202, total regularisd loss (sum of batches): 49374.3588867188\n",
      "obs A loss: 3.9386973307, pde A loss: 16.1142820716\n",
      "obs B loss: 10.7415061593, pde B loss: 1.6206066813\n",
      "obs C loss: 2.0798641071, pde C loss: 1.1050699688\n",
      "obs D loss: 932.2510032654, pde D loss: 6.8664513081\n",
      "obs E loss: 112.7479629517, pde E loss: 6.0392025709\n",
      "obs F loss: 28.0237511992, pde F loss: 0.7484696992\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 269\n",
      "Training observations acc over epoch: 175.0576629639\n",
      "total loss: 1073.7489738464, total regularisd loss (sum of batches): 47245.4774169922\n",
      "obs A loss: 3.6190335602, pde A loss: 12.3202460557\n",
      "obs B loss: 10.3643962294, pde B loss: 1.4766273983\n",
      "obs C loss: 1.9675685279, pde C loss: 0.6442752080\n",
      "obs D loss: 901.3521213531, pde D loss: 3.5488731340\n",
      "obs E loss: 110.3147752285, pde E loss: 4.9593160525\n",
      "obs F loss: 22.7281440794, pde F loss: 0.4535896052\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.69s\n",
      "\n",
      "Start of epoch 270\n",
      "Training observations acc over epoch: 170.8114624023\n",
      "total loss: 1045.8471870422, total regularisd loss (sum of batches): 46012.8718872070\n",
      "obs A loss: 3.2427633628, pde A loss: 11.3536480665\n",
      "obs B loss: 10.0020602345, pde B loss: 1.5703637153\n",
      "obs C loss: 1.9008656517, pde C loss: 0.4181806990\n",
      "obs D loss: 881.4813404083, pde D loss: 4.3136891313\n",
      "obs E loss: 109.3339653015, pde E loss: 2.9708874896\n",
      "obs F loss: 18.9076394737, pde F loss: 0.3517850703\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.82s\n",
      "\n",
      "Start of epoch 271\n",
      "Training observations acc over epoch: 166.8658142090\n",
      "total loss: 1019.7076644897, total regularisd loss (sum of batches): 44865.2102050781\n",
      "obs A loss: 2.9274736382, pde A loss: 10.6069189310\n",
      "obs B loss: 9.7257723212, pde B loss: 1.7153061833\n",
      "obs C loss: 1.9019162450, pde C loss: 0.3682887824\n",
      "obs D loss: 862.6721477509, pde D loss: 3.6156069450\n",
      "obs E loss: 108.6774785519, pde E loss: 1.8509024642\n",
      "obs F loss: 15.2902630270, pde F loss: 0.3555965303\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 272\n",
      "Training observations acc over epoch: 164.5632476807\n",
      "total loss: 1005.8080596924, total regularisd loss (sum of batches): 44258.2979125977\n",
      "obs A loss: 2.8534987718, pde A loss: 9.6994758248\n",
      "obs B loss: 9.5543860346, pde B loss: 1.6999651864\n",
      "obs C loss: 1.9152994603, pde C loss: 0.3836378395\n",
      "obs D loss: 851.6829490662, pde D loss: 4.5494967140\n",
      "obs E loss: 108.2068808079, pde E loss: 1.7628840096\n",
      "obs F loss: 13.1664324105, pde F loss: 0.3331615869\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 163.6126556396\n",
      "total loss: 997.9216880798, total regularisd loss (sum of batches): 43910.7433471680\n",
      "obs A loss: 2.8358058408, pde A loss: 8.6497392803\n",
      "obs B loss: 9.4781606346, pde B loss: 1.7705540657\n",
      "obs C loss: 1.9149314091, pde C loss: 0.3709584195\n",
      "obs D loss: 847.6472072601, pde D loss: 3.4952372126\n",
      "obs E loss: 107.8184869289, pde E loss: 1.6790516004\n",
      "obs F loss: 11.9813083410, pde F loss: 0.2802382959\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 274\n",
      "Training observations acc over epoch: 162.6660156250\n",
      "total loss: 992.5506210327, total regularisd loss (sum of batches): 43677.3857421875\n",
      "obs A loss: 2.8300284930, pde A loss: 8.7864512056\n",
      "obs B loss: 9.3912386745, pde B loss: 1.7726193704\n",
      "obs C loss: 1.9059335776, pde C loss: 0.3217939795\n",
      "obs D loss: 842.9951858521, pde D loss: 3.7853220105\n",
      "obs E loss: 107.6979999542, pde E loss: 1.6331802327\n",
      "obs F loss: 11.1760000885, pde F loss: 0.2548608677\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 275\n",
      "Training observations acc over epoch: 161.9447631836\n",
      "total loss: 988.0760421753, total regularisd loss (sum of batches): 43478.7638549805\n",
      "obs A loss: 2.9193894789, pde A loss: 8.5528210700\n",
      "obs B loss: 9.3386884332, pde B loss: 1.6350529008\n",
      "obs C loss: 1.8983257618, pde C loss: 0.3106669844\n",
      "obs D loss: 839.3059272766, pde D loss: 4.0708926730\n",
      "obs E loss: 107.5123994350, pde E loss: 1.5937490221\n",
      "obs F loss: 10.6938679367, pde F loss: 0.2442518319\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 276\n",
      "Training observations acc over epoch: 161.7248077393\n",
      "total loss: 986.9882450104, total regularisd loss (sum of batches): 43425.6853637695\n",
      "obs A loss: 2.9072843753, pde A loss: 8.6070529222\n",
      "obs B loss: 9.2785885483, pde B loss: 1.5188173819\n",
      "obs C loss: 1.8950183280, pde C loss: 0.2868381618\n",
      "obs D loss: 838.5618495941, pde D loss: 4.3566466197\n",
      "obs E loss: 107.3670387268, pde E loss: 1.6387428399\n",
      "obs F loss: 10.3393660188, pde F loss: 0.2310205181\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.40s\n",
      "\n",
      "Start of epoch 277\n",
      "Training observations acc over epoch: 161.1930694580\n",
      "total loss: 984.7183551788, total regularisd loss (sum of batches): 43330.0633544922\n",
      "obs A loss: 2.8771357611, pde A loss: 9.3846268058\n",
      "obs B loss: 9.1966390461, pde B loss: 1.6045025811\n",
      "obs C loss: 1.8973557688, pde C loss: 0.3054708368\n",
      "obs D loss: 835.9018173218, pde D loss: 4.4487855881\n",
      "obs E loss: 107.2620918751, pde E loss: 1.5800079182\n",
      "obs F loss: 10.0231600106, pde F loss: 0.2367528761\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 278\n",
      "Training observations acc over epoch: 160.0760955811\n",
      "total loss: 977.9040699005, total regularisd loss (sum of batches): 43033.6713867188\n",
      "obs A loss: 2.8285919800, pde A loss: 8.9714499563\n",
      "obs B loss: 9.2273492217, pde B loss: 1.6559419073\n",
      "obs C loss: 1.9107151926, pde C loss: 0.3484342708\n",
      "obs D loss: 829.6685390472, pde D loss: 4.3455990441\n",
      "obs E loss: 107.1529303789, pde E loss: 1.9086281098\n",
      "obs F loss: 9.6683932394, pde F loss: 0.2174941553\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 279\n",
      "Training observations acc over epoch: 159.7635498047\n",
      "total loss: 976.9684658051, total regularisd loss (sum of batches): 42984.7963256836\n",
      "obs A loss: 2.7754284181, pde A loss: 9.3012233824\n",
      "obs B loss: 9.1964796036, pde B loss: 1.6625714935\n",
      "obs C loss: 1.9148771670, pde C loss: 0.3350836672\n",
      "obs D loss: 828.2334833145, pde D loss: 5.0666488409\n",
      "obs E loss: 107.0057959557, pde E loss: 1.7895674556\n",
      "obs F loss: 9.4552619457, pde F loss: 0.2320397994\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.76s\n",
      "\n",
      "Start of epoch 280\n",
      "Training observations acc over epoch: 159.5213470459\n",
      "total loss: 972.2775268555, total regularisd loss (sum of batches): 42780.6705322266\n",
      "obs A loss: 2.7479958236, pde A loss: 8.5146456957\n",
      "obs B loss: 9.1791013181, pde B loss: 1.5173935778\n",
      "obs C loss: 1.9104748070, pde C loss: 0.3082817043\n",
      "obs D loss: 827.1195087433, pde D loss: 3.0747745372\n",
      "obs E loss: 106.9163846970, pde E loss: 1.5163141992\n",
      "obs F loss: 9.2544909418, pde F loss: 0.2181536383\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 281\n",
      "Training observations acc over epoch: 159.0687713623\n",
      "total loss: 972.0659103394, total regularisd loss (sum of batches): 42769.6525878906\n",
      "obs A loss: 2.7262492552, pde A loss: 8.5074707866\n",
      "obs B loss: 9.1504398733, pde B loss: 1.5429103319\n",
      "obs C loss: 1.9099001735, pde C loss: 0.3103914065\n",
      "obs D loss: 824.6573457718, pde D loss: 5.5240196697\n",
      "obs E loss: 106.8914825916, pde E loss: 1.5239365846\n",
      "obs F loss: 9.0771778971, pde F loss: 0.2445912226\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.80s\n",
      "\n",
      "Start of epoch 282\n",
      "Training observations acc over epoch: 158.7854156494\n",
      "total loss: 971.2068595886, total regularisd loss (sum of batches): 42733.3712158203\n",
      "obs A loss: 2.7322571985, pde A loss: 10.1272947788\n",
      "obs B loss: 9.1483284533, pde B loss: 1.7246337608\n",
      "obs C loss: 1.9097111654, pde C loss: 0.3480035597\n",
      "obs D loss: 823.2934684753, pde D loss: 4.2059288584\n",
      "obs E loss: 106.6898927689, pde E loss: 1.8274587244\n",
      "obs F loss: 8.9388590753, pde F loss: 0.2610334372\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 283\n",
      "Training observations acc over epoch: 158.7454528809\n",
      "total loss: 970.3843612671, total regularisd loss (sum of batches): 42698.9701538086\n",
      "obs A loss: 2.6908445396, pde A loss: 8.8173201978\n",
      "obs B loss: 9.1237250865, pde B loss: 1.6684036180\n",
      "obs C loss: 1.9066990763, pde C loss: 0.3087646905\n",
      "obs D loss: 823.1709747314, pde D loss: 5.2697647698\n",
      "obs E loss: 106.7843370438, pde E loss: 1.5929359328\n",
      "obs F loss: 8.7961144894, pde F loss: 0.2544831978\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.83s\n",
      "\n",
      "Start of epoch 284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 158.0404815674\n",
      "total loss: 963.4377632141, total regularisd loss (sum of batches): 42387.2947998047\n",
      "obs A loss: 2.6759563759, pde A loss: 8.8797658235\n",
      "obs B loss: 9.1290444285, pde B loss: 1.4864435289\n",
      "obs C loss: 1.9048215039, pde C loss: 0.2859308426\n",
      "obs D loss: 819.2509822845, pde D loss: 2.9551639166\n",
      "obs E loss: 106.6341500282, pde E loss: 1.3560239989\n",
      "obs F loss: 8.6481315792, pde F loss: 0.2313404712\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 285\n",
      "Training observations acc over epoch: 158.2541503906\n",
      "total loss: 966.3616962433, total regularisd loss (sum of batches): 42515.0007934570\n",
      "obs A loss: 2.6665210202, pde A loss: 9.4257709533\n",
      "obs B loss: 9.1245838553, pde B loss: 1.6162216514\n",
      "obs C loss: 1.9035170786, pde C loss: 0.3269345225\n",
      "obs D loss: 820.6502809525, pde D loss: 3.6433437094\n",
      "obs E loss: 106.5888649225, pde E loss: 1.5823665261\n",
      "obs F loss: 8.5910831988, pde F loss: 0.2422133279\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 286\n",
      "Training observations acc over epoch: 157.9293060303\n",
      "total loss: 964.2755966187, total regularisd loss (sum of batches): 42431.4415893555\n",
      "obs A loss: 2.6744057052, pde A loss: 9.5385646969\n",
      "obs B loss: 9.1428080350, pde B loss: 1.5768967234\n",
      "obs C loss: 1.9010902867, pde C loss: 0.2798005920\n",
      "obs D loss: 818.7455120087, pde D loss: 3.7457539178\n",
      "obs E loss: 106.5946348906, pde E loss: 1.3279158268\n",
      "obs F loss: 8.5173961669, pde F loss: 0.2308137673\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 287\n",
      "Training observations acc over epoch: 157.6890411377\n",
      "total loss: 963.8451232910, total regularisd loss (sum of batches): 42413.6733398438\n",
      "obs A loss: 2.6546622962, pde A loss: 10.5979771167\n",
      "obs B loss: 9.1119798869, pde B loss: 1.7041489091\n",
      "obs C loss: 1.9004638307, pde C loss: 0.2990069008\n",
      "obs D loss: 817.5348787308, pde D loss: 3.4157289825\n",
      "obs E loss: 106.4711325169, pde E loss: 1.4643661268\n",
      "obs F loss: 8.4610612243, pde F loss: 0.2297272370\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 288\n",
      "Training observations acc over epoch: 157.8181304932\n",
      "total loss: 966.0774326324, total regularisd loss (sum of batches): 42503.7961425781\n",
      "obs A loss: 2.6404893249, pde A loss: 9.8375559151\n",
      "obs B loss: 9.1091849357, pde B loss: 1.5540971514\n",
      "obs C loss: 1.8990985099, pde C loss: 0.2822081260\n",
      "obs D loss: 818.2971925735, pde D loss: 5.7552358843\n",
      "obs E loss: 106.5210604668, pde E loss: 1.4999586307\n",
      "obs F loss: 8.4416216910, pde F loss: 0.2397359000\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 289\n",
      "Training observations acc over epoch: 157.9744262695\n",
      "total loss: 968.7243804932, total regularisd loss (sum of batches): 42626.2159423828\n",
      "obs A loss: 2.6419979334, pde A loss: 10.9511362910\n",
      "obs B loss: 9.0984781981, pde B loss: 1.6627740283\n",
      "obs C loss: 1.8980363067, pde C loss: 0.2944548191\n",
      "obs D loss: 819.2302246094, pde D loss: 6.0379188955\n",
      "obs E loss: 106.5635360479, pde E loss: 1.6843170524\n",
      "obs F loss: 8.4142105728, pde F loss: 0.2473030025\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 290\n",
      "Training observations acc over epoch: 157.2725830078\n",
      "total loss: 960.1705703735, total regularisd loss (sum of batches): 42246.6369018555\n",
      "obs A loss: 2.5942888446, pde A loss: 9.4649410397\n",
      "obs B loss: 9.0771995336, pde B loss: 1.5317280758\n",
      "obs C loss: 1.8952875342, pde C loss: 0.2652384718\n",
      "obs D loss: 815.2251205444, pde D loss: 3.6462129876\n",
      "obs E loss: 106.4868664742, pde E loss: 1.4049575124\n",
      "obs F loss: 8.3567461669, pde F loss: 0.2219973528\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 291\n",
      "Training observations acc over epoch: 157.4561157227\n",
      "total loss: 962.0581626892, total regularisd loss (sum of batches): 42328.4091186523\n",
      "obs A loss: 2.5689454377, pde A loss: 10.2451588959\n",
      "obs B loss: 9.0624174029, pde B loss: 1.5917962249\n",
      "obs C loss: 1.8932126127, pde C loss: 0.2749176249\n",
      "obs D loss: 816.5039157867, pde D loss: 3.5712920763\n",
      "obs E loss: 106.3845677376, pde E loss: 1.4328016695\n",
      "obs F loss: 8.3235765994, pde F loss: 0.2055451164\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 292\n",
      "Training observations acc over epoch: 157.3645629883\n",
      "total loss: 961.6718673706, total regularisd loss (sum of batches): 42310.9923706055\n",
      "obs A loss: 2.5493015349, pde A loss: 9.4446855038\n",
      "obs B loss: 9.0639356971, pde B loss: 1.4890175145\n",
      "obs C loss: 1.8925778680, pde C loss: 0.2640324892\n",
      "obs D loss: 816.0277729034, pde D loss: 4.6281380542\n",
      "obs E loss: 106.3570822477, pde E loss: 1.4362884630\n",
      "obs F loss: 8.2965949774, pde F loss: 0.2224468791\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 293\n",
      "Training observations acc over epoch: 157.0193939209\n",
      "total loss: 961.3433036804, total regularisd loss (sum of batches): 42298.3197021484\n",
      "obs A loss: 2.5467013679, pde A loss: 10.0208542496\n",
      "obs B loss: 9.0630445480, pde B loss: 1.5665103514\n",
      "obs C loss: 1.8917551450, pde C loss: 0.2917438643\n",
      "obs D loss: 813.9248609543, pde D loss: 5.6380834728\n",
      "obs E loss: 106.4502527714, pde E loss: 1.4731930513\n",
      "obs F loss: 8.2396468371, pde F loss: 0.2366520707\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.39s\n",
      "\n",
      "Start of epoch 294\n",
      "Training observations acc over epoch: 157.0945892334\n",
      "total loss: 958.8240947723, total regularisd loss (sum of batches): 42191.1744384766\n",
      "obs A loss: 2.5271792375, pde A loss: 9.4558703452\n",
      "obs B loss: 9.0468477607, pde B loss: 1.5049258992\n",
      "obs C loss: 1.8916481696, pde C loss: 0.2584732687\n",
      "obs D loss: 814.4658231735, pde D loss: 3.5334810354\n",
      "obs E loss: 106.4222333431, pde E loss: 1.3086735271\n",
      "obs F loss: 8.2134879380, pde F loss: 0.1954514100\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 157.0089569092\n",
      "total loss: 958.9266567230, total regularisd loss (sum of batches): 42187.4060058594\n",
      "obs A loss: 2.5258151665, pde A loss: 10.0725411624\n",
      "obs B loss: 9.0348332375, pde B loss: 1.5308470260\n",
      "obs C loss: 1.8916065712, pde C loss: 0.2801984306\n",
      "obs D loss: 814.1530351639, pde D loss: 3.4678295627\n",
      "obs E loss: 106.2507979870, pde E loss: 1.3231378999\n",
      "obs F loss: 8.1977394372, pde F loss: 0.1982746203\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 296\n",
      "Training observations acc over epoch: 156.8206481934\n",
      "total loss: 958.6487522125, total regularisd loss (sum of batches): 42175.3718261719\n",
      "obs A loss: 2.5266150013, pde A loss: 11.1651318669\n",
      "obs B loss: 9.0074744821, pde B loss: 1.6286331043\n",
      "obs C loss: 1.8943269812, pde C loss: 0.2767361831\n",
      "obs D loss: 812.9984874725, pde D loss: 3.1741308086\n",
      "obs E loss: 106.3243139982, pde E loss: 1.2919896059\n",
      "obs F loss: 8.1726712584, pde F loss: 0.1882298838\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.37s\n",
      "\n",
      "Start of epoch 297\n",
      "Training observations acc over epoch: 157.1629333496\n",
      "total loss: 964.6343326569, total regularisd loss (sum of batches): 42447.8259887695\n",
      "obs A loss: 2.5272560343, pde A loss: 11.9243873507\n",
      "obs B loss: 8.9999772310, pde B loss: 1.6423112843\n",
      "obs C loss: 1.8941480294, pde C loss: 0.3129490968\n",
      "obs D loss: 814.8523597717, pde D loss: 5.8958043940\n",
      "obs E loss: 106.5219235420, pde E loss: 1.6751305051\n",
      "obs F loss: 8.1818393767, pde F loss: 0.2062468377\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 298\n",
      "Training observations acc over epoch: 157.0445861816\n",
      "total loss: 973.7993164062, total regularisd loss (sum of batches): 42848.7905273438\n",
      "obs A loss: 2.6992102005, pde A loss: 20.8400883973\n",
      "obs B loss: 9.0463148504, pde B loss: 2.8116460200\n",
      "obs C loss: 1.8934942335, pde C loss: 0.4560843999\n",
      "obs D loss: 813.9547443390, pde D loss: 4.7068552934\n",
      "obs E loss: 106.4789814949, pde E loss: 2.4840489607\n",
      "obs F loss: 8.1946058571, pde F loss: 0.2332369222\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.34s\n",
      "\n",
      "Start of epoch 299\n",
      "Training observations acc over epoch: 157.1371002197\n",
      "total loss: 961.6395397186, total regularisd loss (sum of batches): 42313.7013549805\n",
      "obs A loss: 2.6399538368, pde A loss: 11.4672839493\n",
      "obs B loss: 9.0358007103, pde B loss: 1.5359142013\n",
      "obs C loss: 1.8903425317, pde C loss: 0.2824595566\n",
      "obs D loss: 814.6358823776, pde D loss: 3.8601958267\n",
      "obs E loss: 106.4422785044, pde E loss: 1.4847075306\n",
      "obs F loss: 8.1783809364, pde F loss: 0.1863513009\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.39s\n",
      "\n",
      "Start of epoch 300\n",
      "Training observations acc over epoch: 156.7438049316\n",
      "total loss: 957.1110801697, total regularisd loss (sum of batches): 42113.7692871094\n",
      "obs A loss: 2.5892496519, pde A loss: 9.9972790182\n",
      "obs B loss: 8.9871972650, pde B loss: 1.4009921327\n",
      "obs C loss: 1.8910761103, pde C loss: 0.2612140356\n",
      "obs D loss: 812.4239921570, pde D loss: 3.5181370303\n",
      "obs E loss: 106.4319108725, pde E loss: 1.2905388605\n",
      "obs F loss: 8.1392522454, pde F loss: 0.1802496929\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 301\n",
      "Training observations acc over epoch: 156.7454071045\n",
      "total loss: 957.6253738403, total regularisd loss (sum of batches): 42132.7944335938\n",
      "obs A loss: 2.5439856797, pde A loss: 10.6794842333\n",
      "obs B loss: 8.9340561330, pde B loss: 1.4090390950\n",
      "obs C loss: 1.8930336609, pde C loss: 0.2648986354\n",
      "obs D loss: 812.6426906586, pde D loss: 3.4214533772\n",
      "obs E loss: 106.3174937963, pde E loss: 1.1952518355\n",
      "obs F loss: 8.1409560442, pde F loss: 0.1830319820\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 302\n",
      "Training observations acc over epoch: 156.6261749268\n",
      "total loss: 957.2481002808, total regularisd loss (sum of batches): 42120.3448486328\n",
      "obs A loss: 2.5560756326, pde A loss: 11.4173983335\n",
      "obs B loss: 8.9437854439, pde B loss: 1.4594004732\n",
      "obs C loss: 1.8952884134, pde C loss: 0.2751495661\n",
      "obs D loss: 811.9592561722, pde D loss: 2.9427917581\n",
      "obs E loss: 106.2753416300, pde E loss: 1.2159040123\n",
      "obs F loss: 8.1273614913, pde F loss: 0.1803368207\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 303\n",
      "Training observations acc over epoch: 156.3100891113\n",
      "total loss: 953.3865222931, total regularisd loss (sum of batches): 41953.6406250000\n",
      "obs A loss: 2.5151030459, pde A loss: 9.6526047140\n",
      "obs B loss: 8.9038805664, pde B loss: 1.3976135068\n",
      "obs C loss: 1.8925821148, pde C loss: 0.2487616492\n",
      "obs D loss: 810.2009582520, pde D loss: 2.9502546955\n",
      "obs E loss: 106.2436130047, pde E loss: 1.1018155161\n",
      "obs F loss: 8.1043001711, pde F loss: 0.1750370774\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 304\n",
      "Training observations acc over epoch: 156.3348388672\n",
      "total loss: 955.8697566986, total regularisd loss (sum of batches): 42061.8043823242\n",
      "obs A loss: 2.5015535504, pde A loss: 9.2306070775\n",
      "obs B loss: 8.8955055326, pde B loss: 1.2984573562\n",
      "obs C loss: 1.8919747416, pde C loss: 0.2452745708\n",
      "obs D loss: 810.4109363556, pde D loss: 5.6876393892\n",
      "obs E loss: 106.2022634745, pde E loss: 1.2126703877\n",
      "obs F loss: 8.1068454534, pde F loss: 0.1860317183\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.69s\n",
      "\n",
      "Start of epoch 305\n",
      "Training observations acc over epoch: 156.5529022217\n",
      "total loss: 964.3556880951, total regularisd loss (sum of batches): 42427.2075805664\n",
      "obs A loss: 2.6010184810, pde A loss: 16.5913519263\n",
      "obs B loss: 8.8983119726, pde B loss: 2.0691295397\n",
      "obs C loss: 1.8915197961, pde C loss: 0.4054324823\n",
      "obs D loss: 811.4820165634, pde D loss: 3.7184535936\n",
      "obs E loss: 106.3434803486, pde E loss: 2.0611836873\n",
      "obs F loss: 8.1010727584, pde F loss: 0.1927111475\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.80s\n",
      "\n",
      "Start of epoch 306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 156.2996826172\n",
      "total loss: 955.2663955688, total regularisd loss (sum of batches): 42031.4495849609\n",
      "obs A loss: 2.6365695074, pde A loss: 11.0312156528\n",
      "obs B loss: 8.8987907916, pde B loss: 1.3462366425\n",
      "obs C loss: 1.8921992052, pde C loss: 0.2915128465\n",
      "obs D loss: 809.8245449066, pde D loss: 3.2155131847\n",
      "obs E loss: 106.4579508305, pde E loss: 1.4117470682\n",
      "obs F loss: 8.0880266428, pde F loss: 0.1720951772\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 307\n",
      "Training observations acc over epoch: 156.2262268066\n",
      "total loss: 952.4867115021, total regularisd loss (sum of batches): 41909.8244018555\n",
      "obs A loss: 2.5450589769, pde A loss: 8.4088280201\n",
      "obs B loss: 8.8500579447, pde B loss: 1.0946502313\n",
      "obs C loss: 1.8929179125, pde C loss: 0.2476016502\n",
      "obs D loss: 809.6906108856, pde D loss: 4.1115926765\n",
      "obs E loss: 106.2982060909, pde E loss: 1.0970221180\n",
      "obs F loss: 8.0803987384, pde F loss: 0.1697736091\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 308\n",
      "Training observations acc over epoch: 156.3817443848\n",
      "total loss: 957.6428375244, total regularisd loss (sum of batches): 42140.9515380859\n",
      "obs A loss: 2.5556885451, pde A loss: 10.5785989612\n",
      "obs B loss: 8.8357889950, pde B loss: 1.3897544816\n",
      "obs C loss: 1.8896115553, pde C loss: 0.2978666527\n",
      "obs D loss: 810.5879869461, pde D loss: 5.4180832598\n",
      "obs E loss: 106.3325028419, pde E loss: 1.4582083784\n",
      "obs F loss: 8.0889429748, pde F loss: 0.2097931644\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 309\n",
      "Training observations acc over epoch: 155.9426727295\n",
      "total loss: 950.8831958771, total regularisd loss (sum of batches): 41837.0097656250\n",
      "obs A loss: 2.5306688771, pde A loss: 9.0750067234\n",
      "obs B loss: 8.8142406344, pde B loss: 1.1967425998\n",
      "obs C loss: 1.8895286433, pde C loss: 0.2500235413\n",
      "obs D loss: 808.0926647186, pde D loss: 3.3313155677\n",
      "obs E loss: 106.2511217594, pde E loss: 1.2088861521\n",
      "obs F loss: 8.0776890218, pde F loss: 0.1652953618\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 310\n",
      "Training observations acc over epoch: 156.1407470703\n",
      "total loss: 956.3894634247, total regularisd loss (sum of batches): 42082.6373901367\n",
      "obs A loss: 2.5874969624, pde A loss: 12.0067370981\n",
      "obs B loss: 8.8263445944, pde B loss: 1.4116749391\n",
      "obs C loss: 1.8923518881, pde C loss: 0.3028966077\n",
      "obs D loss: 809.1239080429, pde D loss: 4.2240914740\n",
      "obs E loss: 106.3338878155, pde E loss: 1.4163918048\n",
      "obs F loss: 8.0805729181, pde F loss: 0.1831221043\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 311\n",
      "Training observations acc over epoch: 156.5754241943\n",
      "total loss: 957.5419807434, total regularisd loss (sum of batches): 42132.3283691406\n",
      "obs A loss: 2.5576656461, pde A loss: 10.9001574218\n",
      "obs B loss: 8.7967641205, pde B loss: 1.2623072714\n",
      "obs C loss: 1.8863878287, pde C loss: 0.2655941523\n",
      "obs D loss: 811.7708492279, pde D loss: 4.2029677927\n",
      "obs E loss: 106.3358972073, pde E loss: 1.2819795702\n",
      "obs F loss: 8.1048464626, pde F loss: 0.1765512710\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 312\n",
      "Training observations acc over epoch: 156.2530822754\n",
      "total loss: 960.0430259705, total regularisd loss (sum of batches): 42239.4890747070\n",
      "obs A loss: 2.5846806355, pde A loss: 14.0695049167\n",
      "obs B loss: 8.7978312969, pde B loss: 1.6776168291\n",
      "obs C loss: 1.8897725977, pde C loss: 0.3185672243\n",
      "obs D loss: 809.6821575165, pde D loss: 4.5753829665\n",
      "obs E loss: 106.4700150490, pde E loss: 1.6750744916\n",
      "obs F loss: 8.0940343291, pde F loss: 0.2083757361\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 313\n",
      "Training observations acc over epoch: 156.1455230713\n",
      "total loss: 953.4849071503, total regularisd loss (sum of batches): 41954.7904663086\n",
      "obs A loss: 2.6036283150, pde A loss: 10.5436994135\n",
      "obs B loss: 8.7868661731, pde B loss: 1.2898097951\n",
      "obs C loss: 1.8867612667, pde C loss: 0.2570145302\n",
      "obs D loss: 809.2060031891, pde D loss: 3.1611340810\n",
      "obs E loss: 106.3043162823, pde E loss: 1.1939799413\n",
      "obs F loss: 8.0856343508, pde F loss: 0.1660607120\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 314\n",
      "Training observations acc over epoch: 156.1211090088\n",
      "total loss: 952.1682243347, total regularisd loss (sum of batches): 41892.0627441406\n",
      "obs A loss: 2.5658876002, pde A loss: 9.2021624893\n",
      "obs B loss: 8.7622621655, pde B loss: 1.0858735405\n",
      "obs C loss: 1.8874748796, pde C loss: 0.2448979041\n",
      "obs D loss: 809.1575717926, pde D loss: 3.5663470328\n",
      "obs E loss: 106.2698082924, pde E loss: 1.1729071662\n",
      "obs F loss: 8.0837582648, pde F loss: 0.1692778477\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 315\n",
      "Training observations acc over epoch: 156.2643737793\n",
      "total loss: 953.7675132751, total regularisd loss (sum of batches): 41969.0091552734\n",
      "obs A loss: 2.5176830441, pde A loss: 9.4857001752\n",
      "obs B loss: 8.7380159646, pde B loss: 1.1632253900\n",
      "obs C loss: 1.8870038688, pde C loss: 0.2471854617\n",
      "obs D loss: 810.1170978546, pde D loss: 3.9559800252\n",
      "obs E loss: 106.2287021875, pde E loss: 1.1618158780\n",
      "obs F loss: 8.0976670086, pde F loss: 0.1674294707\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 316\n",
      "Training observations acc over epoch: 156.0345764160\n",
      "total loss: 953.5605335236, total regularisd loss (sum of batches): 41958.8741455078\n",
      "obs A loss: 2.5150203146, pde A loss: 10.1999051124\n",
      "obs B loss: 8.7413069159, pde B loss: 1.1196574792\n",
      "obs C loss: 1.8871576749, pde C loss: 0.2867274596\n",
      "obs D loss: 808.7495832443, pde D loss: 4.2680330873\n",
      "obs E loss: 106.2319679260, pde E loss: 1.3044672608\n",
      "obs F loss: 8.0823538154, pde F loss: 0.1743483690\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 156.1111907959\n",
      "total loss: 955.1067008972, total regularisd loss (sum of batches): 42025.1035156250\n",
      "obs A loss: 2.5065017156, pde A loss: 10.1990204751\n",
      "obs B loss: 8.7163649052, pde B loss: 1.3343249355\n",
      "obs C loss: 1.8879989255, pde C loss: 0.2835420296\n",
      "obs D loss: 809.1160993576, pde D loss: 5.0613329597\n",
      "obs E loss: 106.3608976603, pde E loss: 1.3839073442\n",
      "obs F loss: 8.0791685432, pde F loss: 0.1775350112\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 318\n",
      "Training observations acc over epoch: 156.2435760498\n",
      "total loss: 956.1651897430, total regularisd loss (sum of batches): 42074.6956787109\n",
      "obs A loss: 2.5105085783, pde A loss: 10.8888116777\n",
      "obs B loss: 8.7120447755, pde B loss: 1.1076404490\n",
      "obs C loss: 1.8869633470, pde C loss: 0.2904649540\n",
      "obs D loss: 809.9769296646, pde D loss: 4.8263022825\n",
      "obs E loss: 106.2787225246, pde E loss: 1.4019276462\n",
      "obs F loss: 8.0963759720, pde F loss: 0.1884970104\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.90s\n",
      "\n",
      "Start of epoch 319\n",
      "Training observations acc over epoch: 155.9495849609\n",
      "total loss: 954.9821529388, total regularisd loss (sum of batches): 42024.3389282227\n",
      "obs A loss: 2.5106472559, pde A loss: 10.7641849965\n",
      "obs B loss: 8.6975428015, pde B loss: 1.2132810615\n",
      "obs C loss: 1.8875099216, pde C loss: 0.3114032014\n",
      "obs D loss: 808.3368015289, pde D loss: 5.3189598061\n",
      "obs E loss: 106.1840674877, pde E loss: 1.5008623786\n",
      "obs F loss: 8.0807836503, pde F loss: 0.1761131897\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 320\n",
      "Training observations acc over epoch: 155.8325500488\n",
      "total loss: 953.8933677673, total regularisd loss (sum of batches): 41968.7021484375\n",
      "obs A loss: 2.5337802954, pde A loss: 11.5581225753\n",
      "obs B loss: 8.7182345241, pde B loss: 1.2626424804\n",
      "obs C loss: 1.8897600472, pde C loss: 0.3205154231\n",
      "obs D loss: 807.5029449463, pde D loss: 4.0661959611\n",
      "obs E loss: 106.2727737427, pde E loss: 1.4956842382\n",
      "obs F loss: 8.0778739303, pde F loss: 0.1948330784\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.80s\n",
      "\n",
      "Start of epoch 321\n",
      "Training observations acc over epoch: 155.9980621338\n",
      "total loss: 955.0480728149, total regularisd loss (sum of batches): 42027.9885253906\n",
      "obs A loss: 2.5400606208, pde A loss: 10.9721204787\n",
      "obs B loss: 8.7079971284, pde B loss: 1.2169081122\n",
      "obs C loss: 1.8858783357, pde C loss: 0.2992408741\n",
      "obs D loss: 808.3971796036, pde D loss: 4.9861294255\n",
      "obs E loss: 106.3801665306, pde E loss: 1.4056559484\n",
      "obs F loss: 8.0770467222, pde F loss: 0.1796878825\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 322\n",
      "Training observations acc over epoch: 156.3200683594\n",
      "total loss: 959.8789329529, total regularisd loss (sum of batches): 42232.1608276367\n",
      "obs A loss: 2.5289430320, pde A loss: 12.7856590897\n",
      "obs B loss: 8.7058934271, pde B loss: 1.3729157709\n",
      "obs C loss: 1.8846820947, pde C loss: 0.3485271963\n",
      "obs D loss: 810.4004001617, pde D loss: 5.4774108957\n",
      "obs E loss: 106.2920708656, pde E loss: 1.7901081815\n",
      "obs F loss: 8.1084882319, pde F loss: 0.1838349467\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 323\n",
      "Training observations acc over epoch: 155.7883605957\n",
      "total loss: 953.2766685486, total regularisd loss (sum of batches): 41943.4438476562\n",
      "obs A loss: 2.5781074166, pde A loss: 10.3507850319\n",
      "obs B loss: 8.7029906511, pde B loss: 1.3083209302\n",
      "obs C loss: 1.8822574820, pde C loss: 0.2889648222\n",
      "obs D loss: 807.3125343323, pde D loss: 4.9684333950\n",
      "obs E loss: 106.1797528267, pde E loss: 1.4592295401\n",
      "obs F loss: 8.0745109618, pde F loss: 0.1707700156\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.91s\n",
      "\n",
      "Start of epoch 324\n",
      "Training observations acc over epoch: 155.8408660889\n",
      "total loss: 950.5405941010, total regularisd loss (sum of batches): 41820.8820190430\n",
      "obs A loss: 2.4984120056, pde A loss: 9.0898555517\n",
      "obs B loss: 8.6622146219, pde B loss: 0.9885215219\n",
      "obs C loss: 1.8845992982, pde C loss: 0.2435664637\n",
      "obs D loss: 807.6601877213, pde D loss: 3.9141305909\n",
      "obs E loss: 106.2675433159, pde E loss: 1.1051779492\n",
      "obs F loss: 8.0722922385, pde F loss: 0.1541102382\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.80s\n",
      "\n",
      "Start of epoch 325\n",
      "Training observations acc over epoch: 155.9611053467\n",
      "total loss: 950.4616088867, total regularisd loss (sum of batches): 41816.9813232422\n",
      "obs A loss: 2.4962394498, pde A loss: 9.2420288622\n",
      "obs B loss: 8.6607913673, pde B loss: 0.9558612667\n",
      "obs C loss: 1.8828182705, pde C loss: 0.2240094657\n",
      "obs D loss: 808.3605899811, pde D loss: 3.1449071076\n",
      "obs E loss: 106.2875890732, pde E loss: 0.9833407346\n",
      "obs F loss: 8.0787141621, pde F loss: 0.1447237337\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 326\n",
      "Training observations acc over epoch: 188.2386169434\n",
      "total loss: 1982.4909229279, total regularisd loss (sum of batches): 87205.4274902344\n",
      "obs A loss: 3.4311039094, pde A loss: 596.3190911710\n",
      "obs B loss: 10.2238443941, pde B loss: 84.4629929308\n",
      "obs C loss: 2.3986827508, pde C loss: 10.7945114211\n",
      "obs D loss: 974.9195823669, pde D loss: 67.1015437841\n",
      "obs E loss: 116.3046152592, pde E loss: 85.4680463653\n",
      "obs F loss: 22.1537374705, pde F loss: 8.9131682825\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 205.8119506836\n",
      "total loss: 1337.8144035339, total regularisd loss (sum of batches): 58852.8530273438\n",
      "obs A loss: 4.1975288466, pde A loss: 46.6771764159\n",
      "obs B loss: 11.4766992033, pde B loss: 18.5202301741\n",
      "obs C loss: 2.5604753122, pde C loss: 6.5567520261\n",
      "obs D loss: 1065.0553722382, pde D loss: 11.7722122148\n",
      "obs E loss: 122.2001404762, pde E loss: 15.4773286879\n",
      "obs F loss: 29.3813458085, pde F loss: 3.9391383640\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.57s\n",
      "\n",
      "Start of epoch 328\n",
      "Training observations acc over epoch: 193.0372467041\n",
      "total loss: 1203.7948875427, total regularisd loss (sum of batches): 52963.6268310547\n",
      "obs A loss: 4.3174968362, pde A loss: 21.9044132829\n",
      "obs B loss: 10.9560891539, pde B loss: 4.4481569193\n",
      "obs C loss: 2.9126409926, pde C loss: 1.8753924184\n",
      "obs D loss: 1001.4079914093, pde D loss: 5.2542086616\n",
      "obs E loss: 116.8556742668, pde E loss: 9.1110665649\n",
      "obs F loss: 21.7736882865, pde F loss: 2.9780671075\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 329\n",
      "Training observations acc over epoch: 186.5507049561\n",
      "total loss: 1151.1227951050, total regularisd loss (sum of batches): 50646.3985595703\n",
      "obs A loss: 4.3180032149, pde A loss: 14.8567773700\n",
      "obs B loss: 10.5832562298, pde B loss: 1.3990306463\n",
      "obs C loss: 2.5051924549, pde C loss: 0.6166640921\n",
      "obs D loss: 968.8661079407, pde D loss: 5.3847286031\n",
      "obs E loss: 114.6388111115, pde E loss: 8.0999397337\n",
      "obs F loss: 18.3928451240, pde F loss: 1.4614388719\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 330\n",
      "Training observations acc over epoch: 181.0051727295\n",
      "total loss: 1113.2395172119, total regularisd loss (sum of batches): 48978.1048583984\n",
      "obs A loss: 3.9405248463, pde A loss: 13.0885225683\n",
      "obs B loss: 10.3443108052, pde B loss: 1.3921815045\n",
      "obs C loss: 2.2091564126, pde C loss: 0.4601915143\n",
      "obs D loss: 940.1141223907, pde D loss: 4.2823333070\n",
      "obs E loss: 112.8907322884, pde E loss: 7.0842976421\n",
      "obs F loss: 16.5322069228, pde F loss: 0.9009583127\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 331\n",
      "Training observations acc over epoch: 177.1097717285\n",
      "total loss: 1087.1765346527, total regularisd loss (sum of batches): 47825.8070068359\n",
      "obs A loss: 3.7383249328, pde A loss: 10.7328271866\n",
      "obs B loss: 10.0244354457, pde B loss: 1.4191565346\n",
      "obs C loss: 2.1125729270, pde C loss: 0.5160717862\n",
      "obs D loss: 919.6404228210, pde D loss: 4.8116088733\n",
      "obs E loss: 112.3408771753, pde E loss: 6.2878912762\n",
      "obs F loss: 14.8020424843, pde F loss: 0.7503012391\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 332\n",
      "Training observations acc over epoch: 173.8523864746\n",
      "total loss: 1067.1487197876, total regularisd loss (sum of batches): 46951.0493774414\n",
      "obs A loss: 3.5750092939, pde A loss: 9.8971096873\n",
      "obs B loss: 9.8603208065, pde B loss: 1.3736520987\n",
      "obs C loss: 2.1035803072, pde C loss: 0.5398951322\n",
      "obs D loss: 902.4406261444, pde D loss: 6.3408253491\n",
      "obs E loss: 111.5911786556, pde E loss: 5.3029641509\n",
      "obs F loss: 13.5437016189, pde F loss: 0.5798546532\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 333\n",
      "Training observations acc over epoch: 170.9406280518\n",
      "total loss: 1046.5254364014, total regularisd loss (sum of batches): 46050.0010375977\n",
      "obs A loss: 3.5025844425, pde A loss: 9.3450574130\n",
      "obs B loss: 9.8529304564, pde B loss: 1.2627876978\n",
      "obs C loss: 2.0477495678, pde C loss: 0.4886884242\n",
      "obs D loss: 887.1017646790, pde D loss: 4.7865868807\n",
      "obs E loss: 110.3428330421, pde E loss: 4.4804095775\n",
      "obs F loss: 12.7959003150, pde F loss: 0.5181531226\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 334\n",
      "Training observations acc over epoch: 169.2660980225\n",
      "total loss: 1034.3264274597, total regularisd loss (sum of batches): 45509.4248657227\n",
      "obs A loss: 3.3995376006, pde A loss: 8.6583168954\n",
      "obs B loss: 9.7486654967, pde B loss: 1.2361695748\n",
      "obs C loss: 1.9710211568, pde C loss: 0.4437516909\n",
      "obs D loss: 878.5400199890, pde D loss: 3.8310248405\n",
      "obs E loss: 109.7483019829, pde E loss: 4.0992763191\n",
      "obs F loss: 12.1891439557, pde F loss: 0.4611973064\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 335\n",
      "Training observations acc over epoch: 167.9410247803\n",
      "total loss: 1025.8190784454, total regularisd loss (sum of batches): 45129.3171997070\n",
      "obs A loss: 3.4009473994, pde A loss: 8.6298889220\n",
      "obs B loss: 9.7222008705, pde B loss: 1.1385588981\n",
      "obs C loss: 1.9275577646, pde C loss: 0.4008135432\n",
      "obs D loss: 871.6285266876, pde D loss: 3.9475899339\n",
      "obs E loss: 109.2037558556, pde E loss: 3.6398399025\n",
      "obs F loss: 11.7631623745, pde F loss: 0.4162387699\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 336\n",
      "Training observations acc over epoch: 166.7113189697\n",
      "total loss: 1017.0461921692, total regularisd loss (sum of batches): 44749.3483276367\n",
      "obs A loss: 3.3566116840, pde A loss: 8.4209178686\n",
      "obs B loss: 9.7465240210, pde B loss: 1.0528846756\n",
      "obs C loss: 1.9019371513, pde C loss: 0.3927497556\n",
      "obs D loss: 865.2714061737, pde D loss: 3.2371268123\n",
      "obs E loss: 108.7178711891, pde E loss: 3.2672225684\n",
      "obs F loss: 11.2737190574, pde F loss: 0.4072236065\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 165.9513092041\n",
      "total loss: 1013.8554267883, total regularisd loss (sum of batches): 44611.5586547852\n",
      "obs A loss: 3.2655153796, pde A loss: 9.0374586433\n",
      "obs B loss: 9.7029342055, pde B loss: 1.1059320308\n",
      "obs C loss: 1.8893794436, pde C loss: 0.4045139644\n",
      "obs D loss: 861.4666309357, pde D loss: 4.1000034027\n",
      "obs E loss: 108.5951390266, pde E loss: 3.0344800167\n",
      "obs F loss: 10.7881755084, pde F loss: 0.4652622910\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 338\n",
      "Training observations acc over epoch: 164.9581756592\n",
      "total loss: 1007.5878582001, total regularisd loss (sum of batches): 44335.7940063477\n",
      "obs A loss: 3.2541826665, pde A loss: 9.0254624039\n",
      "obs B loss: 9.6554838419, pde B loss: 1.0174455307\n",
      "obs C loss: 1.8865279499, pde C loss: 0.3642134015\n",
      "obs D loss: 856.2032432556, pde D loss: 3.9584036022\n",
      "obs E loss: 108.4075009823, pde E loss: 3.0204070173\n",
      "obs F loss: 10.3419608325, pde F loss: 0.4530191431\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 339\n",
      "Training observations acc over epoch: 164.7409057617\n",
      "total loss: 1005.2054328918, total regularisd loss (sum of batches): 44227.7218017578\n",
      "obs A loss: 3.2449178398, pde A loss: 8.9083701819\n",
      "obs B loss: 9.6449730098, pde B loss: 1.0100415461\n",
      "obs C loss: 1.8857909739, pde C loss: 0.3349504936\n",
      "obs D loss: 855.5714874268, pde D loss: 3.4534924515\n",
      "obs E loss: 108.0752892494, pde E loss: 2.6366304569\n",
      "obs F loss: 10.0230667144, pde F loss: 0.4164255308\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.28s\n",
      "\n",
      "Start of epoch 340\n",
      "Training observations acc over epoch: 164.1336059570\n",
      "total loss: 1001.1868515015, total regularisd loss (sum of batches): 44048.0895996094\n",
      "obs A loss: 3.1762222946, pde A loss: 8.8110547662\n",
      "obs B loss: 9.6446546018, pde B loss: 0.9621073604\n",
      "obs C loss: 1.8849962968, pde C loss: 0.3039981653\n",
      "obs D loss: 852.3442821503, pde D loss: 3.5494402274\n",
      "obs E loss: 107.9849565029, pde E loss: 2.3435294256\n",
      "obs F loss: 9.7665468305, pde F loss: 0.4150683898\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 341\n",
      "Training observations acc over epoch: 163.5868377686\n",
      "total loss: 999.0845012665, total regularisd loss (sum of batches): 43960.5123291016\n",
      "obs A loss: 3.1260053441, pde A loss: 9.5603647977\n",
      "obs B loss: 9.6286703944, pde B loss: 1.0000740383\n",
      "obs C loss: 1.8826604374, pde C loss: 0.2910478781\n",
      "obs D loss: 849.5575962067, pde D loss: 4.0683858804\n",
      "obs E loss: 107.7594103813, pde E loss: 2.2471828200\n",
      "obs F loss: 9.5668595284, pde F loss: 0.3962453692\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 342\n",
      "Training observations acc over epoch: 163.0453643799\n",
      "total loss: 995.9790802002, total regularisd loss (sum of batches): 43817.0092163086\n",
      "obs A loss: 3.1068804264, pde A loss: 8.8852693737\n",
      "obs B loss: 9.6257501245, pde B loss: 0.9958413411\n",
      "obs C loss: 1.8839556649, pde C loss: 0.2675937423\n",
      "obs D loss: 846.4965343475, pde D loss: 5.0487725735\n",
      "obs E loss: 107.7059999704, pde E loss: 2.1313898824\n",
      "obs F loss: 9.4532082528, pde F loss: 0.3778824592\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 343\n",
      "Training observations acc over epoch: 162.9024047852\n",
      "total loss: 994.6105384827, total regularisd loss (sum of batches): 43759.5947875977\n",
      "obs A loss: 3.0848558620, pde A loss: 9.0185131133\n",
      "obs B loss: 9.6238356233, pde B loss: 0.9621291906\n",
      "obs C loss: 1.8812783193, pde C loss: 0.2707418469\n",
      "obs D loss: 845.9733390808, pde D loss: 4.4407989942\n",
      "obs E loss: 107.5174765587, pde E loss: 2.1206556968\n",
      "obs F loss: 9.3336275816, pde F loss: 0.3833060777\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 344\n",
      "Training observations acc over epoch: 162.3918609619\n",
      "total loss: 989.8939170837, total regularisd loss (sum of batches): 43552.9122314453\n",
      "obs A loss: 3.0528541580, pde A loss: 9.0313480645\n",
      "obs B loss: 9.6253723651, pde B loss: 1.0415536165\n",
      "obs C loss: 1.8818427082, pde C loss: 0.2329051592\n",
      "obs D loss: 843.1370716095, pde D loss: 3.1792309918\n",
      "obs E loss: 107.4541842937, pde E loss: 1.7128346600\n",
      "obs F loss: 9.1998651624, pde F loss: 0.3448614459\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 345\n",
      "Training observations acc over epoch: 161.7194061279\n",
      "total loss: 986.4075317383, total regularisd loss (sum of batches): 43399.6171264648\n",
      "obs A loss: 2.9395370595, pde A loss: 10.1896147281\n",
      "obs B loss: 9.5954889804, pde B loss: 1.0813470371\n",
      "obs C loss: 1.8811288998, pde C loss: 0.2353916424\n",
      "obs D loss: 839.4314918518, pde D loss: 2.6714401245\n",
      "obs E loss: 107.4031274319, pde E loss: 1.5671717282\n",
      "obs F loss: 9.0656799972, pde F loss: 0.3461057856\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 346\n",
      "Training observations acc over epoch: 161.6240997314\n",
      "total loss: 986.8810844421, total regularisd loss (sum of batches): 43426.7667236328\n",
      "obs A loss: 2.8741955161, pde A loss: 9.6152868420\n",
      "obs B loss: 9.5566058755, pde B loss: 1.0789697990\n",
      "obs C loss: 1.8821670935, pde C loss: 0.2178988876\n",
      "obs D loss: 839.1336860657, pde D loss: 4.3313250206\n",
      "obs E loss: 107.3455846310, pde E loss: 1.5344614293\n",
      "obs F loss: 8.9523329437, pde F loss: 0.3585776798\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.84s\n",
      "\n",
      "Start of epoch 347\n",
      "Training observations acc over epoch: 161.2888488770\n",
      "total loss: 985.0641269684, total regularisd loss (sum of batches): 43337.7728271484\n",
      "obs A loss: 2.8117047772, pde A loss: 10.1491260678\n",
      "obs B loss: 9.5181285590, pde B loss: 1.1098966487\n",
      "obs C loss: 1.8829072788, pde C loss: 0.2164251180\n",
      "obs D loss: 837.3872756958, pde D loss: 3.8725859001\n",
      "obs E loss: 107.2963058949, pde E loss: 1.6448763721\n",
      "obs F loss: 8.8367582411, pde F loss: 0.3381298832\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.87s\n",
      "\n",
      "Start of epoch 348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 161.0162963867\n",
      "total loss: 982.0602836609, total regularisd loss (sum of batches): 43208.5653686523\n",
      "obs A loss: 2.7469495125, pde A loss: 9.6473202854\n",
      "obs B loss: 9.4819855392, pde B loss: 1.0663255993\n",
      "obs C loss: 1.8816867918, pde C loss: 0.1987765850\n",
      "obs D loss: 836.0085391998, pde D loss: 3.3629211895\n",
      "obs E loss: 107.2001056671, pde E loss: 1.3517070338\n",
      "obs F loss: 8.7783896625, pde F loss: 0.3355698548\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.85s\n",
      "\n",
      "Start of epoch 349\n",
      "Training observations acc over epoch: 160.3705139160\n",
      "total loss: 977.6300067902, total regularisd loss (sum of batches): 43016.0016479492\n",
      "obs A loss: 2.6532028541, pde A loss: 9.5594183654\n",
      "obs B loss: 9.4138123542, pde B loss: 1.0442161243\n",
      "obs C loss: 1.8823579811, pde C loss: 0.1978022086\n",
      "obs D loss: 832.4382286072, pde D loss: 3.1004129313\n",
      "obs E loss: 107.1312870979, pde E loss: 1.1837321110\n",
      "obs F loss: 8.7042256445, pde F loss: 0.3213072121\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 350\n",
      "Training observations acc over epoch: 159.8349761963\n",
      "total loss: 975.2323570251, total regularisd loss (sum of batches): 42911.4109497070\n",
      "obs A loss: 2.5574977435, pde A loss: 9.5387430489\n",
      "obs B loss: 9.3496737778, pde B loss: 1.1152606234\n",
      "obs C loss: 1.8810743205, pde C loss: 0.2302552324\n",
      "obs D loss: 829.4012756348, pde D loss: 3.6553066485\n",
      "obs E loss: 107.2071949244, pde E loss: 1.3305554055\n",
      "obs F loss: 8.6131105870, pde F loss: 0.3524172418\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 351\n",
      "Training observations acc over epoch: 159.7473297119\n",
      "total loss: 977.3713779449, total regularisd loss (sum of batches): 43001.3950805664\n",
      "obs A loss: 2.4509749971, pde A loss: 10.5887963623\n",
      "obs B loss: 9.2487127781, pde B loss: 1.1980067454\n",
      "obs C loss: 1.8840467334, pde C loss: 0.2591965538\n",
      "obs D loss: 829.2505302429, pde D loss: 4.9650907628\n",
      "obs E loss: 107.1003580093, pde E loss: 1.5093673356\n",
      "obs F loss: 8.5490696430, pde F loss: 0.3672335688\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.73s\n",
      "\n",
      "Start of epoch 352\n",
      "Training observations acc over epoch: 159.5975646973\n",
      "total loss: 973.9150085449, total regularisd loss (sum of batches): 42844.3984985352\n",
      "obs A loss: 2.4031866118, pde A loss: 9.4809547514\n",
      "obs B loss: 9.0877913088, pde B loss: 1.1806516610\n",
      "obs C loss: 1.8852786273, pde C loss: 0.2494179653\n",
      "obs D loss: 828.6644525528, pde D loss: 3.7140251547\n",
      "obs E loss: 107.0675963163, pde E loss: 1.3407444675\n",
      "obs F loss: 8.4771731645, pde F loss: 0.3637351021\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 353\n",
      "Training observations acc over epoch: 159.0570068359\n",
      "total loss: 972.6007633209, total regularisd loss (sum of batches): 42800.5103149414\n",
      "obs A loss: 2.3726490140, pde A loss: 10.9501641989\n",
      "obs B loss: 9.0393353105, pde B loss: 1.3556923103\n",
      "obs C loss: 1.8804707974, pde C loss: 0.2574965942\n",
      "obs D loss: 825.7661304474, pde D loss: 3.8681070395\n",
      "obs E loss: 106.8903683424, pde E loss: 1.4525997154\n",
      "obs F loss: 8.3930898011, pde F loss: 0.3746515973\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.77s\n",
      "\n",
      "Start of epoch 354\n",
      "Training observations acc over epoch: 159.1213836670\n",
      "total loss: 973.3982830048, total regularisd loss (sum of batches): 42831.4942626953\n",
      "obs A loss: 2.3594272248, pde A loss: 10.7917830348\n",
      "obs B loss: 8.9705020636, pde B loss: 1.2816534098\n",
      "obs C loss: 1.8813036885, pde C loss: 0.2611184376\n",
      "obs D loss: 826.2565956116, pde D loss: 4.5142195970\n",
      "obs E loss: 106.8948308229, pde E loss: 1.4720697105\n",
      "obs F loss: 8.3655874431, pde F loss: 0.3491933006\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.81s\n",
      "\n",
      "Start of epoch 355\n",
      "Training observations acc over epoch: 158.3687133789\n",
      "total loss: 969.4603061676, total regularisd loss (sum of batches): 42655.8487548828\n",
      "obs A loss: 2.3436909951, pde A loss: 11.6465732455\n",
      "obs B loss: 8.9376269877, pde B loss: 1.3775381260\n",
      "obs C loss: 1.8798138946, pde C loss: 0.2364680935\n",
      "obs D loss: 822.0098772049, pde D loss: 4.4425300695\n",
      "obs E loss: 106.7607235909, pde E loss: 1.2056821119\n",
      "obs F loss: 8.2804201096, pde F loss: 0.3393610627\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.96s\n",
      "\n",
      "Start of epoch 356\n",
      "Training observations acc over epoch: 157.8656616211\n",
      "total loss: 962.0168380737, total regularisd loss (sum of batches): 42323.4718017578\n",
      "obs A loss: 2.3539995402, pde A loss: 8.9650257826\n",
      "obs B loss: 8.9284076840, pde B loss: 1.1731755044\n",
      "obs C loss: 1.8783337325, pde C loss: 0.2199359592\n",
      "obs D loss: 819.0455503464, pde D loss: 3.1091280337\n",
      "obs E loss: 106.7589622736, pde E loss: 1.0495402701\n",
      "obs F loss: 8.2285431027, pde F loss: 0.3062472497\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.92s\n",
      "\n",
      "Start of epoch 357\n",
      "Training observations acc over epoch: 157.7754211426\n",
      "total loss: 962.6254329681, total regularisd loss (sum of batches): 42352.6492309570\n",
      "obs A loss: 2.3322260007, pde A loss: 10.4188253582\n",
      "obs B loss: 8.9215768278, pde B loss: 1.3236170989\n",
      "obs C loss: 1.8789884578, pde C loss: 0.2429128126\n",
      "obs D loss: 818.7141084671, pde D loss: 2.5442938991\n",
      "obs E loss: 106.5960936546, pde E loss: 1.1519461088\n",
      "obs F loss: 8.2095313519, pde F loss: 0.2912978576\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.83s\n",
      "\n",
      "Start of epoch 358\n",
      "Training observations acc over epoch: 157.8852233887\n",
      "total loss: 969.0833663940, total regularisd loss (sum of batches): 42643.2949829102\n",
      "obs A loss: 2.3933043480, pde A loss: 14.6366157234\n",
      "obs B loss: 8.9171648324, pde B loss: 1.5978600010\n",
      "obs C loss: 1.8781410027, pde C loss: 0.2414516006\n",
      "obs D loss: 819.3154096603, pde D loss: 3.7763770111\n",
      "obs E loss: 106.5841747522, pde E loss: 1.2062791083\n",
      "obs F loss: 8.2231001407, pde F loss: 0.3134921282\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 157.7447204590\n",
      "total loss: 965.4210052490, total regularisd loss (sum of batches): 42486.1847534180\n",
      "obs A loss: 2.4245316461, pde A loss: 12.3577463031\n",
      "obs B loss: 8.9048852921, pde B loss: 1.4512494933\n",
      "obs C loss: 1.8806558773, pde C loss: 0.2677980622\n",
      "obs D loss: 818.3527908325, pde D loss: 3.2208468877\n",
      "obs E loss: 106.7012571096, pde E loss: 1.3621982113\n",
      "obs F loss: 8.2044253349, pde F loss: 0.2926194379\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 360\n",
      "Training observations acc over epoch: 158.0386505127\n",
      "total loss: 966.6488380432, total regularisd loss (sum of batches): 42529.9649658203\n",
      "obs A loss: 2.4297835715, pde A loss: 11.1129434109\n",
      "obs B loss: 8.9019656628, pde B loss: 1.2968364097\n",
      "obs C loss: 1.8783317152, pde C loss: 0.2466297154\n",
      "obs D loss: 820.1682653427, pde D loss: 4.2264023572\n",
      "obs E loss: 106.6453629732, pde E loss: 1.2309873607\n",
      "obs F loss: 8.2080677897, pde F loss: 0.3032621429\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.86s\n",
      "\n",
      "Start of epoch 361\n",
      "Training observations acc over epoch: 157.5765380859\n",
      "total loss: 961.2458820343, total regularisd loss (sum of batches): 42293.9552612305\n",
      "obs A loss: 2.4384218045, pde A loss: 9.1901374757\n",
      "obs B loss: 8.8703779876, pde B loss: 1.1141805761\n",
      "obs C loss: 1.8809775114, pde C loss: 0.2601312138\n",
      "obs D loss: 817.4838800430, pde D loss: 3.7933217827\n",
      "obs E loss: 106.5942816734, pde E loss: 1.1655882355\n",
      "obs F loss: 8.1912163943, pde F loss: 0.2633756544\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.71s\n",
      "\n",
      "Start of epoch 362\n",
      "Training observations acc over epoch: 157.6301269531\n",
      "total loss: 963.3572692871, total regularisd loss (sum of batches): 42393.9824218750\n",
      "obs A loss: 2.4239205532, pde A loss: 10.0239397734\n",
      "obs B loss: 8.8477242291, pde B loss: 1.1888705119\n",
      "obs C loss: 1.8812507093, pde C loss: 0.2945922278\n",
      "obs D loss: 817.7635049820, pde D loss: 4.3379085250\n",
      "obs E loss: 106.6733255386, pde E loss: 1.4528844450\n",
      "obs F loss: 8.1909765154, pde F loss: 0.2783721080\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.83s\n",
      "\n",
      "Start of epoch 363\n",
      "Training observations acc over epoch: 157.3015899658\n",
      "total loss: 960.3472290039, total regularisd loss (sum of batches): 42255.8723144531\n",
      "obs A loss: 2.4589228481, pde A loss: 10.6130552590\n",
      "obs B loss: 8.8400831819, pde B loss: 1.2056820560\n",
      "obs C loss: 1.8828487508, pde C loss: 0.2587630332\n",
      "obs D loss: 815.8229007721, pde D loss: 3.0935336091\n",
      "obs E loss: 106.6362407207, pde E loss: 1.0933368783\n",
      "obs F loss: 8.1685369313, pde F loss: 0.2733197836\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 364\n",
      "Training observations acc over epoch: 157.0127563477\n",
      "total loss: 960.5009784698, total regularisd loss (sum of batches): 42269.0914306641\n",
      "obs A loss: 2.4725513346, pde A loss: 11.4106179476\n",
      "obs B loss: 8.8282276839, pde B loss: 1.2449264675\n",
      "obs C loss: 1.8802465443, pde C loss: 0.2608808209\n",
      "obs D loss: 814.2863922119, pde D loss: 4.0363981687\n",
      "obs E loss: 106.4438532591, pde E loss: 1.2097561546\n",
      "obs F loss: 8.1651593596, pde F loss: 0.2619717028\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.60s\n",
      "\n",
      "Start of epoch 365\n",
      "Training observations acc over epoch: 157.0755157471\n",
      "total loss: 960.0625591278, total regularisd loss (sum of batches): 42239.9974365234\n",
      "obs A loss: 2.4648539200, pde A loss: 10.9237167686\n",
      "obs B loss: 8.8261261135, pde B loss: 1.2301867101\n",
      "obs C loss: 1.8821326606, pde C loss: 0.2653965233\n",
      "obs D loss: 814.6476192474, pde D loss: 3.8320072629\n",
      "obs E loss: 106.4458236694, pde E loss: 1.1103609540\n",
      "obs F loss: 8.1865061820, pde F loss: 0.2478250824\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 366\n",
      "Training observations acc over epoch: 156.9962310791\n",
      "total loss: 958.0240764618, total regularisd loss (sum of batches): 42156.3508300781\n",
      "obs A loss: 2.4895507917, pde A loss: 10.1323549896\n",
      "obs B loss: 8.8169846833, pde B loss: 1.1521928087\n",
      "obs C loss: 1.8822252974, pde C loss: 0.2345827916\n",
      "obs D loss: 814.0926532745, pde D loss: 3.3041142635\n",
      "obs E loss: 106.5175285339, pde E loss: 0.9718088033\n",
      "obs F loss: 8.1783900708, pde F loss: 0.2516970220\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.85s\n",
      "\n",
      "Start of epoch 367\n",
      "Training observations acc over epoch: 156.9070129395\n",
      "total loss: 955.5388851166, total regularisd loss (sum of batches): 42038.5543212891\n",
      "obs A loss: 2.4514524937, pde A loss: 8.6772593558\n",
      "obs B loss: 8.7844835073, pde B loss: 1.1084475927\n",
      "obs C loss: 1.8834002335, pde C loss: 0.2515895637\n",
      "obs D loss: 813.7342376709, pde D loss: 2.8498787526\n",
      "obs E loss: 106.4064066410, pde E loss: 0.9890992790\n",
      "obs F loss: 8.1820208877, pde F loss: 0.2206110167\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.90s\n",
      "\n",
      "Start of epoch 368\n",
      "Training observations acc over epoch: 156.8867492676\n",
      "total loss: 960.6782875061, total regularisd loss (sum of batches): 42265.2826538086\n",
      "obs A loss: 2.4425455183, pde A loss: 12.2262171656\n",
      "obs B loss: 8.7599947155, pde B loss: 1.2946089990\n",
      "obs C loss: 1.8847426698, pde C loss: 0.2773475419\n",
      "obs D loss: 813.6193208694, pde D loss: 4.0745729282\n",
      "obs E loss: 106.4280116558, pde E loss: 1.2376532350\n",
      "obs F loss: 8.1859288067, pde F loss: 0.2473358540\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.94s\n",
      "\n",
      "Start of epoch 369\n",
      "Training observations acc over epoch: 157.1278533936\n",
      "total loss: 961.1373844147, total regularisd loss (sum of batches): 42296.0663452148\n",
      "obs A loss: 2.4617620744, pde A loss: 10.3259852529\n",
      "obs B loss: 8.7612441778, pde B loss: 1.2064246554\n",
      "obs C loss: 1.8865326587, pde C loss: 0.2643903317\n",
      "obs D loss: 814.9576168060, pde D loss: 5.1914960705\n",
      "obs E loss: 106.4982576370, pde E loss: 1.1311591994\n",
      "obs F loss: 8.2016968429, pde F loss: 0.2508320939\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.82s\n",
      "\n",
      "Start of epoch 370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 156.8212432861\n",
      "total loss: 959.7467346191, total regularisd loss (sum of batches): 42225.9201660156\n",
      "obs A loss: 2.4567546919, pde A loss: 10.2848006934\n",
      "obs B loss: 8.7380998135, pde B loss: 1.1373509411\n",
      "obs C loss: 1.8843042646, pde C loss: 0.2916083848\n",
      "obs D loss: 813.2003660202, pde D loss: 5.4566197991\n",
      "obs E loss: 106.4567998648, pde E loss: 1.3936481494\n",
      "obs F loss: 8.1909977943, pde F loss: 0.2553784274\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 66.12s\n",
      "\n",
      "Start of epoch 371\n",
      "Training observations acc over epoch: 156.4360961914\n",
      "total loss: 955.7013931274, total regularisd loss (sum of batches): 42057.8038940430\n",
      "obs A loss: 2.4523542039, pde A loss: 10.5992212445\n",
      "obs B loss: 8.7299167961, pde B loss: 1.1751058977\n",
      "obs C loss: 1.8882777765, pde C loss: 0.2672884394\n",
      "obs D loss: 810.8549680710, pde D loss: 3.8178338334\n",
      "obs E loss: 106.5096180439, pde E loss: 0.9924624152\n",
      "obs F loss: 8.1815958470, pde F loss: 0.2327501494\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.81s\n",
      "\n",
      "Start of epoch 372\n",
      "Training observations acc over epoch: 156.2886810303\n",
      "total loss: 952.6990432739, total regularisd loss (sum of batches): 41917.8017578125\n",
      "obs A loss: 2.4333266281, pde A loss: 9.2087948173\n",
      "obs B loss: 8.7138691545, pde B loss: 1.0896808710\n",
      "obs C loss: 1.8923526816, pde C loss: 0.2884082855\n",
      "obs D loss: 810.1443653107, pde D loss: 3.1013749875\n",
      "obs E loss: 106.3697750568, pde E loss: 1.0638283007\n",
      "obs F loss: 8.1784137189, pde F loss: 0.2148503256\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.84s\n",
      "\n",
      "Start of epoch 373\n",
      "Training observations acc over epoch: 156.5366821289\n",
      "total loss: 958.3041286469, total regularisd loss (sum of batches): 42167.8256835938\n",
      "obs A loss: 2.4473579228, pde A loss: 10.1302761585\n",
      "obs B loss: 8.6998996586, pde B loss: 1.1169920955\n",
      "obs C loss: 1.8945572432, pde C loss: 0.3072167435\n",
      "obs D loss: 811.5369491577, pde D loss: 5.9424351417\n",
      "obs E loss: 106.4580419064, pde E loss: 1.3269795086\n",
      "obs F loss: 8.1833961010, pde F loss: 0.2600329551\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.98s\n",
      "\n",
      "Start of epoch 374\n",
      "Training observations acc over epoch: 156.0935974121\n",
      "total loss: 952.3242282867, total regularisd loss (sum of batches): 41901.4996337891\n",
      "obs A loss: 2.4457099512, pde A loss: 9.7118643671\n",
      "obs B loss: 8.7073267549, pde B loss: 1.0558638722\n",
      "obs C loss: 1.8934859261, pde C loss: 0.2913714307\n",
      "obs D loss: 809.0487508774, pde D loss: 3.4998924658\n",
      "obs E loss: 106.3090798855, pde E loss: 0.9747986170\n",
      "obs F loss: 8.1571941525, pde F loss: 0.2288888069\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 375\n",
      "Training observations acc over epoch: 156.2453155518\n",
      "total loss: 956.2815704346, total regularisd loss (sum of batches): 42071.2605590820\n",
      "obs A loss: 2.4701966457, pde A loss: 10.7233667374\n",
      "obs B loss: 8.7020413131, pde B loss: 1.1625936180\n",
      "obs C loss: 1.8918342907, pde C loss: 0.2913301149\n",
      "obs D loss: 809.8977155685, pde D loss: 5.2002116330\n",
      "obs E loss: 106.3432204723, pde E loss: 1.1915362533\n",
      "obs F loss: 8.1669763178, pde F loss: 0.2405457483\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.69s\n",
      "\n",
      "Start of epoch 376\n",
      "Training observations acc over epoch: 156.0559997559\n",
      "total loss: 952.5601692200, total regularisd loss (sum of batches): 41912.9979858398\n",
      "obs A loss: 2.4889017455, pde A loss: 9.1996372342\n",
      "obs B loss: 8.6881504804, pde B loss: 1.0677917898\n",
      "obs C loss: 1.8906826377, pde C loss: 0.2931720591\n",
      "obs D loss: 808.7145862579, pde D loss: 4.3505324461\n",
      "obs E loss: 106.3960516453, pde E loss: 1.0973298689\n",
      "obs F loss: 8.1575417072, pde F loss: 0.2157951202\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.26s\n",
      "\n",
      "Start of epoch 377\n",
      "Training observations acc over epoch: 156.2575531006\n",
      "total loss: 953.6193485260, total regularisd loss (sum of batches): 41963.5856323242\n",
      "obs A loss: 2.4630517885, pde A loss: 9.0607353747\n",
      "obs B loss: 8.6688177884, pde B loss: 0.9782016333\n",
      "obs C loss: 1.8914796878, pde C loss: 0.2722015493\n",
      "obs D loss: 809.9813671112, pde D loss: 4.5083391517\n",
      "obs E loss: 106.3753916025, pde E loss: 1.0422101095\n",
      "obs F loss: 8.1650717109, pde F loss: 0.2124701776\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 378\n",
      "Training observations acc over epoch: 156.2839813232\n",
      "total loss: 956.0122337341, total regularisd loss (sum of batches): 42064.1280517578\n",
      "obs A loss: 2.4706354849, pde A loss: 9.8296324015\n",
      "obs B loss: 8.6585420668, pde B loss: 1.0370693654\n",
      "obs C loss: 1.8887544274, pde C loss: 0.2886761744\n",
      "obs D loss: 810.1133384705, pde D loss: 5.6630098261\n",
      "obs E loss: 106.4087924957, pde E loss: 1.2616270501\n",
      "obs F loss: 8.1638450027, pde F loss: 0.2283118775\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.06s\n",
      "\n",
      "Start of epoch 379\n",
      "Training observations acc over epoch: 155.9822235107\n",
      "total loss: 950.9958648682, total regularisd loss (sum of batches): 41846.7651367188\n",
      "obs A loss: 2.4527291544, pde A loss: 8.7705378532\n",
      "obs B loss: 8.6315430701, pde B loss: 0.9767869748\n",
      "obs C loss: 1.8898373656, pde C loss: 0.2672226117\n",
      "obs D loss: 808.4127216339, pde D loss: 3.9252497256\n",
      "obs E loss: 106.3556470871, pde E loss: 0.9578117430\n",
      "obs F loss: 8.1508648992, pde F loss: 0.2048944908\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 380\n",
      "Training observations acc over epoch: 156.1840820312\n",
      "total loss: 953.4552230835, total regularisd loss (sum of batches): 41949.2402954102\n",
      "obs A loss: 2.4759673998, pde A loss: 9.7100752443\n",
      "obs B loss: 8.6239722818, pde B loss: 0.9876389951\n",
      "obs C loss: 1.8903825488, pde C loss: 0.2681752420\n",
      "obs D loss: 809.6705284119, pde D loss: 4.2159694359\n",
      "obs E loss: 106.2761349678, pde E loss: 0.9629327292\n",
      "obs F loss: 8.1677275598, pde F loss: 0.2057098846\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.30s\n",
      "\n",
      "Start of epoch 381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 155.9991149902\n",
      "total loss: 959.1907978058, total regularisd loss (sum of batches): 42199.6154785156\n",
      "obs A loss: 2.5609571524, pde A loss: 14.7366672456\n",
      "obs B loss: 8.5980276167, pde B loss: 1.5447128136\n",
      "obs C loss: 1.8927490320, pde C loss: 0.3488400606\n",
      "obs D loss: 808.4565982819, pde D loss: 4.7673335299\n",
      "obs E loss: 106.3282973766, pde E loss: 1.5447740853\n",
      "obs F loss: 8.1581356972, pde F loss: 0.2537067430\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.29s\n",
      "\n",
      "Start of epoch 382\n",
      "Training observations acc over epoch: 156.0082397461\n",
      "total loss: 950.7008457184, total regularisd loss (sum of batches): 41832.2947387695\n",
      "obs A loss: 2.5547527038, pde A loss: 9.4399422705\n",
      "obs B loss: 8.5791893899, pde B loss: 1.0034427308\n",
      "obs C loss: 1.8894857969, pde C loss: 0.2582567707\n",
      "obs D loss: 808.4900302887, pde D loss: 2.8906174637\n",
      "obs E loss: 106.3812429905, pde E loss: 0.8660242055\n",
      "obs F loss: 8.1546954960, pde F loss: 0.1931618825\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.83s\n",
      "\n",
      "Start of epoch 383\n",
      "Training observations acc over epoch: 155.7130737305\n",
      "total loss: 948.6703128815, total regularisd loss (sum of batches): 41740.5059814453\n",
      "obs A loss: 2.5048472285, pde A loss: 8.4049253464\n",
      "obs B loss: 8.5737735480, pde B loss: 0.8732938562\n",
      "obs C loss: 1.8903788775, pde C loss: 0.2416319703\n",
      "obs D loss: 806.6916904449, pde D loss: 3.8380223885\n",
      "obs E loss: 106.4803419113, pde E loss: 0.8442062289\n",
      "obs F loss: 8.1374387741, pde F loss: 0.1897687374\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.69s\n",
      "\n",
      "Start of epoch 384\n",
      "Training observations acc over epoch: 155.8279266357\n",
      "total loss: 949.5700378418, total regularisd loss (sum of batches): 41779.7006835938\n",
      "obs A loss: 2.4858364686, pde A loss: 8.9091361910\n",
      "obs B loss: 8.5565977842, pde B loss: 0.9648453295\n",
      "obs C loss: 1.8899913505, pde C loss: 0.2398412568\n",
      "obs D loss: 807.6174678802, pde D loss: 3.4741344154\n",
      "obs E loss: 106.2661330700, pde E loss: 0.8381657451\n",
      "obs F loss: 8.1515426189, pde F loss: 0.1763486941\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 385\n",
      "Training observations acc over epoch: 155.9921722412\n",
      "total loss: 955.6679248810, total regularisd loss (sum of batches): 42048.4855346680\n",
      "obs A loss: 2.5180831403, pde A loss: 11.3232822716\n",
      "obs B loss: 8.5286506712, pde B loss: 1.1374955345\n",
      "obs C loss: 1.8878816944, pde C loss: 0.2931948570\n",
      "obs D loss: 808.4893703461, pde D loss: 5.5238266848\n",
      "obs E loss: 106.3684058189, pde E loss: 1.2149920631\n",
      "obs F loss: 8.1605794877, pde F loss: 0.2221701124\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.66s\n",
      "\n",
      "Start of epoch 386\n",
      "Training observations acc over epoch: 155.7432861328\n",
      "total loss: 954.9035434723, total regularisd loss (sum of batches): 42017.5293579102\n",
      "obs A loss: 2.5808323398, pde A loss: 13.2122919410\n",
      "obs B loss: 8.5049624890, pde B loss: 1.2713322984\n",
      "obs C loss: 1.8893090449, pde C loss: 0.2874473571\n",
      "obs D loss: 806.8659572601, pde D loss: 4.3580908962\n",
      "obs E loss: 106.4740082026, pde E loss: 1.1050958466\n",
      "obs F loss: 8.1446230859, pde F loss: 0.2095917372\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 387\n",
      "Training observations acc over epoch: 155.5521545410\n",
      "total loss: 947.3047389984, total regularisd loss (sum of batches): 41682.9759521484\n",
      "obs A loss: 2.5213129483, pde A loss: 8.7962421179\n",
      "obs B loss: 8.5013808012, pde B loss: 0.9424222969\n",
      "obs C loss: 1.8865208514, pde C loss: 0.2335329428\n",
      "obs D loss: 806.0440368652, pde D loss: 3.0045297556\n",
      "obs E loss: 106.2121462822, pde E loss: 0.8356277319\n",
      "obs F loss: 8.1474387199, pde F loss: 0.1795455471\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 388\n",
      "Training observations acc over epoch: 155.7537689209\n",
      "total loss: 949.1207714081, total regularisd loss (sum of batches): 41759.5646972656\n",
      "obs A loss: 2.5086509436, pde A loss: 8.4257386327\n",
      "obs B loss: 8.4705514759, pde B loss: 0.8969974732\n",
      "obs C loss: 1.8882991932, pde C loss: 0.2542629244\n",
      "obs D loss: 807.1487798691, pde D loss: 3.8925850131\n",
      "obs E loss: 106.3664312363, pde E loss: 0.9445607364\n",
      "obs F loss: 8.1397646815, pde F loss: 0.1841473936\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 389\n",
      "Training observations acc over epoch: 155.6504821777\n",
      "total loss: 949.9931564331, total regularisd loss (sum of batches): 41798.0900268555\n",
      "obs A loss: 2.4954803921, pde A loss: 9.2727319896\n",
      "obs B loss: 8.4606749862, pde B loss: 0.9108507996\n",
      "obs C loss: 1.8867562767, pde C loss: 0.2613602350\n",
      "obs D loss: 806.5843982697, pde D loss: 4.3895432986\n",
      "obs E loss: 106.3400588036, pde E loss: 1.0674894974\n",
      "obs F loss: 8.1355618387, pde F loss: 0.1882448925\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 390\n",
      "Training observations acc over epoch: 155.7062377930\n",
      "total loss: 951.8285465240, total regularisd loss (sum of batches): 41880.1046142578\n",
      "obs A loss: 2.5042820983, pde A loss: 10.9771919399\n",
      "obs B loss: 8.4183116853, pde B loss: 1.0285312412\n",
      "obs C loss: 1.8870870490, pde C loss: 0.2443352295\n",
      "obs D loss: 806.8339710236, pde D loss: 4.1619889922\n",
      "obs E loss: 106.4552161694, pde E loss: 0.9890885111\n",
      "obs F loss: 8.1385428309, pde F loss: 0.1900028344\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 391\n",
      "Training observations acc over epoch: 155.9774169922\n",
      "total loss: 953.4460391998, total regularisd loss (sum of batches): 41946.6651611328\n",
      "obs A loss: 2.5144167170, pde A loss: 10.1899520904\n",
      "obs B loss: 8.4154511690, pde B loss: 0.9667832348\n",
      "obs C loss: 1.8878852352, pde C loss: 0.2542818617\n",
      "obs D loss: 808.4562568665, pde D loss: 4.9697624296\n",
      "obs E loss: 106.4408404827, pde E loss: 1.0104106497\n",
      "obs F loss: 8.1494958848, pde F loss: 0.1905020289\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 155.8341369629\n",
      "total loss: 951.5069999695, total regularisd loss (sum of batches): 41869.8491821289\n",
      "obs A loss: 2.5066568777, pde A loss: 8.7985846400\n",
      "obs B loss: 8.3911302686, pde B loss: 0.9336695559\n",
      "obs C loss: 1.8886823505, pde C loss: 0.2653506282\n",
      "obs D loss: 807.6911392212, pde D loss: 5.2636440508\n",
      "obs E loss: 106.3786499500, pde E loss: 1.0589765683\n",
      "obs F loss: 8.1483206898, pde F loss: 0.1821904876\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 393\n",
      "Training observations acc over epoch: 155.7904815674\n",
      "total loss: 951.1472682953, total regularisd loss (sum of batches): 41852.4289550781\n",
      "obs A loss: 2.5079760365, pde A loss: 10.3403205574\n",
      "obs B loss: 8.3544376194, pde B loss: 1.0982672349\n",
      "obs C loss: 1.8847093862, pde C loss: 0.2569024123\n",
      "obs D loss: 807.5293359756, pde D loss: 3.5608088076\n",
      "obs E loss: 106.3147803545, pde E loss: 0.9677128084\n",
      "obs F loss: 8.1514503807, pde F loss: 0.1805587760\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 394\n",
      "Training observations acc over epoch: 155.6443786621\n",
      "total loss: 950.2577114105, total regularisd loss (sum of batches): 41810.9490966797\n",
      "obs A loss: 2.4994178601, pde A loss: 8.9186533988\n",
      "obs B loss: 8.3395969421, pde B loss: 0.8622989068\n",
      "obs C loss: 1.8868002761, pde C loss: 0.2503239135\n",
      "obs D loss: 806.5953531265, pde D loss: 5.1601289734\n",
      "obs E loss: 106.4076590538, pde E loss: 1.0123631163\n",
      "obs F loss: 8.1374074668, pde F loss: 0.1877055741\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 395\n",
      "Training observations acc over epoch: 155.7560424805\n",
      "total loss: 948.7837104797, total regularisd loss (sum of batches): 41743.2390136719\n",
      "obs A loss: 2.4702999443, pde A loss: 8.7922022939\n",
      "obs B loss: 8.3137427419, pde B loss: 0.9184049023\n",
      "obs C loss: 1.8848671466, pde C loss: 0.2396469591\n",
      "obs D loss: 807.3116445541, pde D loss: 3.2654373255\n",
      "obs E loss: 106.4148759842, pde E loss: 0.8704087492\n",
      "obs F loss: 8.1408271044, pde F loss: 0.1613543688\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.21s\n",
      "\n",
      "Start of epoch 396\n",
      "Training observations acc over epoch: 155.6069793701\n",
      "total loss: 953.0765209198, total regularisd loss (sum of batches): 41935.5122070312\n",
      "obs A loss: 2.5354812779, pde A loss: 11.0425928831\n",
      "obs B loss: 8.3129203469, pde B loss: 1.0934898704\n",
      "obs C loss: 1.8869426679, pde C loss: 0.2574347479\n",
      "obs D loss: 806.4932775497, pde D loss: 5.7182890251\n",
      "obs E loss: 106.2860376835, pde E loss: 1.1247638641\n",
      "obs F loss: 8.1271370053, pde F loss: 0.1981537188\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.35s\n",
      "\n",
      "Start of epoch 397\n",
      "Training observations acc over epoch: 155.9369506836\n",
      "total loss: 954.0748729706, total regularisd loss (sum of batches): 41979.3185424805\n",
      "obs A loss: 2.4927993976, pde A loss: 10.7571398616\n",
      "obs B loss: 8.2784229368, pde B loss: 1.0314678717\n",
      "obs C loss: 1.8843776863, pde C loss: 0.2680743241\n",
      "obs D loss: 808.5520172119, pde D loss: 5.0260214172\n",
      "obs E loss: 106.2630130053, pde E loss: 1.1819975553\n",
      "obs F loss: 8.1513728201, pde F loss: 0.1881573303\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 398\n",
      "Training observations acc over epoch: 155.5093841553\n",
      "total loss: 947.9569320679, total regularisd loss (sum of batches): 41703.4320678711\n",
      "obs A loss: 2.4825622067, pde A loss: 8.5486592799\n",
      "obs B loss: 8.2811456621, pde B loss: 0.8094410645\n",
      "obs C loss: 1.8833186552, pde C loss: 0.2362474594\n",
      "obs D loss: 805.9671325684, pde D loss: 4.2370589115\n",
      "obs E loss: 106.3106843233, pde E loss: 0.8973942576\n",
      "obs F loss: 8.1312699914, pde F loss: 0.1720054662\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 399\n",
      "Training observations acc over epoch: 155.7109832764\n",
      "total loss: 953.3771057129, total regularisd loss (sum of batches): 41945.2017211914\n",
      "obs A loss: 2.5020973459, pde A loss: 11.1317664385\n",
      "obs B loss: 8.2477423996, pde B loss: 1.0744791906\n",
      "obs C loss: 1.8842587136, pde C loss: 0.2412102192\n",
      "obs D loss: 807.1362829208, pde D loss: 5.5428618789\n",
      "obs E loss: 106.3616912365, pde E loss: 0.9352101823\n",
      "obs F loss: 8.1337644756, pde F loss: 0.1857380106\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 400\n",
      "Training observations acc over epoch: 155.6726226807\n",
      "total loss: 948.3679161072, total regularisd loss (sum of batches): 41726.2896118164\n",
      "obs A loss: 2.4847161211, pde A loss: 8.5093108565\n",
      "obs B loss: 8.2329774946, pde B loss: 0.8230831334\n",
      "obs C loss: 1.8826108202, pde C loss: 0.2279996262\n",
      "obs D loss: 806.9269800186, pde D loss: 3.6911964957\n",
      "obs E loss: 106.3711709976, pde E loss: 0.9132904662\n",
      "obs F loss: 8.1372618675, pde F loss: 0.1673110337\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.38s\n",
      "\n",
      "Start of epoch 401\n",
      "Training observations acc over epoch: 155.7616729736\n",
      "total loss: 950.1720657349, total regularisd loss (sum of batches): 41810.2136840820\n",
      "obs A loss: 2.4981377348, pde A loss: 9.2251854092\n",
      "obs B loss: 8.2204970568, pde B loss: 0.9185636332\n",
      "obs C loss: 1.8844356202, pde C loss: 0.2618485074\n",
      "obs D loss: 807.4460525513, pde D loss: 3.9702969566\n",
      "obs E loss: 106.3958802223, pde E loss: 1.0746382307\n",
      "obs F loss: 8.1248930395, pde F loss: 0.1516336997\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 402\n",
      "Training observations acc over epoch: 155.7557678223\n",
      "total loss: 955.5336894989, total regularisd loss (sum of batches): 42042.3699340820\n",
      "obs A loss: 2.5194125623, pde A loss: 11.6496077180\n",
      "obs B loss: 8.2157371342, pde B loss: 1.1814224785\n",
      "obs C loss: 1.8850614205, pde C loss: 0.2917988640\n",
      "obs D loss: 807.4967765808, pde D loss: 6.2630910203\n",
      "obs E loss: 106.2732517719, pde E loss: 1.4003804829\n",
      "obs F loss: 8.1441630274, pde F loss: 0.2129788962\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.26s\n",
      "\n",
      "Start of epoch 403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 155.2418060303\n",
      "total loss: 944.5474662781, total regularisd loss (sum of batches): 41563.0499267578\n",
      "obs A loss: 2.4801488072, pde A loss: 7.9258154035\n",
      "obs B loss: 8.1777256280, pde B loss: 0.8024910381\n",
      "obs C loss: 1.8844467327, pde C loss: 0.2364210251\n",
      "obs D loss: 804.5585250854, pde D loss: 3.1496552043\n",
      "obs E loss: 106.2395615578, pde E loss: 0.8079022281\n",
      "obs F loss: 8.1104093343, pde F loss: 0.1743623652\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 404\n",
      "Training observations acc over epoch: 155.3226776123\n",
      "total loss: 949.6963710785, total regularisd loss (sum of batches): 41784.8702392578\n",
      "obs A loss: 2.5249703564, pde A loss: 11.8869229704\n",
      "obs B loss: 8.1677694172, pde B loss: 1.1084982511\n",
      "obs C loss: 1.8856525868, pde C loss: 0.2623142749\n",
      "obs D loss: 804.9388723373, pde D loss: 3.3001590632\n",
      "obs E loss: 106.3118509054, pde E loss: 1.0425350349\n",
      "obs F loss: 8.1068984419, pde F loss: 0.1599234254\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 405\n",
      "Training observations acc over epoch: 155.2681427002\n",
      "total loss: 948.7574424744, total regularisd loss (sum of batches): 41750.3222656250\n",
      "obs A loss: 2.5292351246, pde A loss: 10.3622252792\n",
      "obs B loss: 8.1559912413, pde B loss: 0.9575623171\n",
      "obs C loss: 1.8847135007, pde C loss: 0.2510374915\n",
      "obs D loss: 804.5721969604, pde D loss: 4.3105727360\n",
      "obs E loss: 106.3541212082, pde E loss: 1.0922283027\n",
      "obs F loss: 8.1125192493, pde F loss: 0.1750391403\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 406\n",
      "Training observations acc over epoch: 155.4407043457\n",
      "total loss: 946.3956871033, total regularisd loss (sum of batches): 41639.6366577148\n",
      "obs A loss: 2.4715665877, pde A loss: 7.8073632568\n",
      "obs B loss: 8.1405706406, pde B loss: 0.7505684327\n",
      "obs C loss: 1.8818155620, pde C loss: 0.2069166421\n",
      "obs D loss: 805.7443962097, pde D loss: 4.0508591607\n",
      "obs E loss: 106.2888114452, pde E loss: 0.7742360402\n",
      "obs F loss: 8.1170065105, pde F loss: 0.1615580295\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.39s\n",
      "\n",
      "Start of epoch 407\n",
      "Training observations acc over epoch: 155.5679168701\n",
      "total loss: 947.9015541077, total regularisd loss (sum of batches): 41710.4155883789\n",
      "obs A loss: 2.4517883286, pde A loss: 8.1872789413\n",
      "obs B loss: 8.1093443632, pde B loss: 0.7901628390\n",
      "obs C loss: 1.8823833503, pde C loss: 0.2242166139\n",
      "obs D loss: 806.5418052673, pde D loss: 4.3071593381\n",
      "obs E loss: 106.3001511097, pde E loss: 0.8369769109\n",
      "obs F loss: 8.1216626167, pde F loss: 0.1486278928\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 408\n",
      "Training observations acc over epoch: 155.3813781738\n",
      "total loss: 947.4068508148, total regularisd loss (sum of batches): 41689.2577514648\n",
      "obs A loss: 2.4518212304, pde A loss: 8.8031656146\n",
      "obs B loss: 8.0869579613, pde B loss: 0.8926609848\n",
      "obs C loss: 1.8804279678, pde C loss: 0.2388934903\n",
      "obs D loss: 805.5051040649, pde D loss: 4.0700049661\n",
      "obs E loss: 106.2560734749, pde E loss: 0.9589756411\n",
      "obs F loss: 8.1076202989, pde F loss: 0.1551509306\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 65.03s\n",
      "\n",
      "Start of epoch 409\n",
      "Training observations acc over epoch: 155.4327697754\n",
      "total loss: 947.4520931244, total regularisd loss (sum of batches): 41692.5526123047\n",
      "obs A loss: 2.4355400093, pde A loss: 8.7215974778\n",
      "obs B loss: 8.0465719253, pde B loss: 0.8205764415\n",
      "obs C loss: 1.8843961358, pde C loss: 0.2553344471\n",
      "obs D loss: 805.7770948410, pde D loss: 3.9438348543\n",
      "obs E loss: 106.3410401344, pde E loss: 0.9650703799\n",
      "obs F loss: 8.1116754711, pde F loss: 0.1493684629\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.82s\n",
      "\n",
      "Start of epoch 410\n",
      "Training observations acc over epoch: 155.4876556396\n",
      "total loss: 952.7820453644, total regularisd loss (sum of batches): 41922.4205932617\n",
      "obs A loss: 2.5290162079, pde A loss: 12.9696648568\n",
      "obs B loss: 8.0490631014, pde B loss: 1.2981143789\n",
      "obs C loss: 1.8812628184, pde C loss: 0.2657835539\n",
      "obs D loss: 806.1402769089, pde D loss: 4.0670547634\n",
      "obs E loss: 106.2130988836, pde E loss: 1.0858469587\n",
      "obs F loss: 8.1131155491, pde F loss: 0.1697452012\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.69s\n",
      "\n",
      "Start of epoch 411\n",
      "Training observations acc over epoch: 155.2665557861\n",
      "total loss: 948.1521835327, total regularisd loss (sum of batches): 41719.2066650391\n",
      "obs A loss: 2.5226736516, pde A loss: 10.0391978174\n",
      "obs B loss: 8.0175493211, pde B loss: 1.0220136708\n",
      "obs C loss: 1.8808672614, pde C loss: 0.2369267477\n",
      "obs D loss: 804.7530965805, pde D loss: 4.1474446207\n",
      "obs E loss: 106.3204960823, pde E loss: 0.9455901282\n",
      "obs F loss: 8.1046758294, pde F loss: 0.1616499699\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.93s\n",
      "\n",
      "Start of epoch 412\n",
      "Training observations acc over epoch: 155.1780853271\n",
      "total loss: 943.6459102631, total regularisd loss (sum of batches): 41515.4249267578\n",
      "obs A loss: 2.4489652738, pde A loss: 7.6048408151\n",
      "obs B loss: 7.9934890717, pde B loss: 0.7088783961\n",
      "obs C loss: 1.8817153405, pde C loss: 0.2014200168\n",
      "obs D loss: 804.4662523270, pde D loss: 3.2455309220\n",
      "obs E loss: 106.1770327091, pde E loss: 0.6848079655\n",
      "obs F loss: 8.1010096371, pde F loss: 0.1319603366\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 413\n",
      "Training observations acc over epoch: 155.4659271240\n",
      "total loss: 964.3399906158, total regularisd loss (sum of batches): 42437.5072021484\n",
      "obs A loss: 2.5503924973, pde A loss: 16.2503247112\n",
      "obs B loss: 7.9873846471, pde B loss: 1.6915911371\n",
      "obs C loss: 1.8837051727, pde C loss: 0.3946395945\n",
      "obs D loss: 805.8709535599, pde D loss: 11.1761991195\n",
      "obs E loss: 106.3987140656, pde E loss: 1.7927487139\n",
      "obs F loss: 8.1043129563, pde F loss: 0.2390146786\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 202.1959075928\n",
      "total loss: 2018.2871246338, total regularisd loss (sum of batches): 88765.2833251953\n",
      "obs A loss: 4.4768089466, pde A loss: 484.3211383224\n",
      "obs B loss: 10.6562843919, pde B loss: 116.6078039333\n",
      "obs C loss: 2.2498267554, pde C loss: 13.2910201196\n",
      "obs D loss: 1051.3607139587, pde D loss: 88.4347442761\n",
      "obs E loss: 112.1768960953, pde E loss: 87.3750144318\n",
      "obs F loss: 32.2546987683, pde F loss: 15.0821800991\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 415\n",
      "Training observations acc over epoch: 192.9755096436\n",
      "total loss: 1216.6695709229, total regularisd loss (sum of batches): 53530.1929931641\n",
      "obs A loss: 6.0783914626, pde A loss: 31.6117889881\n",
      "obs B loss: 10.6746592969, pde B loss: 3.1327177621\n",
      "obs C loss: 2.0394257046, pde C loss: 2.0394854899\n",
      "obs D loss: 995.1638698578, pde D loss: 9.7046234459\n",
      "obs E loss: 111.4041912556, pde E loss: 10.5424115360\n",
      "obs F loss: 32.4926230311, pde F loss: 1.7853896301\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.65s\n",
      "\n",
      "Start of epoch 416\n",
      "Training observations acc over epoch: 183.7147521973\n",
      "total loss: 1140.7445755005, total regularisd loss (sum of batches): 50188.8822021484\n",
      "obs A loss: 5.7589395642, pde A loss: 20.6555317640\n",
      "obs B loss: 10.4157924354, pde B loss: 2.3745894842\n",
      "obs C loss: 2.0844230913, pde C loss: 0.9717976637\n",
      "obs D loss: 948.2170715332, pde D loss: 6.8215714619\n",
      "obs E loss: 110.3597481251, pde E loss: 6.6520257741\n",
      "obs F loss: 25.4525579810, pde F loss: 0.9805296352\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.41s\n",
      "\n",
      "Start of epoch 417\n",
      "Training observations acc over epoch: 178.5593719482\n",
      "total loss: 1101.8127517700, total regularisd loss (sum of batches): 48480.3467407227\n",
      "obs A loss: 5.4875853136, pde A loss: 15.2560459673\n",
      "obs B loss: 10.3039829433, pde B loss: 2.0717504807\n",
      "obs C loss: 1.9431592859, pde C loss: 0.6582918279\n",
      "obs D loss: 921.4635028839, pde D loss: 7.1372325942\n",
      "obs E loss: 110.2423171997, pde E loss: 4.7879942656\n",
      "obs F loss: 21.9157694280, pde F loss: 0.5451141987\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 418\n",
      "Training observations acc over epoch: 174.4960174561\n",
      "total loss: 1072.7271099091, total regularisd loss (sum of batches): 47193.1981201172\n",
      "obs A loss: 4.9967067391, pde A loss: 12.9766919464\n",
      "obs B loss: 10.0454426855, pde B loss: 1.7300207708\n",
      "obs C loss: 1.9191330448, pde C loss: 0.7745305346\n",
      "obs D loss: 900.5994014740, pde D loss: 5.9193279594\n",
      "obs E loss: 109.8309342861, pde E loss: 3.8330250084\n",
      "obs F loss: 19.5843121111, pde F loss: 0.5175780375\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 419\n",
      "Training observations acc over epoch: 171.2017364502\n",
      "total loss: 1048.6671752930, total regularisd loss (sum of batches): 46140.6572875977\n",
      "obs A loss: 4.0632430166, pde A loss: 11.0303836316\n",
      "obs B loss: 9.8264719397, pde B loss: 1.2935111560\n",
      "obs C loss: 1.9762859084, pde C loss: 0.7873979583\n",
      "obs D loss: 885.3717098236, pde D loss: 4.1234208643\n",
      "obs E loss: 109.0203453302, pde E loss: 3.7736831680\n",
      "obs F loss: 16.9521873593, pde F loss: 0.4485269422\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 420\n",
      "Training observations acc over epoch: 168.6379089355\n",
      "total loss: 1033.2501392365, total regularisd loss (sum of batches): 45455.7562866211\n",
      "obs A loss: 3.6579144299, pde A loss: 10.9947451204\n",
      "obs B loss: 9.6197074950, pde B loss: 1.1260035317\n",
      "obs C loss: 1.9070364088, pde C loss: 0.6437008874\n",
      "obs D loss: 873.3653392792, pde D loss: 4.6111961268\n",
      "obs E loss: 108.3056151867, pde E loss: 3.5825150684\n",
      "obs F loss: 14.9717658162, pde F loss: 0.4646002855\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 421\n",
      "Training observations acc over epoch: 166.9580841064\n",
      "total loss: 1022.0515041351, total regularisd loss (sum of batches): 44969.9210205078\n",
      "obs A loss: 3.5647056028, pde A loss: 10.5652612746\n",
      "obs B loss: 9.3695245385, pde B loss: 0.9134733118\n",
      "obs C loss: 1.8922019899, pde C loss: 0.5243165670\n",
      "obs D loss: 865.1407642365, pde D loss: 4.8924848139\n",
      "obs E loss: 107.9516111612, pde E loss: 2.9524849840\n",
      "obs F loss: 13.8297024667, pde F loss: 0.4549866547\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 422\n",
      "Training observations acc over epoch: 165.4818420410\n",
      "total loss: 1010.8510913849, total regularisd loss (sum of batches): 44482.7725830078\n",
      "obs A loss: 3.5018771514, pde A loss: 9.9600721300\n",
      "obs B loss: 9.2087389380, pde B loss: 0.7409442868\n",
      "obs C loss: 1.8975920454, pde C loss: 0.4055196652\n",
      "obs D loss: 857.5422382355, pde D loss: 3.8378992677\n",
      "obs E loss: 107.7919964790, pde E loss: 2.5792053081\n",
      "obs F loss: 12.9484751225, pde F loss: 0.4365244419\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.73s\n",
      "\n",
      "Start of epoch 423\n",
      "Training observations acc over epoch: 164.3627319336\n",
      "total loss: 1004.6386432648, total regularisd loss (sum of batches): 44207.3104248047\n",
      "obs A loss: 3.3784651756, pde A loss: 10.0441056192\n",
      "obs B loss: 9.0811367929, pde B loss: 0.6879846947\n",
      "obs C loss: 1.8922688887, pde C loss: 0.3661933853\n",
      "obs D loss: 852.0261383057, pde D loss: 4.4935573600\n",
      "obs E loss: 107.4432989359, pde E loss: 2.4217803143\n",
      "obs F loss: 12.3551238179, pde F loss: 0.4485866930\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 163.4942169189\n",
      "total loss: 997.8496379852, total regularisd loss (sum of batches): 43906.9565429688\n",
      "obs A loss: 3.2467435822, pde A loss: 9.2332758904\n",
      "obs B loss: 8.9687415212, pde B loss: 0.6916078692\n",
      "obs C loss: 1.8840712328, pde C loss: 0.3373179277\n",
      "obs D loss: 847.8608417511, pde D loss: 4.0705043934\n",
      "obs E loss: 107.2496296167, pde E loss: 2.1901721917\n",
      "obs F loss: 11.7553609163, pde F loss: 0.3613802930\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.41s\n",
      "\n",
      "Start of epoch 425\n",
      "Training observations acc over epoch: 162.1744232178\n",
      "total loss: 989.8383674622, total regularisd loss (sum of batches): 43552.1383056641\n",
      "obs A loss: 3.1351557523, pde A loss: 9.2707571834\n",
      "obs B loss: 8.8802139908, pde B loss: 0.7059450047\n",
      "obs C loss: 1.8747154530, pde C loss: 0.3405253515\n",
      "obs D loss: 841.1671352386, pde D loss: 4.0204935372\n",
      "obs E loss: 106.9484908581, pde E loss: 2.1422158778\n",
      "obs F loss: 11.0407837480, pde F loss: 0.3119351319\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 426\n",
      "Training observations acc over epoch: 161.1739349365\n",
      "total loss: 984.1511363983, total regularisd loss (sum of batches): 43305.7719116211\n",
      "obs A loss: 3.0179297701, pde A loss: 9.0944713801\n",
      "obs B loss: 8.7737430632, pde B loss: 0.8508932618\n",
      "obs C loss: 1.8751348052, pde C loss: 0.3695987933\n",
      "obs D loss: 835.9865379333, pde D loss: 4.2633051313\n",
      "obs E loss: 107.0329990387, pde E loss: 2.1761492230\n",
      "obs F loss: 10.3571783751, pde F loss: 0.3531815484\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 427\n",
      "Training observations acc over epoch: 160.3509979248\n",
      "total loss: 978.3632545471, total regularisd loss (sum of batches): 43048.7101440430\n",
      "obs A loss: 2.9377777241, pde A loss: 9.0888788253\n",
      "obs B loss: 8.7470759302, pde B loss: 0.7948196856\n",
      "obs C loss: 1.8746157512, pde C loss: 0.3897112785\n",
      "obs D loss: 831.6910438538, pde D loss: 3.8200003989\n",
      "obs E loss: 106.8988170624, pde E loss: 1.8203065768\n",
      "obs F loss: 9.9567124248, pde F loss: 0.3434993476\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 428\n",
      "Training observations acc over epoch: 159.6046447754\n",
      "total loss: 974.1035099030, total regularisd loss (sum of batches): 42855.7427368164\n",
      "obs A loss: 2.8870847784, pde A loss: 9.1297589391\n",
      "obs B loss: 8.7597728372, pde B loss: 0.8535811957\n",
      "obs C loss: 1.8725189660, pde C loss: 0.3935786462\n",
      "obs D loss: 827.6729087830, pde D loss: 4.1163614653\n",
      "obs E loss: 106.8353695869, pde E loss: 1.6849468462\n",
      "obs F loss: 9.6000241041, pde F loss: 0.2976016263\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.37s\n",
      "\n",
      "Start of epoch 429\n",
      "Training observations acc over epoch: 159.1085510254\n",
      "total loss: 970.5540447235, total regularisd loss (sum of batches): 42710.8977050781\n",
      "obs A loss: 2.8598550558, pde A loss: 9.1402650326\n",
      "obs B loss: 8.7120969892, pde B loss: 0.8095332608\n",
      "obs C loss: 1.8725331482, pde C loss: 0.3956439011\n",
      "obs D loss: 825.1851701736, pde D loss: 3.6350713186\n",
      "obs E loss: 106.6868687868, pde E loss: 1.6482384987\n",
      "obs F loss: 9.3348512799, pde F loss: 0.2739158063\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 430\n",
      "Training observations acc over epoch: 158.9668121338\n",
      "total loss: 973.6710319519, total regularisd loss (sum of batches): 42833.4055175781\n",
      "obs A loss: 2.8482650742, pde A loss: 10.5481700301\n",
      "obs B loss: 8.6602041274, pde B loss: 0.8920342019\n",
      "obs C loss: 1.8725368995, pde C loss: 0.4173099063\n",
      "obs D loss: 824.5853700638, pde D loss: 5.8274018914\n",
      "obs E loss: 106.6669373512, pde E loss: 1.9011095166\n",
      "obs F loss: 9.1675983518, pde F loss: 0.2840871350\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 431\n",
      "Training observations acc over epoch: 158.3632507324\n",
      "total loss: 966.5972499847, total regularisd loss (sum of batches): 42529.7647094727\n",
      "obs A loss: 2.8146545216, pde A loss: 9.2812976092\n",
      "obs B loss: 8.5867744088, pde B loss: 0.7795120208\n",
      "obs C loss: 1.8690017704, pde C loss: 0.3883460299\n",
      "obs D loss: 821.3316440582, pde D loss: 4.0401840918\n",
      "obs E loss: 106.5797266960, pde E loss: 1.6664831433\n",
      "obs F loss: 8.9977978170, pde F loss: 0.2618351099\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.70s\n",
      "\n",
      "Start of epoch 432\n",
      "Training observations acc over epoch: 158.2428741455\n",
      "total loss: 965.3732471466, total regularisd loss (sum of batches): 42467.7350463867\n",
      "obs A loss: 2.7526169717, pde A loss: 9.0588822514\n",
      "obs B loss: 8.5213115364, pde B loss: 0.8145608278\n",
      "obs C loss: 1.8684697710, pde C loss: 0.3523936211\n",
      "obs D loss: 820.8108835220, pde D loss: 3.8946930356\n",
      "obs E loss: 106.6415617466, pde E loss: 1.5425911639\n",
      "obs F loss: 8.8623674363, pde F loss: 0.2529267026\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 433\n",
      "Training observations acc over epoch: 158.0902252197\n",
      "total loss: 965.6431770325, total regularisd loss (sum of batches): 42484.6857910156\n",
      "obs A loss: 2.7200291120, pde A loss: 9.6550848633\n",
      "obs B loss: 8.4343906492, pde B loss: 0.8321082154\n",
      "obs C loss: 1.8683848139, pde C loss: 0.3709129486\n",
      "obs D loss: 820.2283840179, pde D loss: 4.5062796772\n",
      "obs E loss: 106.5410443544, pde E loss: 1.4872654509\n",
      "obs F loss: 8.7490145266, pde F loss: 0.2502860357\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.58s\n",
      "\n",
      "Start of epoch 434\n",
      "Training observations acc over epoch: 157.7219848633\n",
      "total loss: 963.7253799438, total regularisd loss (sum of batches): 42401.8312377930\n",
      "obs A loss: 2.6982314959, pde A loss: 10.1400545388\n",
      "obs B loss: 8.3527726084, pde B loss: 0.8808621140\n",
      "obs C loss: 1.8688861821, pde C loss: 0.3885500138\n",
      "obs D loss: 818.1431312561, pde D loss: 4.1496563032\n",
      "obs E loss: 106.6434181929, pde E loss: 1.5675899796\n",
      "obs F loss: 8.6254776865, pde F loss: 0.2667435929\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 157.5031127930\n",
      "total loss: 962.4726486206, total regularisd loss (sum of batches): 42341.7631835938\n",
      "obs A loss: 2.6106985658, pde A loss: 8.3640279174\n",
      "obs B loss: 8.2730275244, pde B loss: 0.8460302493\n",
      "obs C loss: 1.8677753806, pde C loss: 0.3536903365\n",
      "obs D loss: 817.1473960876, pde D loss: 5.9803004302\n",
      "obs E loss: 106.5933635235, pde E loss: 1.6334109437\n",
      "obs F loss: 8.5264216065, pde F loss: 0.2765070829\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 436\n",
      "Training observations acc over epoch: 157.3090362549\n",
      "total loss: 959.5511608124, total regularisd loss (sum of batches): 42223.4710083008\n",
      "obs A loss: 2.6306034625, pde A loss: 8.5695731491\n",
      "obs B loss: 8.2481341809, pde B loss: 0.7879071636\n",
      "obs C loss: 1.8659123387, pde C loss: 0.3318695743\n",
      "obs D loss: 816.1076335907, pde D loss: 4.4660561830\n",
      "obs E loss: 106.5609712601, pde E loss: 1.2931267153\n",
      "obs F loss: 8.4409371465, pde F loss: 0.2484397716\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 437\n",
      "Training observations acc over epoch: 157.0943450928\n",
      "total loss: 958.6994495392, total regularisd loss (sum of batches): 42181.7946777344\n",
      "obs A loss: 2.6112284325, pde A loss: 8.4763930738\n",
      "obs B loss: 8.2200561762, pde B loss: 0.8390088975\n",
      "obs C loss: 1.8664938062, pde C loss: 0.3726116726\n",
      "obs D loss: 815.1405439377, pde D loss: 4.8577028885\n",
      "obs E loss: 106.3447111845, pde E loss: 1.3433563225\n",
      "obs F loss: 8.3830327988, pde F loss: 0.2443124345\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.55s\n",
      "\n",
      "Start of epoch 438\n",
      "Training observations acc over epoch: 156.5993957520\n",
      "total loss: 954.5408859253, total regularisd loss (sum of batches): 42002.8150024414\n",
      "obs A loss: 2.5892832428, pde A loss: 8.3871270567\n",
      "obs B loss: 8.1926280707, pde B loss: 0.8010576330\n",
      "obs C loss: 1.8658624012, pde C loss: 0.3745087031\n",
      "obs D loss: 812.2727155685, pde D loss: 3.7658010609\n",
      "obs E loss: 106.3616790771, pde E loss: 1.3764654808\n",
      "obs F loss: 8.3141543716, pde F loss: 0.2396016680\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.56s\n",
      "\n",
      "Start of epoch 439\n",
      "Training observations acc over epoch: 156.8563385010\n",
      "total loss: 955.8822059631, total regularisd loss (sum of batches): 42055.8373413086\n",
      "obs A loss: 2.5842837580, pde A loss: 8.6357501000\n",
      "obs B loss: 8.1430430859, pde B loss: 0.8329946604\n",
      "obs C loss: 1.8680432681, pde C loss: 0.3900083266\n",
      "obs D loss: 813.7502355576, pde D loss: 3.2916122936\n",
      "obs E loss: 106.5163662434, pde E loss: 1.3462599497\n",
      "obs F loss: 8.2761243582, pde F loss: 0.2474711500\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.79s\n",
      "\n",
      "Start of epoch 440\n",
      "Training observations acc over epoch: 156.5457153320\n",
      "total loss: 953.9913291931, total regularisd loss (sum of batches): 41974.5065307617\n",
      "obs A loss: 2.5410399847, pde A loss: 8.7937358469\n",
      "obs B loss: 8.1386719793, pde B loss: 0.8435276477\n",
      "obs C loss: 1.8668679409, pde C loss: 0.3629162391\n",
      "obs D loss: 812.1565513611, pde D loss: 3.2792980149\n",
      "obs E loss: 106.3129310608, pde E loss: 1.2040657569\n",
      "obs F loss: 8.2580455393, pde F loss: 0.2336798483\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.68s\n",
      "\n",
      "Start of epoch 441\n",
      "Training observations acc over epoch: 156.4396972656\n",
      "total loss: 953.7696113586, total regularisd loss (sum of batches): 41967.6869506836\n",
      "obs A loss: 2.5086107738, pde A loss: 8.5376922637\n",
      "obs B loss: 8.0934045017, pde B loss: 0.8654701384\n",
      "obs C loss: 1.8679375984, pde C loss: 0.3969463413\n",
      "obs D loss: 811.6333875656, pde D loss: 3.7047187984\n",
      "obs E loss: 106.3093414307, pde E loss: 1.3797672205\n",
      "obs F loss: 8.2255940139, pde F loss: 0.2467415030\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 442\n",
      "Training observations acc over epoch: 156.2829589844\n",
      "total loss: 953.3279838562, total regularisd loss (sum of batches): 41943.3695678711\n",
      "obs A loss: 2.5077620223, pde A loss: 9.5009098947\n",
      "obs B loss: 8.0742525756, pde B loss: 0.8688719012\n",
      "obs C loss: 1.8654781096, pde C loss: 0.4011536664\n",
      "obs D loss: 810.6968975067, pde D loss: 3.1192018017\n",
      "obs E loss: 106.3498094082, pde E loss: 1.4903171249\n",
      "obs F loss: 8.2036198229, pde F loss: 0.2496977295\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.54s\n",
      "\n",
      "Start of epoch 443\n",
      "Training observations acc over epoch: 156.0664062500\n",
      "total loss: 951.0010223389, total regularisd loss (sum of batches): 41836.2570190430\n",
      "obs A loss: 2.5026795380, pde A loss: 8.5050764382\n",
      "obs B loss: 8.0317080468, pde B loss: 0.8351215348\n",
      "obs C loss: 1.8649925981, pde C loss: 0.3880524151\n",
      "obs D loss: 809.6021680832, pde D loss: 3.4124005921\n",
      "obs E loss: 106.2069286108, pde E loss: 1.2321408000\n",
      "obs F loss: 8.1901389658, pde F loss: 0.2296189666\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 444\n",
      "Training observations acc over epoch: 156.2774353027\n",
      "total loss: 956.9163799286, total regularisd loss (sum of batches): 42104.6904296875\n",
      "obs A loss: 2.5398238115, pde A loss: 10.7852946222\n",
      "obs B loss: 8.0119862556, pde B loss: 0.8642561119\n",
      "obs C loss: 1.8682865296, pde C loss: 0.4330109777\n",
      "obs D loss: 810.6337604523, pde D loss: 5.2151133120\n",
      "obs E loss: 106.4333674908, pde E loss: 1.6644378696\n",
      "obs F loss: 8.1772958785, pde F loss: 0.2897356190\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.91s\n",
      "\n",
      "Start of epoch 445\n",
      "Training observations acc over epoch: 156.2240905762\n",
      "total loss: 952.6509952545, total regularisd loss (sum of batches): 41908.6808471680\n",
      "obs A loss: 2.4977870807, pde A loss: 8.8498957306\n",
      "obs B loss: 7.9633741081, pde B loss: 0.8674718766\n",
      "obs C loss: 1.8664997462, pde C loss: 0.4042639560\n",
      "obs D loss: 810.5125656128, pde D loss: 3.8419801816\n",
      "obs E loss: 106.3358213902, pde E loss: 1.1099242400\n",
      "obs F loss: 8.1684324294, pde F loss: 0.2329790127\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 156.1000518799\n",
      "total loss: 952.1120281219, total regularisd loss (sum of batches): 41887.4104614258\n",
      "obs A loss: 2.5025614426, pde A loss: 9.1740905792\n",
      "obs B loss: 7.9533412457, pde B loss: 0.8438427048\n",
      "obs C loss: 1.8654536400, pde C loss: 0.3989591529\n",
      "obs D loss: 809.8262891769, pde D loss: 3.6041876487\n",
      "obs E loss: 106.3013691902, pde E loss: 1.2590857688\n",
      "obs F loss: 8.1512300819, pde F loss: 0.2316018615\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 447\n",
      "Training observations acc over epoch: 155.9471282959\n",
      "total loss: 950.0193462372, total regularisd loss (sum of batches): 41801.3392944336\n",
      "obs A loss: 2.4843483195, pde A loss: 8.2267114371\n",
      "obs B loss: 7.9292689562, pde B loss: 0.8158839867\n",
      "obs C loss: 1.8682196848, pde C loss: 0.3965357710\n",
      "obs D loss: 808.9994783401, pde D loss: 3.4822865240\n",
      "obs E loss: 106.2626862526, pde E loss: 1.1929819304\n",
      "obs F loss: 8.1386212111, pde F loss: 0.2223236880\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 448\n",
      "Training observations acc over epoch: 156.1254272461\n",
      "total loss: 952.7920913696, total regularisd loss (sum of batches): 41919.2199096680\n",
      "obs A loss: 2.4758587293, pde A loss: 8.6881450415\n",
      "obs B loss: 7.8596588522, pde B loss: 0.8090064256\n",
      "obs C loss: 1.8647466283, pde C loss: 0.3650036994\n",
      "obs D loss: 810.0736541748, pde D loss: 4.8274787515\n",
      "obs E loss: 106.3400480747, pde E loss: 1.1194059607\n",
      "obs F loss: 8.1386069059, pde F loss: 0.2304836079\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.74s\n",
      "\n",
      "Start of epoch 449\n",
      "Training observations acc over epoch: 156.1112670898\n",
      "total loss: 956.2952938080, total regularisd loss (sum of batches): 42083.1893920898\n",
      "obs A loss: 2.5443103313, pde A loss: 12.3348567933\n",
      "obs B loss: 7.8668913096, pde B loss: 1.0737325493\n",
      "obs C loss: 1.8649029378, pde C loss: 0.4373626825\n",
      "obs D loss: 809.9929904938, pde D loss: 4.0755023994\n",
      "obs E loss: 106.2602511644, pde E loss: 1.4537942540\n",
      "obs F loss: 8.1382014453, pde F loss: 0.2524930933\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.63s\n",
      "\n",
      "Start of epoch 450\n",
      "Training observations acc over epoch: 156.1082153320\n",
      "total loss: 953.2761993408, total regularisd loss (sum of batches): 41947.9967041016\n",
      "obs A loss: 2.5064950660, pde A loss: 9.2901399732\n",
      "obs B loss: 7.8265549839, pde B loss: 0.7873949502\n",
      "obs C loss: 1.8622389007, pde C loss: 0.3937860308\n",
      "obs D loss: 810.0542688370, pde D loss: 4.5589567535\n",
      "obs E loss: 106.2758407593, pde E loss: 1.3635228537\n",
      "obs F loss: 8.1239542067, pde F loss: 0.2330409759\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 451\n",
      "Training observations acc over epoch: 155.7398986816\n",
      "total loss: 948.9650249481, total regularisd loss (sum of batches): 41758.6624145508\n",
      "obs A loss: 2.4796744362, pde A loss: 8.7839661464\n",
      "obs B loss: 7.7742560506, pde B loss: 0.8043147000\n",
      "obs C loss: 1.8650712110, pde C loss: 0.3749105940\n",
      "obs D loss: 807.9500284195, pde D loss: 3.2876612917\n",
      "obs E loss: 106.2636897564, pde E loss: 1.0626165858\n",
      "obs F loss: 8.1066457331, pde F loss: 0.2121930476\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 452\n",
      "Training observations acc over epoch: 155.4870147705\n",
      "total loss: 945.9959754944, total regularisd loss (sum of batches): 41617.6402587891\n",
      "obs A loss: 2.4461085461, pde A loss: 7.9282195121\n",
      "obs B loss: 7.7584809959, pde B loss: 0.7778171711\n",
      "obs C loss: 1.8642644938, pde C loss: 0.3510644492\n",
      "obs D loss: 806.5534353256, pde D loss: 2.7854221798\n",
      "obs E loss: 106.2020177841, pde E loss: 1.0455288403\n",
      "obs F loss: 8.0976550281, pde F loss: 0.1859518380\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 453\n",
      "Training observations acc over epoch: 155.9146575928\n",
      "total loss: 950.0191783905, total regularisd loss (sum of batches): 41797.7360839844\n",
      "obs A loss: 2.4257241748, pde A loss: 8.8116739243\n",
      "obs B loss: 7.7157160193, pde B loss: 0.8149383543\n",
      "obs C loss: 1.8641714025, pde C loss: 0.3532411782\n",
      "obs D loss: 809.0638484955, pde D loss: 3.3077494912\n",
      "obs E loss: 106.3156013489, pde E loss: 1.0428577717\n",
      "obs F loss: 8.1029091775, pde F loss: 0.2007585934\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 454\n",
      "Training observations acc over epoch: 155.7980499268\n",
      "total loss: 949.5434703827, total regularisd loss (sum of batches): 41777.5704345703\n",
      "obs A loss: 2.3850171082, pde A loss: 8.5535506457\n",
      "obs B loss: 7.6882392466, pde B loss: 0.7545280252\n",
      "obs C loss: 1.8640521355, pde C loss: 0.3597861333\n",
      "obs D loss: 808.4573650360, pde D loss: 3.8087438308\n",
      "obs E loss: 106.2912348509, pde E loss: 1.0691848937\n",
      "obs F loss: 8.1023094356, pde F loss: 0.2094495585\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.52s\n",
      "\n",
      "Start of epoch 455\n",
      "Training observations acc over epoch: 155.7132720947\n",
      "total loss: 949.2164325714, total regularisd loss (sum of batches): 41768.9920043945\n",
      "obs A loss: 2.3555317409, pde A loss: 8.4457295537\n",
      "obs B loss: 7.6623242199, pde B loss: 0.7949482203\n",
      "obs C loss: 1.8651360180, pde C loss: 0.3508376027\n",
      "obs D loss: 808.1262931824, pde D loss: 4.0128426589\n",
      "obs E loss: 106.1752536297, pde E loss: 1.1104684845\n",
      "obs F loss: 8.0952000767, pde F loss: 0.2218653611\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 456\n",
      "Training observations acc over epoch: 155.4634399414\n",
      "total loss: 947.8554821014, total regularisd loss (sum of batches): 41709.9268798828\n",
      "obs A loss: 2.3522222564, pde A loss: 9.0201861262\n",
      "obs B loss: 7.6332875639, pde B loss: 0.7658678526\n",
      "obs C loss: 1.8626231495, pde C loss: 0.3452015757\n",
      "obs D loss: 806.7739706039, pde D loss: 3.6662495472\n",
      "obs E loss: 106.0733723640, pde E loss: 1.0657554865\n",
      "obs F loss: 8.0850735158, pde F loss: 0.2116526563\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 155.3856964111\n",
      "total loss: 945.8308124542, total regularisd loss (sum of batches): 41613.4083862305\n",
      "obs A loss: 2.3263985366, pde A loss: 7.9105665088\n",
      "obs B loss: 7.6121015996, pde B loss: 0.7291568229\n",
      "obs C loss: 1.8645270430, pde C loss: 0.3199438103\n",
      "obs D loss: 806.1346664429, pde D loss: 3.4260393195\n",
      "obs E loss: 106.3049653769, pde E loss: 0.9434831971\n",
      "obs F loss: 8.0713913888, pde F loss: 0.1875676615\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 458\n",
      "Training observations acc over epoch: 155.1548919678\n",
      "total loss: 944.2440586090, total regularisd loss (sum of batches): 41545.3433227539\n",
      "obs A loss: 2.2925039493, pde A loss: 7.6992786676\n",
      "obs B loss: 7.5869090855, pde B loss: 0.7385146739\n",
      "obs C loss: 1.8639028892, pde C loss: 0.3343991488\n",
      "obs D loss: 804.9840068817, pde D loss: 3.2631280050\n",
      "obs E loss: 106.1337740421, pde E loss: 1.0898664603\n",
      "obs F loss: 8.0679182112, pde F loss: 0.1898489243\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.40s\n",
      "\n",
      "Start of epoch 459\n",
      "Training observations acc over epoch: 155.2880249023\n",
      "total loss: 945.1363773346, total regularisd loss (sum of batches): 41582.8711547852\n",
      "obs A loss: 2.2995795533, pde A loss: 7.7977199554\n",
      "obs B loss: 7.5794780999, pde B loss: 0.7995930519\n",
      "obs C loss: 1.8646507524, pde C loss: 0.3136351719\n",
      "obs D loss: 805.5676479340, pde D loss: 3.3200287223\n",
      "obs E loss: 106.3514082432, pde E loss: 0.9838027116\n",
      "obs F loss: 8.0654758364, pde F loss: 0.1933665888\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.72s\n",
      "\n",
      "Start of epoch 460\n",
      "Training observations acc over epoch: 155.2931060791\n",
      "total loss: 946.0522899628, total regularisd loss (sum of batches): 41625.9745483398\n",
      "obs A loss: 2.2690572664, pde A loss: 8.0791312009\n",
      "obs B loss: 7.5279371589, pde B loss: 0.7383195059\n",
      "obs C loss: 1.8659002688, pde C loss: 0.3457184229\n",
      "obs D loss: 805.7715358734, pde D loss: 3.8663584944\n",
      "obs E loss: 106.2602427006, pde E loss: 1.0580531741\n",
      "obs F loss: 8.0637163669, pde F loss: 0.2063235608\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 461\n",
      "Training observations acc over epoch: 155.0913848877\n",
      "total loss: 944.0572986603, total regularisd loss (sum of batches): 41539.5311279297\n",
      "obs A loss: 2.2852485403, pde A loss: 7.7909604758\n",
      "obs B loss: 7.5143151283, pde B loss: 0.7728531389\n",
      "obs C loss: 1.8690364454, pde C loss: 0.3021238423\n",
      "obs D loss: 804.7293691635, pde D loss: 3.5147567559\n",
      "obs E loss: 106.0915672779, pde E loss: 0.9314528517\n",
      "obs F loss: 8.0586469471, pde F loss: 0.1969625207\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.78s\n",
      "\n",
      "Start of epoch 462\n",
      "Training observations acc over epoch: 155.8247222900\n",
      "total loss: 950.7584648132, total regularisd loss (sum of batches): 41831.1234741211\n",
      "obs A loss: 2.2844099738, pde A loss: 7.9479988366\n",
      "obs B loss: 7.5024781674, pde B loss: 0.7671531821\n",
      "obs C loss: 1.8639734183, pde C loss: 0.3234041384\n",
      "obs D loss: 808.9520177841, pde D loss: 5.4836766347\n",
      "obs E loss: 106.2538437843, pde E loss: 1.0727953399\n",
      "obs F loss: 8.0915624201, pde F loss: 0.2151516685\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 463\n",
      "Training observations acc over epoch: 155.4343566895\n",
      "total loss: 948.4702701569, total regularisd loss (sum of batches): 41729.6987915039\n",
      "obs A loss: 2.2903202623, pde A loss: 9.1076677218\n",
      "obs B loss: 7.4662541747, pde B loss: 0.8396026101\n",
      "obs C loss: 1.8613351509, pde C loss: 0.3322961028\n",
      "obs D loss: 806.6872539520, pde D loss: 4.1950253583\n",
      "obs E loss: 106.2341164351, pde E loss: 1.1682719588\n",
      "obs F loss: 8.0669810176, pde F loss: 0.2211571988\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.75s\n",
      "\n",
      "Start of epoch 464\n",
      "Training observations acc over epoch: 155.0797119141\n",
      "total loss: 943.0466518402, total regularisd loss (sum of batches): 41494.6256103516\n",
      "obs A loss: 2.2727477849, pde A loss: 6.9537717998\n",
      "obs B loss: 7.4558028877, pde B loss: 0.6753563313\n",
      "obs C loss: 1.8644691929, pde C loss: 0.3003170281\n",
      "obs D loss: 804.6105260849, pde D loss: 3.4687108584\n",
      "obs E loss: 106.2269480228, pde E loss: 0.9889866570\n",
      "obs F loss: 8.0476442277, pde F loss: 0.1813646026\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 465\n",
      "Training observations acc over epoch: 155.5666656494\n",
      "total loss: 950.7690334320, total regularisd loss (sum of batches): 41839.7259521484\n",
      "obs A loss: 2.2466949411, pde A loss: 8.7350721359\n",
      "obs B loss: 7.4141361862, pde B loss: 0.7833374608\n",
      "obs C loss: 1.8618168328, pde C loss: 0.3054573736\n",
      "obs D loss: 807.5613203049, pde D loss: 6.2868354842\n",
      "obs E loss: 106.2460994720, pde E loss: 1.0458960244\n",
      "obs F loss: 8.0698583424, pde F loss: 0.2125152261\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 466\n",
      "Training observations acc over epoch: 155.6398468018\n",
      "total loss: 954.7412624359, total regularisd loss (sum of batches): 42010.9052124023\n",
      "obs A loss: 2.3888958767, pde A loss: 11.3885281831\n",
      "obs B loss: 7.4219554663, pde B loss: 1.0477411849\n",
      "obs C loss: 1.8600021210, pde C loss: 0.3778192345\n",
      "obs D loss: 807.9057731628, pde D loss: 6.2322020009\n",
      "obs E loss: 106.1862287521, pde E loss: 1.5697287377\n",
      "obs F loss: 8.0761591792, pde F loss: 0.2862186318\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 467\n",
      "Training observations acc over epoch: 155.2992248535\n",
      "total loss: 948.8760147095, total regularisd loss (sum of batches): 41749.8308715820\n",
      "obs A loss: 2.3306972422, pde A loss: 9.0930163860\n",
      "obs B loss: 7.3889626414, pde B loss: 0.7884475673\n",
      "obs C loss: 1.8596195169, pde C loss: 0.3632150441\n",
      "obs D loss: 806.0453338623, pde D loss: 5.1356443837\n",
      "obs E loss: 106.1149303913, pde E loss: 1.4697290137\n",
      "obs F loss: 8.0556243360, pde F loss: 0.2307970736\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.45s\n",
      "\n",
      "Start of epoch 468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 155.2636566162\n",
      "total loss: 946.3022041321, total regularisd loss (sum of batches): 41639.2946166992\n",
      "obs A loss: 2.3322165161, pde A loss: 8.2342531830\n",
      "obs B loss: 7.3696813136, pde B loss: 0.8113882402\n",
      "obs C loss: 1.8622365855, pde C loss: 0.3087777174\n",
      "obs D loss: 805.7796812057, pde D loss: 4.0871927738\n",
      "obs E loss: 106.1918257475, pde E loss: 1.0901878327\n",
      "obs F loss: 8.0464483351, pde F loss: 0.1883128132\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.62s\n",
      "\n",
      "Start of epoch 469\n",
      "Training observations acc over epoch: 155.1741943359\n",
      "total loss: 946.8764019012, total regularisd loss (sum of batches): 41665.5773925781\n",
      "obs A loss: 2.3062191978, pde A loss: 8.2211237326\n",
      "obs B loss: 7.3377904743, pde B loss: 0.7700683037\n",
      "obs C loss: 1.8614450451, pde C loss: 0.3043522751\n",
      "obs D loss: 805.3739604950, pde D loss: 5.0831386447\n",
      "obs E loss: 106.1200671196, pde E loss: 1.2232607035\n",
      "obs F loss: 8.0454968214, pde F loss: 0.2294824994\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.61s\n",
      "\n",
      "Start of epoch 470\n",
      "Training observations acc over epoch: 155.1862182617\n",
      "total loss: 947.0599727631, total regularisd loss (sum of batches): 41669.6788940430\n",
      "obs A loss: 2.2796099521, pde A loss: 8.5430317074\n",
      "obs B loss: 7.3122280687, pde B loss: 0.7508919360\n",
      "obs C loss: 1.8611894213, pde C loss: 0.2946546446\n",
      "obs D loss: 805.5758428574, pde D loss: 4.9733216539\n",
      "obs E loss: 106.0426617861, pde E loss: 1.1550443070\n",
      "obs F loss: 8.0455971211, pde F loss: 0.2259022424\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.48s\n",
      "\n",
      "Start of epoch 471\n",
      "Training observations acc over epoch: 155.2184295654\n",
      "total loss: 945.3579711914, total regularisd loss (sum of batches): 41598.9767456055\n",
      "obs A loss: 2.2389863469, pde A loss: 8.5785239190\n",
      "obs B loss: 7.2860575467, pde B loss: 0.7217930853\n",
      "obs C loss: 1.8627854213, pde C loss: 0.2940581655\n",
      "obs D loss: 805.7146854401, pde D loss: 3.2342556529\n",
      "obs E loss: 106.1634902954, pde E loss: 1.0270656915\n",
      "obs F loss: 8.0446511507, pde F loss: 0.1916021365\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.28s\n",
      "\n",
      "Start of epoch 472\n",
      "Training observations acc over epoch: 154.8867950439\n",
      "total loss: 942.8719959259, total regularisd loss (sum of batches): 41485.8292236328\n",
      "obs A loss: 2.2815152705, pde A loss: 7.8509783745\n",
      "obs B loss: 7.2917658836, pde B loss: 0.7519021872\n",
      "obs C loss: 1.8616372310, pde C loss: 0.2454952602\n",
      "obs D loss: 803.7471942902, pde D loss: 3.7101420686\n",
      "obs E loss: 106.1041682959, pde E loss: 0.8282669177\n",
      "obs F loss: 8.0343862325, pde F loss: 0.1645443728\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.36s\n",
      "\n",
      "Start of epoch 473\n",
      "Training observations acc over epoch: 155.0823822021\n",
      "total loss: 944.4912567139, total regularisd loss (sum of batches): 41552.0682983398\n",
      "obs A loss: 2.2674707286, pde A loss: 7.8976659775\n",
      "obs B loss: 7.2489477694, pde B loss: 0.7227130840\n",
      "obs C loss: 1.8629895691, pde C loss: 0.2839206243\n",
      "obs D loss: 804.8806123734, pde D loss: 3.9802403897\n",
      "obs E loss: 106.1960723400, pde E loss: 0.9315920761\n",
      "obs F loss: 8.0381687433, pde F loss: 0.1808553599\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.57s\n",
      "\n",
      "Start of epoch 474\n",
      "Training observations acc over epoch: 154.9769744873\n",
      "total loss: 946.5440826416, total regularisd loss (sum of batches): 41645.5949707031\n",
      "obs A loss: 2.2820710652, pde A loss: 8.3887364119\n",
      "obs B loss: 7.2411869168, pde B loss: 0.8253465025\n",
      "obs C loss: 1.8622630201, pde C loss: 0.3024998638\n",
      "obs D loss: 804.2774238586, pde D loss: 5.7180775553\n",
      "obs E loss: 106.1710716486, pde E loss: 1.2288629152\n",
      "obs F loss: 8.0276971608, pde F loss: 0.2188492669\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.67s\n",
      "\n",
      "Start of epoch 475\n",
      "Training observations acc over epoch: 154.7573242188\n",
      "total loss: 940.6422519684, total regularisd loss (sum of batches): 41391.2350463867\n",
      "obs A loss: 2.2393422648, pde A loss: 7.0291429982\n",
      "obs B loss: 7.2082982957, pde B loss: 0.6603806838\n",
      "obs C loss: 1.8628505748, pde C loss: 0.2521063301\n",
      "obs D loss: 803.0396242142, pde D loss: 3.1213117614\n",
      "obs E loss: 106.1785831451, pde E loss: 0.8659462975\n",
      "obs F loss: 8.0151436329, pde F loss: 0.1695228631\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 476\n",
      "Training observations acc over epoch: 155.1026306152\n",
      "total loss: 945.4583320618, total regularisd loss (sum of batches): 41601.3299560547\n",
      "obs A loss: 2.2164620273, pde A loss: 8.6264716759\n",
      "obs B loss: 7.1838424504, pde B loss: 0.7689477056\n",
      "obs C loss: 1.8629885279, pde C loss: 0.2658701264\n",
      "obs D loss: 805.1931962967, pde D loss: 4.0583200492\n",
      "obs E loss: 106.1248927116, pde E loss: 0.9438440846\n",
      "obs F loss: 8.0341770649, pde F loss: 0.1793190234\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.64s\n",
      "\n",
      "Start of epoch 477\n",
      "Training observations acc over epoch: 155.2832946777\n",
      "total loss: 952.5259151459, total regularisd loss (sum of batches): 41905.0194702148\n",
      "obs A loss: 2.3023145460, pde A loss: 11.5385833532\n",
      "obs B loss: 7.1745307595, pde B loss: 1.0339441039\n",
      "obs C loss: 1.8600152507, pde C loss: 0.3578172196\n",
      "obs D loss: 806.0705509186, pde D loss: 6.1236492991\n",
      "obs E loss: 106.2483885288, pde E loss: 1.5415382423\n",
      "obs F loss: 8.0437355638, pde F loss: 0.2308344964\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.43s\n",
      "\n",
      "Start of epoch 478\n",
      "Training observations acc over epoch: 154.8587799072\n",
      "total loss: 944.0474128723, total regularisd loss (sum of batches): 41543.8961181641\n",
      "obs A loss: 2.3080537319, pde A loss: 8.8869052157\n",
      "obs B loss: 7.1801163405, pde B loss: 0.8222188856\n",
      "obs C loss: 1.8614733983, pde C loss: 0.2949507004\n",
      "obs D loss: 803.7050170898, pde D loss: 3.6746172197\n",
      "obs E loss: 106.0793626308, pde E loss: 1.0176504655\n",
      "obs F loss: 8.0183095187, pde F loss: 0.1987312299\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n",
      "\n",
      "Start of epoch 479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 155.0374145508\n",
      "total loss: 944.4013633728, total regularisd loss (sum of batches): 41556.8270874023\n",
      "obs A loss: 2.2421008758, pde A loss: 7.5224854425\n",
      "obs B loss: 7.1471860856, pde B loss: 0.6643081801\n",
      "obs C loss: 1.8620364033, pde C loss: 0.2564779534\n",
      "obs D loss: 804.8135910034, pde D loss: 4.5892463736\n",
      "obs E loss: 106.1301187277, pde E loss: 0.9691696260\n",
      "obs F loss: 8.0292690247, pde F loss: 0.1753770625\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.44s\n",
      "\n",
      "Start of epoch 480\n",
      "Training observations acc over epoch: 155.3264007568\n",
      "total loss: 949.8529090881, total regularisd loss (sum of batches): 41793.1651611328\n",
      "obs A loss: 2.2308000922, pde A loss: 9.1269658059\n",
      "obs B loss: 7.1239863187, pde B loss: 0.7734687785\n",
      "obs C loss: 1.8591336589, pde C loss: 0.2743288570\n",
      "obs D loss: 806.6235437393, pde D loss: 6.4185809232\n",
      "obs E loss: 106.0763044357, pde E loss: 1.0993283745\n",
      "obs F loss: 8.0442554057, pde F loss: 0.2022136173\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.51s\n",
      "\n",
      "Start of epoch 481\n",
      "Training observations acc over epoch: 154.7487945557\n",
      "total loss: 940.0611667633, total regularisd loss (sum of batches): 41360.9757690430\n",
      "obs A loss: 2.2268853337, pde A loss: 6.7792373151\n",
      "obs B loss: 7.1069780439, pde B loss: 0.6519559389\n",
      "obs C loss: 1.8612779137, pde C loss: 0.2296421598\n",
      "obs D loss: 803.1776018143, pde D loss: 2.9280825667\n",
      "obs E loss: 106.1078989506, pde E loss: 0.8291534148\n",
      "obs F loss: 8.0119899511, pde F loss: 0.1504653115\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 482\n",
      "Training observations acc over epoch: 154.7254943848\n",
      "total loss: 941.8996601105, total regularisd loss (sum of batches): 41445.5449829102\n",
      "obs A loss: 2.2078584768, pde A loss: 7.9059074372\n",
      "obs B loss: 7.0694696158, pde B loss: 0.7238567164\n",
      "obs C loss: 1.8635368794, pde C loss: 0.2591172834\n",
      "obs D loss: 803.1662521362, pde D loss: 3.5333808586\n",
      "obs E loss: 106.0308957100, pde E loss: 0.9626430599\n",
      "obs F loss: 8.0149676949, pde F loss: 0.1617675249\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.59s\n",
      "\n",
      "Start of epoch 483\n",
      "Training observations acc over epoch: 154.7239685059\n",
      "total loss: 940.9864864349, total regularisd loss (sum of batches): 41402.5747070312\n",
      "obs A loss: 2.1898675039, pde A loss: 7.0576053858\n",
      "obs B loss: 7.0601872206, pde B loss: 0.6840806575\n",
      "obs C loss: 1.8650860973, pde C loss: 0.2480245586\n",
      "obs D loss: 803.1406688690, pde D loss: 3.6206776798\n",
      "obs E loss: 106.0800244808, pde E loss: 0.8748187227\n",
      "obs F loss: 8.0076954067, pde F loss: 0.1577574515\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 484\n",
      "Training observations acc over epoch: 154.6061706543\n",
      "total loss: 939.7378540039, total regularisd loss (sum of batches): 41347.2339477539\n",
      "obs A loss: 2.1795868836, pde A loss: 7.0205664411\n",
      "obs B loss: 7.0193450749, pde B loss: 0.6585339019\n",
      "obs C loss: 1.8647090457, pde C loss: 0.2289305492\n",
      "obs D loss: 802.4600009918, pde D loss: 3.1866811849\n",
      "obs E loss: 106.1122707129, pde E loss: 0.8314218670\n",
      "obs F loss: 8.0009563118, pde F loss: 0.1748572292\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 485\n",
      "Training observations acc over epoch: 154.8773345947\n",
      "total loss: 942.2356090546, total regularisd loss (sum of batches): 41457.2795410156\n",
      "obs A loss: 2.1571487226, pde A loss: 7.3162143230\n",
      "obs B loss: 6.9974214286, pde B loss: 0.6820182921\n",
      "obs C loss: 1.8624338731, pde C loss: 0.2271799180\n",
      "obs D loss: 804.1969156265, pde D loss: 3.7087230925\n",
      "obs E loss: 106.0295975208, pde E loss: 0.8731832206\n",
      "obs F loss: 8.0202656239, pde F loss: 0.1645140627\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.40s\n",
      "\n",
      "Start of epoch 486\n",
      "Training observations acc over epoch: 154.7935943604\n",
      "total loss: 942.9432544708, total regularisd loss (sum of batches): 41489.0487060547\n",
      "obs A loss: 2.1513256207, pde A loss: 7.1354437992\n",
      "obs B loss: 6.9683474004, pde B loss: 0.7087444263\n",
      "obs C loss: 1.8612405043, pde C loss: 0.2346664255\n",
      "obs D loss: 803.6881752014, pde D loss: 5.0725339912\n",
      "obs E loss: 106.0861133337, pde E loss: 0.8609512271\n",
      "obs F loss: 8.0063290149, pde F loss: 0.1693863245\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.11s\n",
      "\n",
      "Start of epoch 487\n",
      "Training observations acc over epoch: 154.7525482178\n",
      "total loss: 946.3716049194, total regularisd loss (sum of batches): 41635.1492919922\n",
      "obs A loss: 2.2152445316, pde A loss: 10.3912273645\n",
      "obs B loss: 6.9749905765, pde B loss: 0.9185207495\n",
      "obs C loss: 1.8636902776, pde C loss: 0.3050994256\n",
      "obs D loss: 803.3735094070, pde D loss: 4.7640755735\n",
      "obs E loss: 106.0820944309, pde E loss: 1.2928548763\n",
      "obs F loss: 8.0055011511, pde F loss: 0.1847871880\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 488\n",
      "Training observations acc over epoch: 185.1517791748\n",
      "total loss: 1686.4403953552, total regularisd loss (sum of batches): 74190.6615600586\n",
      "obs A loss: 3.3923684824, pde A loss: 352.7643294334\n",
      "obs B loss: 9.2586052418, pde B loss: 60.5398084559\n",
      "obs C loss: 2.3104740493, pde C loss: 12.1605451074\n",
      "obs D loss: 960.2061042786, pde D loss: 93.9758571945\n",
      "obs E loss: 118.2194819450, pde E loss: 50.2337691374\n",
      "obs F loss: 17.5235508233, pde F loss: 5.8554912361\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 489\n",
      "Training observations acc over epoch: 196.5333709717\n",
      "total loss: 1240.6722583771, total regularisd loss (sum of batches): 54584.0532226562\n",
      "obs A loss: 5.2669663206, pde A loss: 30.8686798513\n",
      "obs B loss: 11.0637039542, pde B loss: 7.9440347515\n",
      "obs C loss: 1.9467103370, pde C loss: 2.4871956762\n",
      "obs D loss: 1010.0890254974, pde D loss: 11.1390994713\n",
      "obs E loss: 124.9361548424, pde E loss: 7.0689582974\n",
      "obs F loss: 25.8976234496, pde F loss: 1.9641037453\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.33s\n",
      "\n",
      "Start of epoch 490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 182.5062408447\n",
      "total loss: 1130.8367519379, total regularisd loss (sum of batches): 49754.6798095703\n",
      "obs A loss: 5.0849470943, pde A loss: 19.1881936789\n",
      "obs B loss: 10.7390309125, pde B loss: 1.9683348201\n",
      "obs C loss: 2.0275750645, pde C loss: 0.7268609302\n",
      "obs D loss: 941.1768474579, pde D loss: 5.9280378222\n",
      "obs E loss: 116.5102784634, pde E loss: 6.8904791772\n",
      "obs F loss: 19.4988072813, pde F loss: 1.0973574519\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.18s\n",
      "\n",
      "Start of epoch 491\n",
      "Training observations acc over epoch: 176.3855133057\n",
      "total loss: 1087.8442745209, total regularisd loss (sum of batches): 47869.2574462891\n",
      "obs A loss: 4.6279973835, pde A loss: 13.7938220650\n",
      "obs B loss: 10.6635639518, pde B loss: 1.2678499706\n",
      "obs C loss: 1.9692734387, pde C loss: 0.7019539177\n",
      "obs D loss: 910.8122081757, pde D loss: 6.1153838262\n",
      "obs E loss: 113.9993314743, pde E loss: 6.6068116724\n",
      "obs F loss: 16.2407403290, pde F loss: 1.0453426261\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.46s\n",
      "\n",
      "Start of epoch 492\n",
      "Training observations acc over epoch: 171.6033630371\n",
      "total loss: 1050.9590072632, total regularisd loss (sum of batches): 46241.8057861328\n",
      "obs A loss: 3.7699360326, pde A loss: 9.7658131272\n",
      "obs B loss: 10.4763073176, pde B loss: 0.7240739148\n",
      "obs C loss: 1.8934260830, pde C loss: 0.8236431889\n",
      "obs D loss: 887.7089157104, pde D loss: 4.1797599122\n",
      "obs E loss: 112.0301308632, pde E loss: 4.6856571883\n",
      "obs F loss: 13.7413136363, pde F loss: 1.1600347664\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.31s\n",
      "\n",
      "Start of epoch 493\n",
      "Training observations acc over epoch: 168.5986175537\n",
      "total loss: 1030.9489555359, total regularisd loss (sum of batches): 45362.3471069336\n",
      "obs A loss: 3.1826109439, pde A loss: 8.8542870581\n",
      "obs B loss: 10.2442435026, pde B loss: 0.8630046695\n",
      "obs C loss: 1.8909257203, pde C loss: 0.9039956927\n",
      "obs D loss: 873.2542896271, pde D loss: 4.1565435752\n",
      "obs E loss: 111.0996098518, pde E loss: 3.8149966374\n",
      "obs F loss: 11.9200829118, pde F loss: 0.7643603971\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.21s\n",
      "\n",
      "Start of epoch 494\n",
      "Training observations acc over epoch: 166.4802093506\n",
      "total loss: 1017.9386749268, total regularisd loss (sum of batches): 44793.3763427734\n",
      "obs A loss: 2.8688043915, pde A loss: 8.4287779927\n",
      "obs B loss: 10.1303871125, pde B loss: 1.0067513566\n",
      "obs C loss: 1.8748769090, pde C loss: 0.9129043967\n",
      "obs D loss: 862.5652828217, pde D loss: 4.8367936537\n",
      "obs E loss: 110.4442021847, pde E loss: 3.3452502415\n",
      "obs F loss: 10.9979321659, pde F loss: 0.5267103501\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.20s\n",
      "\n",
      "Start of epoch 495\n",
      "Training observations acc over epoch: 165.4081573486\n",
      "total loss: 1011.7929172516, total regularisd loss (sum of batches): 44524.8864746094\n",
      "obs A loss: 2.6577292830, pde A loss: 8.1534984708\n",
      "obs B loss: 9.9605298638, pde B loss: 1.0058273710\n",
      "obs C loss: 1.8737173714, pde C loss: 0.8252839521\n",
      "obs D loss: 857.3176364899, pde D loss: 5.9003052227\n",
      "obs E loss: 110.0875115395, pde E loss: 3.0448164716\n",
      "obs F loss: 10.5517030656, pde F loss: 0.4143503788\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.20s\n",
      "\n",
      "Start of epoch 496\n",
      "Training observations acc over epoch: 164.4639739990\n",
      "total loss: 1006.2967281342, total regularisd loss (sum of batches): 44278.4193725586\n",
      "obs A loss: 2.6436562799, pde A loss: 8.9561170712\n",
      "obs B loss: 9.8442476690, pde B loss: 0.9282447118\n",
      "obs C loss: 1.8751453217, pde C loss: 0.6887746211\n",
      "obs D loss: 852.5555839539, pde D loss: 5.7097839639\n",
      "obs E loss: 109.6507138014, pde E loss: 2.7768586762\n",
      "obs F loss: 10.2145162225, pde F loss: 0.4530810309\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.47s\n",
      "\n",
      "Start of epoch 497\n",
      "Training observations acc over epoch: 163.2728424072\n",
      "total loss: 994.5731830597, total regularisd loss (sum of batches): 43760.4387207031\n",
      "obs A loss: 2.5731671527, pde A loss: 7.4422482252\n",
      "obs B loss: 9.7255533189, pde B loss: 0.7661393685\n",
      "obs C loss: 1.8780293316, pde C loss: 0.5116582019\n",
      "obs D loss: 846.1737804413, pde D loss: 3.5364793725\n",
      "obs E loss: 109.3825888634, pde E loss: 2.3050614260\n",
      "obs F loss: 9.9040252864, pde F loss: 0.3744541630\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.49s\n",
      "\n",
      "Start of epoch 498\n",
      "Training observations acc over epoch: 162.3393707275\n",
      "total loss: 989.6079216003, total regularisd loss (sum of batches): 43537.3702392578\n",
      "obs A loss: 2.4211996980, pde A loss: 7.6962560937\n",
      "obs B loss: 9.5917655528, pde B loss: 0.8350754026\n",
      "obs C loss: 1.8732140008, pde C loss: 0.4853650928\n",
      "obs D loss: 841.4311027527, pde D loss: 3.8993118964\n",
      "obs E loss: 109.0386401415, pde E loss: 2.2622512653\n",
      "obs F loss: 9.6801703721, pde F loss: 0.3935691393\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.50s\n",
      "\n",
      "Start of epoch 499\n",
      "Training observations acc over epoch: 161.6802825928\n",
      "total loss: 986.6322364807, total regularisd loss (sum of batches): 43413.2774047852\n",
      "obs A loss: 2.2827111930, pde A loss: 7.8794101179\n",
      "obs B loss: 9.4893965125, pde B loss: 0.8560533347\n",
      "obs C loss: 1.8743200805, pde C loss: 0.4775223220\n",
      "obs D loss: 838.1395092010, pde D loss: 4.7361186147\n",
      "obs E loss: 108.7903666496, pde E loss: 2.2028408609\n",
      "obs F loss: 9.5054730177, pde F loss: 0.3985131439\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.42s\n"
     ]
    }
   ],
   "source": [
    "results = model.train(\n",
    "        epochs = 100,\n",
    "        batch_size = 1024,\n",
    "        X = obs_X,\n",
    "        Y = obs_Y,\n",
    "        print_interval=1,\n",
    "        stop_threshold=0,\n",
    "        shuffle=True,\n",
    "        sample_losses=True,\n",
    "        sample_parameters=True,\n",
    "        sample_regularisations=False,\n",
    "        sample_gradients=False,\n",
    "        regularise=False)\n",
    "\n",
    "model.optimizer.lr.assign(1e-4)\n",
    "\n",
    "results2 = model.train(\n",
    "        epochs = 500,\n",
    "        batch_size = 1024,\n",
    "        X = obs_X,\n",
    "        Y = obs_Y,\n",
    "        print_interval=1,\n",
    "        stop_threshold=0,\n",
    "        shuffle=True,\n",
    "        sample_losses=True,\n",
    "        sample_parameters=True,\n",
    "        sample_regularisations=False,\n",
    "        sample_gradients=False,\n",
    "        regularise=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0813b938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T11:09:40.625917Z",
     "start_time": "2022-08-19T07:32:32.394277Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training observations acc over epoch: 160.6791381836\n",
      "total loss: 976.8777503967, total regularisd loss (sum of batches): 42980.0263671875\n",
      "obs A loss: 2.2396738343, pde A loss: 6.8385827318\n",
      "obs B loss: 9.4536937028, pde B loss: 0.8065079851\n",
      "obs C loss: 1.8718741946, pde C loss: 0.4480265556\n",
      "obs D loss: 832.3795242310, pde D loss: 2.5196467154\n",
      "obs E loss: 108.7085883617, pde E loss: 1.7988897152\n",
      "obs F loss: 9.4215080291, pde F loss: 0.3912347159\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 64.69s\n",
      "\n",
      "Start of epoch 10\n",
      "Training observations acc over epoch: 159.8414916992\n",
      "total loss: 970.2834453583, total regularisd loss (sum of batches): 42692.1271362305\n",
      "obs A loss: 2.1751683466, pde A loss: 6.4344307259\n",
      "obs B loss: 9.4147357494, pde B loss: 0.7695713276\n",
      "obs C loss: 1.8719181716, pde C loss: 0.4240492946\n",
      "obs D loss: 827.9456176758, pde D loss: 1.5485740639\n",
      "obs E loss: 108.4147033691, pde E loss: 1.7094724216\n",
      "obs F loss: 9.2267790735, pde F loss: 0.3484203750\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 643.67s\n",
      "\n",
      "Start of epoch 20\n",
      "Training observations acc over epoch: 159.1629943848\n",
      "total loss: 966.0018882751, total regularisd loss (sum of batches): 42510.0538940430\n",
      "obs A loss: 2.1645639054, pde A loss: 6.4258322790\n",
      "obs B loss: 9.3154413700, pde B loss: 0.7660811702\n",
      "obs C loss: 1.8697256986, pde C loss: 0.3942525308\n",
      "obs D loss: 824.3672313690, pde D loss: 1.5442168750\n",
      "obs E loss: 108.1788406372, pde E loss: 1.5627103858\n",
      "obs F loss: 9.0819605440, pde F loss: 0.3310395475\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 643.68s\n",
      "\n",
      "Start of epoch 30\n",
      "Training observations acc over epoch: 158.4682617188\n",
      "total loss: 961.8720378876, total regularisd loss (sum of batches): 42321.9481201172\n",
      "obs A loss: 2.1221785024, pde A loss: 6.5063758790\n",
      "obs B loss: 9.1839193553, pde B loss: 0.8250668943\n",
      "obs C loss: 1.8703470249, pde C loss: 0.3912938763\n",
      "obs D loss: 820.7781562805, pde D loss: 1.6116756480\n",
      "obs E loss: 107.9485492706, pde E loss: 1.4053841345\n",
      "obs F loss: 8.9063031375, pde F loss: 0.3227797132\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 643.44s\n",
      "\n",
      "Start of epoch 40\n",
      "Training observations acc over epoch: 157.5386810303\n",
      "total loss: 956.4164142609, total regularisd loss (sum of batches): 42079.5298461914\n",
      "obs A loss: 2.0944944993, pde A loss: 6.6721657589\n",
      "obs B loss: 9.0572495162, pde B loss: 0.9024012350\n",
      "obs C loss: 1.8812366538, pde C loss: 0.4306620406\n",
      "obs D loss: 815.8769645691, pde D loss: 1.6357988697\n",
      "obs E loss: 107.5395774841, pde E loss: 1.2084904611\n",
      "obs F loss: 8.7825420201, pde F loss: 0.3348411457\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 644.68s\n",
      "\n",
      "Start of epoch 50\n",
      "Training observations acc over epoch: 156.5360412598\n",
      "total loss: 949.7011394501, total regularisd loss (sum of batches): 41790.6267089844\n",
      "obs A loss: 2.1615848839, pde A loss: 6.2003729567\n",
      "obs B loss: 8.6871373355, pde B loss: 0.8067982523\n",
      "obs C loss: 1.8900940642, pde C loss: 0.3409016263\n",
      "obs D loss: 810.5541296005, pde D loss: 1.7595051713\n",
      "obs E loss: 107.2819421291, pde E loss: 1.0248288587\n",
      "obs F loss: 8.6414531618, pde F loss: 0.3523823507\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 645.17s\n",
      "\n",
      "Start of epoch 60\n",
      "Training observations acc over epoch: 155.9022216797\n",
      "total loss: 945.2647933960, total regularisd loss (sum of batches): 41593.9352416992\n",
      "obs A loss: 2.1206804626, pde A loss: 5.9815339372\n",
      "obs B loss: 8.6441262960, pde B loss: 0.7319884449\n",
      "obs C loss: 1.8929093070, pde C loss: 0.3538609631\n",
      "obs D loss: 807.3767871857, pde D loss: 1.5258407667\n",
      "obs E loss: 106.9130966663, pde E loss: 0.8924279027\n",
      "obs F loss: 8.4657124281, pde F loss: 0.3658387782\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 645.45s\n",
      "\n",
      "Start of epoch 70\n",
      "Training observations acc over epoch: 155.3827667236\n",
      "total loss: 941.6191616058, total regularisd loss (sum of batches): 41440.1846923828\n",
      "obs A loss: 2.0704537034, pde A loss: 5.7453134283\n",
      "obs B loss: 8.5775172412, pde B loss: 0.6937946659\n",
      "obs C loss: 1.8937508985, pde C loss: 0.3383545964\n",
      "obs D loss: 804.6530990601, pde D loss: 1.4042105190\n",
      "obs E loss: 106.7435982227, pde E loss: 0.7857093420\n",
      "obs F loss: 8.3584206402, pde F loss: 0.3549292558\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 645.74s\n",
      "\n",
      "Start of epoch 80\n",
      "Training observations acc over epoch: 155.1318359375\n",
      "total loss: 939.7333488464, total regularisd loss (sum of batches): 41340.9162597656\n",
      "obs A loss: 2.0053854249, pde A loss: 5.6254774481\n",
      "obs B loss: 8.4916957766, pde B loss: 0.6768475026\n",
      "obs C loss: 1.8888360485, pde C loss: 0.3080726368\n",
      "obs D loss: 803.5077219009, pde D loss: 1.2867689766\n",
      "obs E loss: 106.6002941132, pde E loss: 0.7171781417\n",
      "obs F loss: 8.2972184718, pde F loss: 0.3278605021\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 646.21s\n",
      "\n",
      "Start of epoch 90\n",
      "Training observations acc over epoch: 154.7343902588\n",
      "total loss: 936.8916110992, total regularisd loss (sum of batches): 41228.7246093750\n",
      "obs A loss: 1.9727286808, pde A loss: 5.4712439477\n",
      "obs B loss: 8.4081726074, pde B loss: 0.6196511285\n",
      "obs C loss: 1.8810382709, pde C loss: 0.2745040846\n",
      "obs D loss: 801.5382633209, pde D loss: 1.1442569550\n",
      "obs E loss: 106.3540241718, pde E loss: 0.6877181232\n",
      "obs F loss: 8.2521185279, pde F loss: 0.2879002006\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 645.37s\n",
      "\n",
      "Start of epoch 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 154.5637817383\n",
      "total loss: 935.4499816895, total regularisd loss (sum of batches): 41159.0429077148\n",
      "obs A loss: 1.9193540253, pde A loss: 5.2321099564\n",
      "obs B loss: 8.2517808974, pde B loss: 0.5938911326\n",
      "obs C loss: 1.8784294482, pde C loss: 0.2409843951\n",
      "obs D loss: 800.8729457855, pde D loss: 1.0820783395\n",
      "obs E loss: 106.2325341702, pde E loss: 0.6558312466\n",
      "obs F loss: 8.2277171910, pde F loss: 0.2623343365\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 645.81s\n",
      "\n",
      "Start of epoch 110\n",
      "Training observations acc over epoch: 154.4509735107\n",
      "total loss: 934.5273170471, total regularisd loss (sum of batches): 41124.0249023438\n",
      "obs A loss: 1.8641128801, pde A loss: 5.0443560928\n",
      "obs B loss: 8.1078502238, pde B loss: 0.5890838969\n",
      "obs C loss: 1.8771243840, pde C loss: 0.2180548953\n",
      "obs D loss: 800.4255084991, pde D loss: 1.1162422057\n",
      "obs E loss: 106.2350432873, pde E loss: 0.6162004890\n",
      "obs F loss: 8.1960694194, pde F loss: 0.2376671871\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 645.89s\n",
      "\n",
      "Start of epoch 120\n",
      "Training observations acc over epoch: 154.3514709473\n",
      "total loss: 933.6877326965, total regularisd loss (sum of batches): 41087.3892822266\n",
      "obs A loss: 1.8085330799, pde A loss: 4.9221435189\n",
      "obs B loss: 7.9975291938, pde B loss: 0.5636374513\n",
      "obs C loss: 1.8783527091, pde C loss: 0.2091893787\n",
      "obs D loss: 799.9827194214, pde D loss: 1.0712354816\n",
      "obs E loss: 106.2731726170, pde E loss: 0.5972576560\n",
      "obs F loss: 8.1682832390, pde F loss: 0.2156728115\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 644.81s\n",
      "\n",
      "Start of epoch 130\n",
      "Training observations acc over epoch: 154.2789001465\n",
      "total loss: 932.9276809692, total regularisd loss (sum of batches): 41051.2393798828\n",
      "obs A loss: 1.7466539033, pde A loss: 4.7191464677\n",
      "obs B loss: 7.8922093660, pde B loss: 0.5559790470\n",
      "obs C loss: 1.8767070342, pde C loss: 0.1996674195\n",
      "obs D loss: 799.8683843613, pde D loss: 1.0357444044\n",
      "obs E loss: 106.1227231026, pde E loss: 0.5536967851\n",
      "obs F loss: 8.1664988399, pde F loss: 0.1902676704\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 644.61s\n",
      "\n",
      "Start of epoch 140\n",
      "Training observations acc over epoch: 154.2696838379\n",
      "total loss: 932.6381072998, total regularisd loss (sum of batches): 41031.2639160156\n",
      "obs A loss: 1.6827059574, pde A loss: 4.5895079300\n",
      "obs B loss: 7.7455574721, pde B loss: 0.5499004787\n",
      "obs C loss: 1.8760405555, pde C loss: 0.1992808650\n",
      "obs D loss: 800.0064039230, pde D loss: 0.9667926785\n",
      "obs E loss: 106.1678335667, pde E loss: 0.5425327420\n",
      "obs F loss: 8.1393305808, pde F loss: 0.1722264234\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 653.81s\n",
      "\n",
      "Start of epoch 150\n",
      "Training observations acc over epoch: 154.0789489746\n",
      "total loss: 931.4345054626, total regularisd loss (sum of batches): 40986.7822875977\n",
      "obs A loss: 1.6079509184, pde A loss: 4.5003571510\n",
      "obs B loss: 7.6244469136, pde B loss: 0.5569082573\n",
      "obs C loss: 1.8741723653, pde C loss: 0.1912006836\n",
      "obs D loss: 799.1804065704, pde D loss: 1.0366519261\n",
      "obs E loss: 106.0583636761, pde E loss: 0.5157021992\n",
      "obs F loss: 8.1280961782, pde F loss: 0.1602604643\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 661.38s\n",
      "\n",
      "Start of epoch 160\n",
      "Training observations acc over epoch: 154.0647735596\n",
      "total loss: 931.1713943481, total regularisd loss (sum of batches): 40968.1048583984\n",
      "obs A loss: 1.5313258730, pde A loss: 4.4256663993\n",
      "obs B loss: 7.5071520358, pde B loss: 0.5628242018\n",
      "obs C loss: 1.8736057598, pde C loss: 0.1826731653\n",
      "obs D loss: 799.2035999298, pde D loss: 0.9615603369\n",
      "obs E loss: 106.1593995094, pde E loss: 0.5035913475\n",
      "obs F loss: 8.1133715510, pde F loss: 0.1466303410\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 660.41s\n",
      "\n",
      "Start of epoch 170\n",
      "Training observations acc over epoch: 154.0074462891\n",
      "total loss: 930.6389484406, total regularisd loss (sum of batches): 40943.1306152344\n",
      "obs A loss: 1.4672213644, pde A loss: 4.2859924361\n",
      "obs B loss: 7.3911330402, pde B loss: 0.5782544212\n",
      "obs C loss: 1.8717013635, pde C loss: 0.1799973599\n",
      "obs D loss: 799.1935033798, pde D loss: 0.9180797171\n",
      "obs E loss: 106.0137385130, pde E loss: 0.4917796375\n",
      "obs F loss: 8.1073030829, pde F loss: 0.1402448211\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 670.64s\n",
      "\n",
      "Start of epoch 180\n",
      "Training observations acc over epoch: 153.9459838867\n",
      "total loss: 930.3393497467, total regularisd loss (sum of batches): 40929.3270263672\n",
      "obs A loss: 1.4117623065, pde A loss: 4.2846881077\n",
      "obs B loss: 7.2620845139, pde B loss: 0.5488253878\n",
      "obs C loss: 1.8701332062, pde C loss: 0.1746771252\n",
      "obs D loss: 799.0359582901, pde D loss: 1.0410825051\n",
      "obs E loss: 106.0043445826, pde E loss: 0.4788177591\n",
      "obs F loss: 8.0915976018, pde F loss: 0.1353739861\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 678.39s\n",
      "\n",
      "Start of epoch 190\n",
      "Training observations acc over epoch: 153.9048919678\n",
      "total loss: 929.9025058746, total regularisd loss (sum of batches): 40914.7177124023\n",
      "obs A loss: 1.3572998773, pde A loss: 4.1854390278\n",
      "obs B loss: 7.1453440785, pde B loss: 0.5481074154\n",
      "obs C loss: 1.8701007739, pde C loss: 0.1690254600\n",
      "obs D loss: 798.9153289795, pde D loss: 0.9605493499\n",
      "obs E loss: 106.0618436337, pde E loss: 0.4839860797\n",
      "obs F loss: 8.0791348964, pde F loss: 0.1263378682\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 658.59s\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr.assign(1e-5)\n",
    "\n",
    "results3 = model.train(\n",
    "        epochs = 200,\n",
    "        batch_size = 1024,\n",
    "        X = obs_X,\n",
    "        Y = obs_Y,\n",
    "        print_interval=10,\n",
    "        stop_threshold=0,\n",
    "        shuffle=True,\n",
    "        sample_losses=True,\n",
    "        sample_parameters=True,\n",
    "        sample_regularisations=False,\n",
    "        sample_gradients=False,\n",
    "        regularise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8cb16a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T11:27:42.447088Z",
     "start_time": "2022-08-19T11:27:40.745017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result_multi_nodes(merge_dict_multi_nodes(results, results2, results3),\n",
    "                        node_names=node_names, start=0,  yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870515b",
   "metadata": {},
   "source": [
    "### Run for 200 more epochs to make sure the convergence is so small that is relatively constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67cf21cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T15:20:22.946685Z",
     "start_time": "2022-08-19T11:27:55.919107Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training observations acc over epoch: 153.8324279785\n",
      "total loss: 929.3761119843, total regularisd loss (sum of batches): 40896.9869384766\n",
      "obs A loss: 1.3012268208, pde A loss: 4.0237238929\n",
      "obs B loss: 7.0261710137, pde B loss: 0.5383190159\n",
      "obs C loss: 1.8698054235, pde C loss: 0.1607211570\n",
      "obs D loss: 798.6647396088, pde D loss: 1.0672367206\n",
      "obs E loss: 106.0760610104, pde E loss: 0.4691079054\n",
      "obs F loss: 8.0564619601, pde F loss: 0.1225448246\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 70.19s\n",
      "\n",
      "Start of epoch 10\n",
      "Training observations acc over epoch: 153.8265380859\n",
      "total loss: 929.4687633514, total regularisd loss (sum of batches): 40897.4481201172\n",
      "obs A loss: 1.2435236722, pde A loss: 4.0656756014\n",
      "obs B loss: 6.8896751702, pde B loss: 0.5635547452\n",
      "obs C loss: 1.8689405117, pde C loss: 0.1581121176\n",
      "obs D loss: 798.8888111115, pde D loss: 1.1387770120\n",
      "obs E loss: 106.0200922489, pde E loss: 0.4654000448\n",
      "obs F loss: 8.0482252091, pde F loss: 0.1179955925\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 659.16s\n",
      "\n",
      "Start of epoch 20\n",
      "Training observations acc over epoch: 153.7281341553\n",
      "total loss: 928.4148082733, total regularisd loss (sum of batches): 40855.2438964844\n",
      "obs A loss: 1.1900804788, pde A loss: 3.9256773591\n",
      "obs B loss: 6.7294718921, pde B loss: 0.5326641835\n",
      "obs C loss: 1.8690261506, pde C loss: 0.1524565772\n",
      "obs D loss: 798.5406284332, pde D loss: 0.8848912446\n",
      "obs E loss: 105.9986643791, pde E loss: 0.4435375258\n",
      "obs F loss: 8.0408069938, pde F loss: 0.1069032871\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 684.89s\n",
      "\n",
      "Start of epoch 30\n",
      "Training observations acc over epoch: 153.6658782959\n",
      "total loss: 928.2609176636, total regularisd loss (sum of batches): 40853.3446044922\n",
      "obs A loss: 1.1456310488, pde A loss: 3.9540252164\n",
      "obs B loss: 6.5029474497, pde B loss: 0.5251276456\n",
      "obs C loss: 1.8676937930, pde C loss: 0.1509848039\n",
      "obs D loss: 798.4903430939, pde D loss: 1.0892629223\n",
      "obs E loss: 105.9548721313, pde E loss: 0.4457310932\n",
      "obs F loss: 8.0334393382, pde F loss: 0.1008587321\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 690.79s\n",
      "\n",
      "Start of epoch 40\n",
      "Training observations acc over epoch: 153.5368499756\n",
      "total loss: 927.0611782074, total regularisd loss (sum of batches): 40793.1237792969\n",
      "obs A loss: 1.1043358184, pde A loss: 3.8179523200\n",
      "obs B loss: 6.2697343379, pde B loss: 0.5320035042\n",
      "obs C loss: 1.8677288480, pde C loss: 0.1447677766\n",
      "obs D loss: 798.0129432678, pde D loss: 0.8316487866\n",
      "obs E loss: 105.9448039532, pde E loss: 0.4182307781\n",
      "obs F loss: 8.0213085711, pde F loss: 0.0957246871\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 682.15s\n",
      "\n",
      "Start of epoch 50\n",
      "Training observations acc over epoch: 153.5191040039\n",
      "total loss: 927.1434707642, total regularisd loss (sum of batches): 40796.7363891602\n",
      "obs A loss: 1.0684080683, pde A loss: 3.7995437682\n",
      "obs B loss: 6.0385954380, pde B loss: 0.5375623163\n",
      "obs C loss: 1.8673567474, pde C loss: 0.1429762067\n",
      "obs D loss: 798.1897697449, pde D loss: 1.0235176291\n",
      "obs E loss: 105.9391967058, pde E loss: 0.4287328217\n",
      "obs F loss: 8.0112524182, pde F loss: 0.0965633804\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 680.18s\n",
      "\n",
      "Start of epoch 60\n",
      "Training observations acc over epoch: 153.3982543945\n",
      "total loss: 926.0679283142, total regularisd loss (sum of batches): 40745.3630981445\n",
      "obs A loss: 1.0273434296, pde A loss: 3.7101575434\n",
      "obs B loss: 5.8378475606, pde B loss: 0.5051505016\n",
      "obs C loss: 1.8667340111, pde C loss: 0.1363492445\n",
      "obs D loss: 797.6811132431, pde D loss: 0.8336394634\n",
      "obs E loss: 105.9817111492, pde E loss: 0.3987734457\n",
      "obs F loss: 7.9946066886, pde F loss: 0.0944876134\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 672.61s\n",
      "\n",
      "Start of epoch 70\n",
      "Training observations acc over epoch: 153.2693176270\n",
      "total loss: 925.1999340057, total regularisd loss (sum of batches): 40707.9001464844\n",
      "obs A loss: 0.9839946367, pde A loss: 3.6154261976\n",
      "obs B loss: 5.6567022577, pde B loss: 0.4917550860\n",
      "obs C loss: 1.8653214201, pde C loss: 0.1346503557\n",
      "obs D loss: 797.2459897995, pde D loss: 0.8528623953\n",
      "obs E loss: 105.8770074844, pde E loss: 0.4004351976\n",
      "obs F loss: 7.9864683300, pde F loss: 0.0893290935\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 682.41s\n",
      "\n",
      "Start of epoch 80\n",
      "Training observations acc over epoch: 153.2762298584\n",
      "total loss: 925.3554306030, total regularisd loss (sum of batches): 40715.4209594727\n",
      "obs A loss: 0.9386943020, pde A loss: 3.6969819665\n",
      "obs B loss: 5.4426325113, pde B loss: 0.5085075079\n",
      "obs C loss: 1.8655875176, pde C loss: 0.1335863869\n",
      "obs D loss: 797.4690837860, pde D loss: 0.8777824007\n",
      "obs E loss: 105.9625766277, pde E loss: 0.3954891930\n",
      "obs F loss: 7.9784115553, pde F loss: 0.0860943643\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 690.02s\n",
      "\n",
      "Start of epoch 90\n",
      "Training observations acc over epoch: 153.1186065674\n",
      "total loss: 924.3523159027, total regularisd loss (sum of batches): 40671.3041992188\n",
      "obs A loss: 0.8791428134, pde A loss: 3.6142065153\n",
      "obs B loss: 5.1748301983, pde B loss: 0.5059563229\n",
      "obs C loss: 1.8651977759, pde C loss: 0.1320924822\n",
      "obs D loss: 796.9187240601, pde D loss: 0.9075116031\n",
      "obs E loss: 105.9135509729, pde E loss: 0.3971445295\n",
      "obs F loss: 7.9598151892, pde F loss: 0.0841499289\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 660.60s\n",
      "\n",
      "Start of epoch 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations acc over epoch: 153.0168457031\n",
      "total loss: 923.6166439056, total regularisd loss (sum of batches): 40634.1397705078\n",
      "obs A loss: 0.8374198526, pde A loss: 3.4984380528\n",
      "obs B loss: 4.8545579240, pde B loss: 0.5038538631\n",
      "obs C loss: 1.8650534917, pde C loss: 0.1292859977\n",
      "obs D loss: 796.6612367630, pde D loss: 0.9166045524\n",
      "obs E loss: 105.9374499321, pde E loss: 0.3865683363\n",
      "obs F loss: 7.9450771511, pde F loss: 0.0810905083\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 646.88s\n",
      "\n",
      "Start of epoch 110\n",
      "Training observations acc over epoch: 152.8710632324\n",
      "total loss: 922.7226963043, total regularisd loss (sum of batches): 40596.7324218750\n",
      "obs A loss: 0.8123221211, pde A loss: 3.4505549632\n",
      "obs B loss: 4.1814441383, pde B loss: 0.5102066323\n",
      "obs C loss: 1.8644015361, pde C loss: 0.1301482611\n",
      "obs D loss: 796.5305509567, pde D loss: 0.9267994054\n",
      "obs E loss: 105.9012891054, pde E loss: 0.3928769999\n",
      "obs F loss: 7.9360946864, pde F loss: 0.0860080055\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 661.76s\n",
      "\n",
      "Start of epoch 120\n",
      "Training observations acc over epoch: 152.7108917236\n",
      "total loss: 921.7842216492, total regularisd loss (sum of batches): 40564.4880981445\n",
      "obs A loss: 0.7889008913, pde A loss: 3.4657414556\n",
      "obs B loss: 3.4649328962, pde B loss: 0.5256544305\n",
      "obs C loss: 1.8627758026, pde C loss: 0.1260020030\n",
      "obs D loss: 796.3089551926, pde D loss: 0.9315615855\n",
      "obs E loss: 105.9121990204, pde E loss: 0.3837466231\n",
      "obs F loss: 7.9273858219, pde F loss: 0.0863669494\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 686.38s\n",
      "\n",
      "Start of epoch 130\n",
      "Training observations acc over epoch: 152.7125244141\n",
      "total loss: 921.5608215332, total regularisd loss (sum of batches): 40551.3256225586\n",
      "obs A loss: 0.7530078590, pde A loss: 3.3183645867\n",
      "obs B loss: 3.1062135994, pde B loss: 0.5238087066\n",
      "obs C loss: 1.8612950798, pde C loss: 0.1268641930\n",
      "obs D loss: 796.7454261780, pde D loss: 0.8756967643\n",
      "obs E loss: 105.8809614182, pde E loss: 0.3579539871\n",
      "obs F loss: 7.9281708598, pde F loss: 0.0830553306\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 655.84s\n",
      "\n",
      "Start of epoch 140\n",
      "Training observations acc over epoch: 152.6879425049\n",
      "total loss: 921.4219608307, total regularisd loss (sum of batches): 40550.3079223633\n",
      "obs A loss: 0.7164159957, pde A loss: 3.3546491899\n",
      "obs B loss: 2.8963873610, pde B loss: 0.5236395588\n",
      "obs C loss: 1.8589894846, pde C loss: 0.1208748026\n",
      "obs D loss: 796.9319734573, pde D loss: 0.8657276118\n",
      "obs E loss: 105.7960486412, pde E loss: 0.3453249978\n",
      "obs F loss: 7.9277444035, pde F loss: 0.0841939081\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 706.89s\n",
      "\n",
      "Start of epoch 150\n",
      "Training observations acc over epoch: 152.6448211670\n",
      "total loss: 921.0044116974, total regularisd loss (sum of batches): 40520.6409301758\n",
      "obs A loss: 0.6852724999, pde A loss: 3.2486718409\n",
      "obs B loss: 2.7429338917, pde B loss: 0.5253723627\n",
      "obs C loss: 1.8573014867, pde C loss: 0.1191180637\n",
      "obs D loss: 796.8355751038, pde D loss: 0.8272879245\n",
      "obs E loss: 105.8303565979, pde E loss: 0.3319211146\n",
      "obs F loss: 7.9173419774, pde F loss: 0.0832460681\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 709.90s\n",
      "\n",
      "Start of epoch 160\n",
      "Training observations acc over epoch: 152.5366516113\n",
      "total loss: 920.3022251129, total regularisd loss (sum of batches): 40490.1933593750\n",
      "obs A loss: 0.6583732376, pde A loss: 3.1935772076\n",
      "obs B loss: 2.6253364384, pde B loss: 0.5059602093\n",
      "obs C loss: 1.8559347466, pde C loss: 0.1163034292\n",
      "obs D loss: 796.3874845505, pde D loss: 0.8542490341\n",
      "obs E loss: 105.7761731148, pde E loss: 0.3284979262\n",
      "obs F loss: 7.9163998961, pde F loss: 0.0839309848\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 801.94s\n",
      "\n",
      "Start of epoch 170\n",
      "Training observations acc over epoch: 152.4630737305\n",
      "total loss: 919.7962150574, total regularisd loss (sum of batches): 40467.0225219727\n",
      "obs A loss: 0.6308804974, pde A loss: 3.1835515499\n",
      "obs B loss: 2.5213122256, pde B loss: 0.5028489139\n",
      "obs C loss: 1.8551475089, pde C loss: 0.1169152523\n",
      "obs D loss: 796.0991706848, pde D loss: 0.8104196033\n",
      "obs E loss: 105.7615464926, pde E loss: 0.3215644681\n",
      "obs F loss: 7.9101365209, pde F loss: 0.0827295908\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 781.15s\n",
      "\n",
      "Start of epoch 180\n",
      "Training observations acc over epoch: 152.3873443604\n",
      "total loss: 919.1767368317, total regularisd loss (sum of batches): 40449.0510253906\n",
      "obs A loss: 0.6066381894, pde A loss: 3.0971241482\n",
      "obs B loss: 2.4411108233, pde B loss: 0.4892644808\n",
      "obs C loss: 1.8543741889, pde C loss: 0.1142541566\n",
      "obs D loss: 795.7767734528, pde D loss: 0.7686503418\n",
      "obs E loss: 105.7391576767, pde E loss: 0.3056965489\n",
      "obs F loss: 7.9057666063, pde F loss: 0.0779138692\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 702.31s\n",
      "\n",
      "Start of epoch 190\n",
      "Training observations acc over epoch: 152.3972167969\n",
      "total loss: 919.2351684570, total regularisd loss (sum of batches): 40454.9926147461\n",
      "obs A loss: 0.5807272838, pde A loss: 3.0844770297\n",
      "obs B loss: 2.3659171835, pde B loss: 0.4729206013\n",
      "obs C loss: 1.8538952582, pde C loss: 0.1145559177\n",
      "obs D loss: 795.8989887238, pde D loss: 0.7885573255\n",
      "obs E loss: 105.7831091881, pde E loss: 0.3154963567\n",
      "obs F loss: 7.9002087116, pde F loss: 0.0763153112\n",
      "lambda obs A: 1.0000000000, lambda pde A: 1.0000000000\n",
      "lambda obs B: 1.0000000000, lambda pde B: 1.0000000000\n",
      "lambda obs C: 1.0000000000, lambda pde C: 1.0000000000\n",
      "lambda obs D: 1.0000000000, lambda pde D: 1.0000000000\n",
      "lambda obs E: 1.0000000000, lambda pde E: 1.0000000000\n",
      "lambda obs F: 1.0000000000, lambda pde F: 1.0000000000\n",
      "\n",
      "Time taken: 719.01s\n"
     ]
    }
   ],
   "source": [
    "results3 = model.train(\n",
    "        epochs = 200,\n",
    "        batch_size = 1024,\n",
    "        X = obs_X,\n",
    "        Y = obs_Y,\n",
    "        print_interval=10,\n",
    "        stop_threshold=0,\n",
    "        shuffle=True,\n",
    "        sample_losses=True,\n",
    "        sample_parameters=True,\n",
    "        sample_regularisations=False,\n",
    "        sample_gradients=False,\n",
    "        regularise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5357c9b",
   "metadata": {},
   "source": [
    "### For 200 epchos, the loss reduction was about 1 unit, which make sense, since the learning rate is $10^{-5}$. And increasing the learning rate keeps it at the plateau with spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c559358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T15:21:53.992976Z",
     "start_time": "2022-08-19T15:21:53.377117Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_result_multi_nodes(merge_dict_multi_nodes(results3),\n",
    "                        node_names=node_names, start=0,  yscale='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97900df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
