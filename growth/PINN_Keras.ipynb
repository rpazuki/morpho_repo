{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbfc782a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T10:40:56.265673Z",
     "start_time": "2022-06-13T10:40:53.642666Z"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import time\n",
    "import threading\n",
    "\n",
    "GPU = False\n",
    "import os\n",
    "\n",
    "if GPU:\n",
    "    txt_device = 'gpu:0'\n",
    "else:\n",
    "    txt_device = 'cpu:0'    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e894400c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T12:10:58.138276Z",
     "start_time": "2022-06-13T12:10:58.118262Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, layers, **kwargs):\n",
    "        \"\"\"\n",
    "        \n",
    "           layers: input, dense layers and outputs dimensions  \n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(self.layers)        \n",
    "        \n",
    "    def build(self, input_shape):         \n",
    "        \"\"\"Create the state of the layers (weights)\"\"\"\n",
    "        weights = []\n",
    "        biases = []        \n",
    "        for l in range(0,self.num_layers-1):\n",
    "            W = self.xavier_init(size=[self.layers[l], self.layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,self.layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        \n",
    "        self.Ws = weights\n",
    "        self.bs = biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.compat.v1.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), \n",
    "                           dtype=tf.float32)\n",
    "    \n",
    "    def normalise_input(self, inputs):\n",
    "        \"\"\"Map the inputs to the range [-1, 1]\"\"\"\n",
    "        return 2.0*(inputs - self.lb)/(self.ub - self.lb) - 1.0\n",
    "    \n",
    "    def __net__(self, inputs):\n",
    "        H = inputs   \n",
    "        for W,b in zip(self.Ws[:-1], self.bs[:-1]):\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "            \n",
    "            W = self.Ws[-1]\n",
    "            b = self.bs[-1]\n",
    "            outputs = tf.add(tf.matmul(H, W), b)\n",
    "        return outputs\n",
    "    \n",
    "    def call(self, inputs, grads=True):\n",
    "        \"\"\"Defines the computation from inputs to outputs\"\"\"\n",
    "        \n",
    "                                                     \n",
    "                        \n",
    "        if grads:\n",
    "            with tf.GradientTape(persistent=False) as second_order_t:\n",
    "                second_order_t.watch(inputs)\n",
    "                with tf.GradientTape(persistent=False) as first_order_t:\n",
    "                    first_order_t.watch(inputs)                \n",
    "                    outputs = self.__net__(inputs)\n",
    "                \n",
    "                    first_orders = first_order_t.gradient(outputs, inputs)        \n",
    "                    second_orders = second_order_t.gradient(first_orders, inputs)\n",
    "            return outputs, first_orders, second_orders\n",
    "        else:\n",
    "            outputs = self.__net__(inputs)\n",
    "            return outputs\n",
    "    \n",
    "    def grads(self):\n",
    "        first_orders = self.first_order_t.gradient(self.Y, self.X)        \n",
    "        secnd_orders = self.second_order_t.gradient(first_orders, self.X)\n",
    "        return first_orders, secnd_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fa0ff6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T12:10:58.670050Z",
     "start_time": "2022-06-13T12:10:58.662034Z"
    }
   },
   "outputs": [],
   "source": [
    "def lower_upper_bounds(inputs_of_inputs):\n",
    "    \"\"\"Find the lower and upper bounds of inputs\n",
    "    \n",
    "       inputs_of_inputs: a list of tensors that their axis one have the same number \n",
    "                         of columns\n",
    "    \"\"\"\n",
    "           \n",
    "    inputs_dim = np.asarray(inputs_of_inputs[0]).shape[1]\n",
    "    lb = np.array([np.inf] * inputs_dim)\n",
    "    ub = np.array([-np.inf] * inputs_dim)\n",
    "    for i, inputs in enumerate(inputs_of_inputs):        \n",
    "        assert inputs_dim == np.asarray(inputs).shape[1]\n",
    "        lb = np.amin(np.c_[inputs.min(0), lb], 1)\n",
    "        ub = np.amax(np.c_[inputs.max(0), ub], 1)\n",
    "        \n",
    "    return lb, ub\n",
    "    \n",
    "def normalise_inputs(inputs_of_inputs):\n",
    "    \"\"\"Scales the values along axis 1 to [-1, 1]\n",
    "    \n",
    "       inputs_of_inputs: a list of tensors that their axis one have the same number \n",
    "                         of columns\n",
    "    \"\"\"\n",
    "    if type(inputs_of_inputs) is not list:\n",
    "        inputs_of_inputs = [inputs_of_inputs]        \n",
    "            \n",
    "    lb, ub = lower_upper_bounds(inputs_of_inputs)\n",
    "    return [2.0*(inputs-lb)/(ub-lb) - 1.0 for inputs in inputs_of_inputs]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e7f0a33a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T12:10:59.370286Z",
     "start_time": "2022-06-13T12:10:59.361736Z"
    }
   },
   "outputs": [],
   "source": [
    "layers = [3, 10, 10, 10, 2]\n",
    "sample_xyt  = np.array([ [0, 0, 0],\n",
    "                         [0, 1, 0],\n",
    "                         [1, 0, 0],\n",
    "                         [1, 1, 0],\n",
    "                         [0, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [1, 0, 1],\n",
    "                         [1, 1, 1],\n",
    "                         [0, 0, 2],\n",
    "                         [0, 1, 2],\n",
    "                         [1, 0, 2],\n",
    "                         [1, 1, 2]\n",
    "                       ])\n",
    "\n",
    "#lb, ub = lower_upper_bounds(sample_xyt)\n",
    "#print(normalise_inputs([sample_xyt, sample_xyt.copy()*2]))\n",
    "\n",
    "model = NN(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9884583d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T12:11:05.203283Z",
     "start_time": "2022-06-13T12:11:05.180213Z"
    }
   },
   "outputs": [],
   "source": [
    "i = tf.constant(sample_xyt*1.0)\n",
    "o = model(i, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e3af123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T12:11:05.828212Z",
     "start_time": "2022-06-13T12:11:05.818801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(12, 2), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [-0.08767529, -0.21518287],\n",
       "        [-0.02415903, -0.08333324],\n",
       "        [-0.16224366, -0.27726024],\n",
       "        [ 0.4444737 , -0.36355215],\n",
       "        [ 0.28590775, -0.52748233],\n",
       "        [ 0.30637497, -0.3949511 ],\n",
       "        [ 0.16782539, -0.58145547],\n",
       "        [ 0.65741426, -0.5023011 ],\n",
       "        [ 0.5166262 , -0.6460754 ],\n",
       "        [ 0.47272864, -0.5192702 ],\n",
       "        [ 0.36170444, -0.6895684 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(12, 3), dtype=float32, numpy=\n",
       " array([[-0.20433848, -0.33760384,  0.08058533],\n",
       "        [-0.20068434, -0.24486914,  0.01957287],\n",
       "        [ 0.01540439, -0.33235598,  0.02412978],\n",
       "        [-0.01175655, -0.28502095, -0.00749357],\n",
       "        [-0.20690554, -0.30236012,  0.0807012 ],\n",
       "        [-0.17983906, -0.29743984,  0.09972762],\n",
       "        [-0.07386359, -0.29976797,  0.02648415],\n",
       "        [-0.07915174, -0.31036854,  0.06210135],\n",
       "        [-0.18094352, -0.252105  ,  0.06414592],\n",
       "        [-0.14204231, -0.28870624,  0.11220174],\n",
       "        [-0.15686458, -0.26313546,  0.05565698],\n",
       "        [-0.17088571, -0.27562633,  0.10138106]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(12, 3), dtype=float32, numpy=\n",
       " array([[ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.03130911,  0.07008214, -0.00446193],\n",
       "        [ 0.16354647, -0.0105414 , -0.10050105],\n",
       "        [ 0.15530841,  0.0016979 , -0.0638631 ],\n",
       "        [-0.10489126, -0.04790611,  0.05582737],\n",
       "        [-0.11969432,  0.11512443,  0.06670924],\n",
       "        [ 0.14306839, -0.04715073, -0.02065039],\n",
       "        [ 0.14639406,  0.07806395, -0.01047164],\n",
       "        [-0.12043138, -0.04827183,  0.06020175],\n",
       "        [-0.15820275,  0.1176645 ,  0.05168908],\n",
       "        [ 0.09937333, -0.05454154, -0.01506297],\n",
       "        [ 0.10834323,  0.08319358, -0.01912568]], dtype=float32)>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea73b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
