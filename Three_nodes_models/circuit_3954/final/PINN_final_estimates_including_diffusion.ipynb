{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7d92a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:28.142814Z",
     "start_time": "2023-07-25T02:26:14.192566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MEMORY = 32*1024\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.set_logical_device_configuration(gpus[0],\n",
    "                                              [tf.config.LogicalDeviceConfiguration(memory_limit=MEMORY)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "except RuntimeError as e:        \n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e) \n",
    "    \n",
    "import pathlib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "sys.path.append(f\"{Path.home()}/morpho_repo\")\n",
    "sys.path.append(f\"{Path.home()}/morpho_repo/turing_codebase\")\n",
    "from turing.utils import *\n",
    "from turing.tf_utils import *\n",
    "import turing.pinns as tu\n",
    "from turing.loss_functions import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1829d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9846c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:39.129695Z",
     "start_time": "2023-07-25T02:26:39.108515Z"
    }
   },
   "outputs": [],
   "source": [
    "from pde_solvers.cn import *\n",
    "from local_utils import *\n",
    "from turing.three_nodes_circuits import create_circuit_3954"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a991c",
   "metadata": {},
   "source": [
    "# Load the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a7201f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:41.079650Z",
     "start_time": "2023-07-25T02:26:41.058047Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../with_diffusions_second_search/df_network_analysis_full_topology_with_estimates.csv\")\n",
    "df[\"adj_tup\"] = df[\"adj_tup\"].apply(lambda x: eval(f\"tuple({x})\"))\n",
    "df[\"Adj\"] = df[\"adj_tup\"].apply(lambda x: np.array(x).reshape((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31caa7c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:42.144078Z",
     "start_time": "2023-07-25T02:26:42.132018Z"
    }
   },
   "outputs": [],
   "source": [
    "adj=np.array([[1, 1, -1], [-1, 0, -1], [0, -1, 1]])\n",
    "subnet_list = [g[1] for g in df.groupby(\"adj_tup\") if g[0] == tuple(adj.flatten())]\n",
    "if len(subnet_list) == 0:\n",
    "    print(\"================================\")\n",
    "    print(\"There is no adjacancy matrix as: \", adj)\n",
    "    print(\"================================\")\n",
    "else:\n",
    "    subnet_df = subnet_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050355fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:43.199099Z",
     "start_time": "2023-07-25T02:26:43.168604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>min_A</th>\n",
       "      <th>min_B</th>\n",
       "      <th>min_C</th>\n",
       "      <th>avg_A</th>\n",
       "      <th>avg_B</th>\n",
       "      <th>avg_C</th>\n",
       "      <th>max_A</th>\n",
       "      <th>max_B</th>\n",
       "      <th>max_C</th>\n",
       "      <th>...</th>\n",
       "      <th>b_C_est_ratio</th>\n",
       "      <th>V_C_est_ratio</th>\n",
       "      <th>K_AC_est_ratio</th>\n",
       "      <th>K_BC_est_ratio</th>\n",
       "      <th>K_CC_est_ratio</th>\n",
       "      <th>bad_estimates</th>\n",
       "      <th>list_of_bad_estimates</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_hat</th>\n",
       "      <th>loss_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.879311</td>\n",
       "      <td>27.4671</td>\n",
       "      <td>2.00005</td>\n",
       "      <td>3.859942</td>\n",
       "      <td>31.707845</td>\n",
       "      <td>2.000238</td>\n",
       "      <td>6.759598</td>\n",
       "      <td>35.970982</td>\n",
       "      <td>2.000543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>1.013337</td>\n",
       "      <td>2.379039</td>\n",
       "      <td>0.894056</td>\n",
       "      <td>2</td>\n",
       "      <td>('V_C', 'K_BC')</td>\n",
       "      <td>9.617466e-08</td>\n",
       "      <td>2.276804e-08</td>\n",
       "      <td>0.763264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     min_A    min_B    min_C     avg_A      avg_B     avg_C  \\\n",
       "0           0  0.879311  27.4671  2.00005  3.859942  31.707845  2.000238   \n",
       "\n",
       "      max_A      max_B     max_C  ...  b_C_est_ratio  V_C_est_ratio  \\\n",
       "0  6.759598  35.970982  2.000543  ...       0.999996       0.020842   \n",
       "\n",
       "   K_AC_est_ratio K_BC_est_ratio  K_CC_est_ratio  bad_estimates  \\\n",
       "0        1.013337       2.379039        0.894056              2   \n",
       "\n",
       "  list_of_bad_estimates          loss      loss_hat loss_ratio  \n",
       "0       ('V_C', 'K_BC')  9.617466e-08  2.276804e-08   0.763264  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subnet_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e2149f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:44.710605Z",
     "start_time": "2023-07-25T02:26:44.698268Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    with open(f\"../{path}\", \"rb\") as f:\n",
    "        k_max, params, res = np.load(f, allow_pickle=True)\n",
    "    (n_val, \n",
    "     b_A_val, mu_A_val, V_A_val, K_AA_val, K_AB_val, K_AC_val,\n",
    "     b_B_val, mu_B_val, V_B_val, K_BA_val, K_BC_val,\n",
    "     b_C_val, mu_C_val, V_C_val, K_CB_val, K_CC_val) = params\n",
    "    params = {\n",
    "              'D_A':0.01,\n",
    "              'D_B':1.0,\n",
    "              'n':n_val, \n",
    "              'b_A':b_A_val, \n",
    "              'mu_A':mu_A_val, \n",
    "              'V_A':V_A_val,\n",
    "              'K_AA':K_AA_val, \n",
    "              'K_AB':K_AB_val,  \n",
    "              'K_AC':K_AC_val,\n",
    "              'b_B':b_B_val, \n",
    "              'mu_B':mu_B_val, \n",
    "              'V_B':V_B_val,\n",
    "              'K_BA':K_BA_val, \n",
    "              'K_BC':K_BC_val,  \n",
    "              'b_C':b_C_val, \n",
    "              'mu_C':mu_C_val, \n",
    "              'V_C':V_C_val,\n",
    "              'K_CB':K_CB_val, \n",
    "              'K_CC':K_CC_val\n",
    "             }\n",
    "           \n",
    "    return (params, res, k_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde5f018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:45.689157Z",
     "start_time": "2023-07-25T02:26:45.669631Z"
    },
    "code_folding": [
     2,
     7,
     49
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def cos_dist(arr1, arr2):\n",
    "    arr1_L = np.sqrt(np.dot(arr1, arr1))\n",
    "    arr2_L = np.sqrt(np.dot(arr2, arr2))\n",
    "    return np.dot(arr1, arr2)/(arr1_L*arr2_L)\n",
    "\n",
    "def alienor_components2(epsilon, l1, bounds):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "          epsilon (float): The accuracy of the estimates.\n",
    "          l1 (float): Lipschitz constant\n",
    "          bounds (list of tuples):\n",
    "          bounds like [a_i, b_i], for each variables separatly.\n",
    "          \n",
    "          \n",
    "    \"\"\"\n",
    "    n = len(bounds) \n",
    "    assert n >= 2, \"The method expects two or more vairbales.\"\n",
    "    assert np.all([len(item) == 2 \n",
    "                   for item in bounds]), \"bounds must be tuple of (a_i,b_i)\"\n",
    "    \n",
    "    alpha = epsilon/(2*l1*np.sqrt(n-1))\n",
    "    alphas = np.ones(n)\n",
    "    \n",
    "    def get_h_i(a,b,alpha):\n",
    "        def h_i(t):\n",
    "            return (a-b)*np.cos(alpha*t)/2 + (a+b)/2\n",
    "        return h_i\n",
    "    a,b = bounds[0]\n",
    "    h_i = get_h_i(a,b,1)\n",
    "    h_list = [h_i]\n",
    "    for i in range(1, n):\n",
    "        # [a_i, b_i]\n",
    "        a,b = bounds[i]\n",
    "        # alphas[i-1] (alpha/pi) / (|b_i| + |a_i|)\n",
    "        alphas[i] = alpha*alphas[i-1]/(np.pi*(np.abs(b)+np.abs(a)))\n",
    "        # h_i = (a_i - b_i)cos(alpha_i theta)/2 +  (a_i + b_i)/2         \n",
    "        h_i = h_i = get_h_i(a,b,alphas[i])#\n",
    "        h_list.append(h_i)        \n",
    "        \n",
    "        \n",
    "    # l2 or Lipschitz constant of the aliemor h functions\n",
    "    l2 = np.linalg.norm([(np.abs(d[1])+np.abs(d[0]))**2 * a**2 for d,a in zip(bounds,alphas) ])/2\n",
    "    #\n",
    "    theta_max = np.pi/alphas[-1]    \n",
    "    return alpha, alphas, l2, h_list, theta_max\n",
    "\n",
    "def minim_2(epsilon, l1, bounds, func, maxiter=10000):\n",
    "    alpha, alphas, l2, h_list, theta_max = alienor_components2(epsilon, l1, bounds)\n",
    "    k = 1\n",
    "    L = l1 * l2\n",
    "    theta = epsilon / L    \n",
    "    theta_epsilon = theta\n",
    "    \n",
    "    f = lambda t: func(*[ h(t) for h in h_list])\n",
    "    f_epsilon = f_theta = f(theta_epsilon)\n",
    "    \n",
    "    while k < maxiter:\n",
    "        if theta > np.pi/alphas[-1]:            \n",
    "            return k, theta,theta_epsilon, f_epsilon, \"\"\n",
    "        \n",
    "        theta = theta + (epsilon + f_theta - f_epsilon)/ L        \n",
    "        f_theta  =  f(theta)\n",
    "        if f_theta < f_epsilon:\n",
    "            f_epsilon = f_theta\n",
    "            theta_epsilon = theta\n",
    "        k += 1    \n",
    "    return k, theta,theta_epsilon, f_epsilon, f\"max iteration '{maxiter}' is reached\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e022a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:46.988508Z",
     "start_time": "2023-07-25T02:26:46.978959Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, shared_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e50a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:26:48.005610Z",
     "start_time": "2023-07-25T02:26:47.989175Z"
    },
    "code_folding": [
     3,
     45
    ]
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, shared_memory\n",
    "\n",
    "@tf.function\n",
    "def grads(pinn, H):\n",
    "    def flatten(arr):\n",
    "        return tf.reshape(arr, (arr.shape[0]*arr.shape[1]*arr.shape[2], arr.shape[3]))\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:        \n",
    "        H = flatten(H)\n",
    "        tape.watch(H)\n",
    "        \n",
    "        outputs = pinn.net(H)\n",
    "        Ag = tf.squeeze(outputs[:, 0])\n",
    "        Bg = tf.squeeze(outputs[:, 1])\n",
    "        Cg = tf.squeeze(outputs[:, 2])\n",
    "        \n",
    "\n",
    "        grad_A = tape.gradient(Ag, H)\n",
    "        A_x = grad_A[:, 0]\n",
    "        A_y = grad_A[:, 1]\n",
    "        A_t = grad_A[:, 2]\n",
    "\n",
    "        grad_B = tape.gradient(Bg, H)\n",
    "        B_x = grad_B[:, 0]\n",
    "        B_y = grad_B[:, 1]\n",
    "        B_t = grad_B[:, 2]\n",
    "\n",
    "\n",
    "        grad_A_x = tape.gradient(A_x, H)\n",
    "        A_xx = grad_A_x[:, 0]\n",
    "        grad_A_y = tape.gradient(A_y, H)\n",
    "        A_yy = grad_A_y[:, 1]\n",
    "        grad_B_x = tape.gradient(B_x, H)\n",
    "        B_xx = grad_B_x[:, 0]\n",
    "        grad_B_y = tape.gradient(B_y, H)\n",
    "        B_yy = grad_B_y[:, 1]\n",
    "        \n",
    "        \n",
    "    return (tf.squeeze(Ag), tf.squeeze(A_xx), tf.squeeze(A_yy), tf.squeeze(A_t),\n",
    "            tf.squeeze(Bg), tf.squeeze(B_xx), tf.squeeze(B_yy), tf.squeeze(B_t),\n",
    "            tf.squeeze(Cg)\n",
    "           )                               \n",
    "\n",
    "class _LocalFunctions:\n",
    "    @classmethod\n",
    "    def add_functions(cls, *args):\n",
    "        for function in args:\n",
    "            setattr(cls, function.__name__, function)\n",
    "            function.__qualname__ = cls.__qualname__ + '.' + function.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa4edbdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:27:15.580049Z",
     "start_time": "2023-07-25T02:27:15.573423Z"
    }
   },
   "outputs": [],
   "source": [
    "pool_num = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2c588d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:27:17.905762Z",
     "start_time": "2023-07-25T02:27:16.855904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta theta A: 4e-06\n",
      "delta theta A: 250000.0\n",
      "\n",
      "delta theta B: 4e-06\n",
      "delta theta B: 250000.0\n",
      "\n",
      "delta theta C: 4.444444444444445e-07\n",
      "delta theta C: 2250000.0\n",
      "A epochs: 25.0\n",
      "B epochs: 25.0\n",
      "C epochs: 225.0\n"
     ]
    }
   ],
   "source": [
    "bounds_A = [(0,10), (0,30), (0,200), (0,30), (0,30)]\n",
    "bounds_B = [(0,10), (0,30), (0,200), (0,30), (0,30)]\n",
    "bounds_C = [(0,30), (0,200), (0,30), (0,30), (0,30)]\n",
    "epsilon = 2e-4#1e-3#1e-5\n",
    "l1 = 1\n",
    "\n",
    "alpha_A, alphas_A, l2_A, h_list2_A, theta_max2_A = alienor_components2(epsilon, l1, bounds_A)\n",
    "alpha_B, alphas_B, l2_B, h_list2_B, theta_max2_B = alienor_components2(epsilon, l1, bounds_B)\n",
    "alpha_C, alphas_C, l2_C, h_list2_C, theta_max2_C = alienor_components2(epsilon, l1, bounds_C)\n",
    "L_A = l1*l2_A\n",
    "L_B = l1*l2_B\n",
    "L_C = l1*l2_C\n",
    "print(\"delta theta A:\", epsilon/L_A)\n",
    "print(\"delta theta A:\", L_A/epsilon)\n",
    "print()\n",
    "print(\"delta theta B:\", epsilon/L_B)\n",
    "print(\"delta theta B:\", L_B/epsilon)\n",
    "print()\n",
    "print(\"delta theta C:\", epsilon/L_C)\n",
    "print(\"delta theta C:\", L_C/epsilon)\n",
    "\n",
    "batch_size = 10000\n",
    "print(\"A epochs:\", L_A/epsilon/batch_size)\n",
    "print(\"B epochs:\", L_B/epsilon/batch_size)\n",
    "print(\"C epochs:\", L_C/epsilon/batch_size)\n",
    "\n",
    "thetas_A = np.linspace(0, theta_max2_A,  int(L_A/epsilon))\n",
    "thetas_B = np.linspace(0, theta_max2_B,  int(L_B/epsilon))\n",
    "thetas_C = np.linspace(0, theta_max2_C,  int(L_C/epsilon))\n",
    "\n",
    "params_by_theta_A = np.stack([h_list2_A[0](thetas_A), h_list2_A[1](thetas_A),\n",
    "                              h_list2_A[2](thetas_A), h_list2_A[3](thetas_A),\n",
    "                              h_list2_A[4](thetas_A)]).T\n",
    "\n",
    "params_by_theta_B = np.stack([h_list2_B[0](thetas_B), h_list2_B[1](thetas_B),\n",
    "                              h_list2_B[2](thetas_B), h_list2_B[3](thetas_B),\n",
    "                              h_list2_B[4](thetas_B)]).T\n",
    "\n",
    "params_by_theta_C = np.stack([h_list2_C[0](thetas_C), h_list2_C[1](thetas_C),\n",
    "                              h_list2_C[2](thetas_C), h_list2_C[3](thetas_C),\n",
    "                              h_list2_C[4](thetas_C)]).T\n",
    "\n",
    "theta_A_n = params_by_theta_A.shape[0]\n",
    "theta_A_m = params_by_theta_A.shape[1]\n",
    "theta_B_n = params_by_theta_B.shape[0]\n",
    "theta_B_m = params_by_theta_B.shape[1]\n",
    "theta_C_n = params_by_theta_C.shape[0]\n",
    "theta_C_m = params_by_theta_C.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd597c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T02:30:39.300712Z",
     "start_time": "2023-07-25T02:30:39.236998Z"
    },
    "code_folding": [
     15,
     19,
     26,
     71,
     94,
     117,
     140,
     156,
     323,
     376
    ]
   },
   "outputs": [],
   "source": [
    "def to(arr):\n",
    "    return arr.reshape(128, 128) \n",
    "\n",
    "def reshape(arr, steps=1):\n",
    "    T = arr.shape[0]\n",
    "    ret = np.array([\n",
    "        [to(arr[i, 0, :]), to(arr[i, 1, :]), to(arr[i, 2, :])]\n",
    "        for i in range(T-steps, T)\n",
    "    ])\n",
    "    return np.einsum(\"tcxy -> cxyt\", ret)\n",
    "\n",
    "def rmse(arr1, arr2):\n",
    "    return np.sqrt(np.mean((arr1-arr2)**2))\n",
    "\n",
    "\n",
    "def G(sigma, x, y):\n",
    "    gaussian = (1/(2*np.pi*sigma**2))*np.exp(-(x**2+y**2)/(2*sigma**2))\n",
    "    return gaussian\n",
    "\n",
    "def G_discrete(sigma, n):\n",
    "    l = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            l[i,j] = G(sigma, (i-(n-1)/2),(j-(n-1)/2))\n",
    "    return l\n",
    "\n",
    "def G_discrete_normalise(sigma, n):\n",
    "    l = G_discrete(sigma, n)\n",
    "    return l/np.sum(l)\n",
    "\n",
    "def search_for_params(index, \n",
    "                      pinn,\n",
    "                      A_max, A_min,\n",
    "                      B_max, B_min,\n",
    "                      C_max, C_min,\n",
    "                      n_max = 20,\n",
    "                      slice_min = 45, \n",
    "                      slice_max = 100,):\n",
    "    print(\"=\"*40)\n",
    "    path = subnet_df[\"path\"].iloc[index]\n",
    "    print(index, path)\n",
    "    (params, res_1, k_max) = load_dataset(path)\n",
    "\n",
    "    n_val = params[\"n\"]\n",
    "    mu_A_val, mu_B_val, mu_C_val = params[\"mu_A\"], params[\"mu_B\"], params[\"mu_C\"]\n",
    "    \n",
    "\n",
    "    def Create_f_A(A, B, C, n, mu_A, A_diffu=None):\n",
    "        def act(x, km, n=4):\n",
    "            return 1 / (1 + (km / (x + 1e-20)) ** (n))\n",
    "\n",
    "        def inh(x, km, n=4):\n",
    "            return 1 / (1 + (x / (km + 1e-20)) ** (n))\n",
    "        A_flat = A#.flatten()[np.newaxis, :]\n",
    "        B_flat = B#.flatten()[np.newaxis, :]           \n",
    "        #A_diffu =  0.01* diffu_2D(A).flatten()[np.newaxis, :]\n",
    "        if A_diffu is None:\n",
    "            dxdy = (10*10)/((A.shape[0]-1)*(A.shape[1]-1))\n",
    "            A_diffu = ((1.0/dxdy)*(diffusion((A.shape[0],A.shape[1]),A))).flatten()[np.newaxis, :]\n",
    "\n",
    "        def L_2_f_a(args):\n",
    "            (D_A, b_A, V_A,  K_AA, K_BA\n",
    "            ) = (args[:, 0:1], args[:, 1:2], args[:, 2:3], args[:, 3:4], args[:, 4:5])\n",
    "            f1 = (b_A + V_A*act(A_flat, K_AA, n)*inh(B_flat, K_BA, n) - mu_A*A_flat \n",
    "                  + D_A*A_diffu)\n",
    "            f2 = (b_A/(D_A+1e-6) + V_A*act(A_flat, K_AA, n)*inh(B_flat, K_BA, n)/(D_A+1e-6) \n",
    "                  - mu_A*A_flat/(D_A+1e-6) + A_diffu)\n",
    "\n",
    "            return np.sum((f1**2 + f2**2 )/A_flat.size, axis=1)\n",
    "        return L_2_f_a\n",
    "\n",
    "    def Create_f_A_1_D(A, B, C, n, mu_A, A_diffu=None):\n",
    "        def act(x, km, n=4):\n",
    "            return 1 / (1 + (km / (x + 1e-20)) ** (n))\n",
    "\n",
    "        def inh(x, km, n=4):\n",
    "            return 1 / (1 + (x / (km + 1e-20)) ** (n))\n",
    "        A_flat = A#.flatten()[np.newaxis, :]\n",
    "        B_flat = B#.flatten()[np.newaxis, :]    \n",
    "        #A_diffu =  0.01* diffu_2D(A).flatten()[np.newaxis, :]\n",
    "        if A_diffu is None:\n",
    "            dxdy = (10*10)/((A.shape[0]-1)*(A.shape[1]-1))\n",
    "            A_diffu = ((1.0/dxdy)*(diffusion((A.shape[0],A.shape[1]),A))).flatten()[np.newaxis, :]\n",
    "        def L_2_f_a(args):        \n",
    "            (D_A, b_A,V_A, K_AA, K_BA\n",
    "            ) = (args[0], args[1], args[2], args[3], args[4])\n",
    "            f1 = (b_A + V_A*act(A_flat, K_AA, n)*inh(B_flat, K_BA, n) - mu_A*A_flat \n",
    "                  + D_A*A_diffu)\n",
    "            f2 = (b_A/(D_A+1e-6) + V_A*act(A_flat, K_AA, n)*inh(B_flat, K_BA, n)/(D_A+1e-6) \n",
    "                  - mu_A*A_flat/(D_A+1e-6) + A_diffu)\n",
    "\n",
    "            return np.sum((f1**2 + f2**2 )/A_flat.size, axis=1)\n",
    "        return L_2_f_a\n",
    "\n",
    "    def Create_f_B(A, B, C, n, mu_B, B_diffu=None):\n",
    "        def act(x, km, n=4):\n",
    "            return 1 / (1 + (km / (x + 1e-20)) ** (n))\n",
    "\n",
    "        def inh(x, km, n=4):\n",
    "            return 1 / (1 + (x / (km + 1e-20)) ** (n))\n",
    "        A_flat = A#.flatten()[np.newaxis, :]\n",
    "        B_flat = B#.flatten()[np.newaxis, :]   \n",
    "        C_flat = C#.flatten()[np.newaxis, :]\n",
    "        #B_diffu =  1.0* diffu_2D(B).flatten()[np.newaxis, :]\n",
    "        if B_diffu is None:\n",
    "            dxdy = (10*10)/((B.shape[0]-1)*(B.shape[1]-1))\n",
    "            B_diffu = ((1.0/dxdy)*(diffusion((B.shape[0],B.shape[1]),B))).flatten()[np.newaxis, :]    \n",
    "        def L_2_f_b(args):\n",
    "            (D_B, b_B, V_B, K_AB, K_CB\n",
    "            ) = (args[:, 0:1], args[:, 1:2], args[:, 2:3], args[:, 3:4], args[:, 4:5])\n",
    "            f1 = (b_B + V_B*act(A_flat, K_AB, n)*inh(C_flat, K_CB, n) - mu_B*B_flat \n",
    "                 + D_B*B_diffu)\n",
    "            f2 = (b_B/(D_B + 1e-6) + V_B*act(A_flat, K_AB, n)*inh(C_flat, K_CB, n)/(D_B + 1e-6)\n",
    "                  - mu_B*B_flat/(D_B + 1e-6)  + B_diffu)\n",
    "            return np.sum((f1**2 + f2**2 )/B_flat.size, axis=1)\n",
    "        return L_2_f_b\n",
    "\n",
    "    def Create_f_B_1_D(A, B, C, n, mu_B, B_diffu=None):\n",
    "        def act(x, km, n=4):\n",
    "            return 1 / (1 + (km / (x + 1e-20)) ** (n))\n",
    "\n",
    "        def inh(x, km, n=4):\n",
    "            return 1 / (1 + (x / (km + 1e-20)) ** (n))\n",
    "        A_flat = A#.flatten()[np.newaxis, :]\n",
    "        B_flat = B#.flatten()[np.newaxis, :]   \n",
    "        C_flat = C#.flatten()[np.newaxis, :]\n",
    "        #B_diffu =  1.0* diffu_2D(B).flatten()[np.newaxis, :]\n",
    "        if B_diffu is None:\n",
    "            dxdy = (10*10)/((B.shape[0]-1)*(B.shape[1]-1))\n",
    "            B_diffu = ((1.0/dxdy)*(diffusion((B.shape[0],B.shape[1]),B))).flatten()[np.newaxis, :]\n",
    "        def L_2_f_b(args):        \n",
    "            (D_B, b_B, V_B,K_AB, K_CB\n",
    "            )  = (args[0], args[1], args[2], args[3], args[4])\n",
    "            f1 = (b_B + V_B*act(A_flat, K_AB, n)*inh(C_flat, K_CB, n) - mu_B*B_flat \n",
    "                 + D_B*B_diffu)\n",
    "            f2 = (b_B/(D_B + 1e-6) + V_B*act(A_flat, K_AB, n)*inh(C_flat, K_CB, n)/(D_B + 1e-6)\n",
    "                  - mu_B*B_flat/(D_B + 1e-6)  + B_diffu)\n",
    "            return np.sum((f1**2 + f2**2 )/B_flat.size, axis=1)\n",
    "        return L_2_f_b\n",
    "\n",
    "    def Create_f_C(A, B, C, n, mu_C):\n",
    "        def act(x, km, n=4):\n",
    "            return 1 / (1 + (km / (x + 1e-20)) ** (n))\n",
    "\n",
    "        def inh(x, km, n=4):\n",
    "            return 1 / (1 + (x / (km + 1e-20)) ** (n))\n",
    "        A_flat = A#.flatten()[np.newaxis, :]\n",
    "        B_flat = B#.flatten()[np.newaxis, :]   \n",
    "        C_flat = C#.flatten()[np.newaxis, :]\n",
    "        def L_2_f_c(args):\n",
    "            b_C, V_C, K_AC, K_BC, K_CC = args[:, 0:1], args[:, 1:2], args[:, 2:3], args[:, 3:4], args[:, 4:5]\n",
    "            #b_C, V_C, K_AC, K_BC, K_CC = args[0], args[1], args[2], args[3], args[4]\n",
    "            f = b_C + V_C*inh(A_flat, K_AC, n)*inh(B_flat, K_BC, n)*act(C_flat, K_CC, n) - mu_C * C_flat\n",
    "            return np.sum(f**2, axis=1)\n",
    "        return L_2_f_c\n",
    "\n",
    "    def Create_f_C_1_D(A, B, C, n, mu_C):\n",
    "        def act(x, km, n=4):\n",
    "            return 1 / (1 + (km / (x + 1e-20)) ** (n))\n",
    "\n",
    "        def inh(x, km, n=4):\n",
    "            return 1 / (1 + (x / (km + 1e-20)) ** (n))\n",
    "        A_flat = A#.flatten()[np.newaxis, :]\n",
    "        B_flat = B#.flatten()[np.newaxis, :]   \n",
    "        C_flat = C#.flatten()[np.newaxis, :]\n",
    "        def L_2_f_c(args):        \n",
    "            b_C, V_C, K_AC, K_BC, K_CC = args[0], args[1], args[2], args[3], args[4]\n",
    "            f = b_C + V_C*inh(A_flat, K_AC, n)*inh(B_flat, K_BC, n)*act(C_flat, K_CC, n) - mu_C * C_flat\n",
    "            return np.sum(f**2)\n",
    "        return L_2_f_c\n",
    "    ####################################################\n",
    "    def flatten(arr):\n",
    "        return tf.reshape(arr, (arr.shape[0]*arr.shape[1]*arr.shape[2], arr.shape[3]))   \n",
    "    ####################################################\n",
    "    T=1    \n",
    "    L=1\n",
    "    data = reshape(res_1, T)\n",
    "    nodes_n = data.shape[0]\n",
    "    node_names = [\"A\", \"B\", \"C\"]\n",
    "    x_size = data.shape[1]\n",
    "    y_size = data.shape[2]\n",
    "    ##########################################\n",
    "    # Create a mesh that is the centers of the\n",
    "    # original mesh\n",
    "    x_size -= 1\n",
    "    y_size -= 1\n",
    "    dxdy = (10 - 10/127)**2/((x_size-1)*(y_size-1))\n",
    "    ##########################\n",
    "    N = x_size*y_size    \n",
    "    t_star = np.arange(T, T+1)\n",
    "    ##########################\n",
    "    x_slice = slice(slice_min, slice_max, 1)\n",
    "    y_slice = slice(slice_min, slice_max, 1)\n",
    "\n",
    "    x_range = L * np.linspace(0, x_size, x_size+1)[x_slice]\n",
    "    y_range = L * np.linspace(0, y_size, y_size+1)[y_slice]\n",
    "\n",
    "    block_x = x_range.shape[0]\n",
    "    block_y = y_range.shape[0]\n",
    "\n",
    "    x = tf.constant(x_range, dtype=tf.float32)\n",
    "    y = tf.constant(y_range, dtype=tf.float32)\n",
    "    # The order of the Y and X must be reversed,\n",
    "    # since the chnages the value finds the derivatives\n",
    "    #Y, X = tf.meshgrid(x, y)\n",
    "\n",
    "    X, Y = tf.meshgrid(x, y)\n",
    "    ts = tf.constant(t_star, dtype=tf.float32)\n",
    "    T = ts[tf.newaxis, tf.newaxis, :] * tf.ones(X.shape)[:, :, tf.newaxis]\n",
    "    def H_cube(X, Y, T):\n",
    "        return tf.concat(\n",
    "                [\n",
    "                    tf.concat(\n",
    "                        [\n",
    "                            X[tf.newaxis, :, :, tf.newaxis],\n",
    "                            Y[tf.newaxis, :, :, tf.newaxis],\n",
    "                            T[:, :, i : i + 1][tf.newaxis, :, :, :],\n",
    "                        ],\n",
    "                        axis=3,\n",
    "                    )\n",
    "                    for i in range(T.shape[-1])\n",
    "                ],\n",
    "                axis=0,\n",
    "            )\n",
    "    H = H_cube(X, Y, T) \n",
    "    ##########################################\n",
    "    def to(arr):\n",
    "        return arr.numpy().reshape(block_x, block_y)\n",
    "    \n",
    "    (A, A_xx, A_yy, A_t,\n",
    "     B, B_xx, B_yy, B_t,\n",
    "     C, \n",
    "    ) = grads(pinn, H)\n",
    "    # Rmeomve the boundary effects due to convolutions, etc.\n",
    "    sub_slice = slice(2,-2,1)\n",
    "    A = to(A).copy()[sub_slice, sub_slice]\n",
    "    B = to(B).copy()[sub_slice, sub_slice]\n",
    "    C = to(C).copy()[sub_slice, sub_slice]\n",
    "    A_diff = to((A_xx + A_yy))[sub_slice, sub_slice]\n",
    "    B_diff = to((B_xx + B_yy))[sub_slice, sub_slice]\n",
    "    # Transform back to the original space\n",
    "    A = (((A+1)*(A_max-A_min))/2) + A_min\n",
    "    B = (((B+1)*(B_max-B_min))/2) + B_min\n",
    "    C = (((C+1)*(C_max-C_min))/2) + C_min\n",
    "    A_diff = A_diff*(A_max-A_min)/2\n",
    "    B_diff = B_diff*(B_max-B_min)/2\n",
    "    # Flatten the arrays\n",
    "    A = A.flatten()[np.newaxis, :]\n",
    "    B = B.flatten()[np.newaxis, :]\n",
    "    C = C.flatten()[np.newaxis, :]\n",
    "    A_diff = A_diff.flatten()[np.newaxis, :]/dxdy\n",
    "    B_diff = B_diff.flatten()[np.newaxis, :]/dxdy\n",
    "    #####################################################\n",
    "    f_a_loss = Create_f_A(A, B, C, 4, params[\"mu_A\"], A_diff)\n",
    "    f_a_loss_1_D = Create_f_A_1_D(A, B, C, 4, params[\"mu_A\"], A_diff)\n",
    "    f_b_loss = Create_f_B(A, B, C, 4, params[\"mu_B\"], B_diff)\n",
    "    f_b_loss_1_D = Create_f_B_1_D(A, B, C, 4, params[\"mu_B\"], B_diff)\n",
    "    f_c_loss = Create_f_C(A, B, C, 4, params[\"mu_C\"])\n",
    "    f_c_loss_1_D = Create_f_C_1_D(A, B, C, 4, params[\"mu_C\"])\n",
    "    #######################################################    \n",
    "    def singA(args):\n",
    "        batch_id,theta_n,theta_m= args \n",
    "        params_shm = shared_memory.SharedMemory(name=\"params_by_theta3\")\n",
    "        output_shm = shared_memory.SharedMemory(name=\"outputs3\")\n",
    "        thetas = np.ndarray((theta_n,theta_m), dtype=np.float64, buffer=params_shm.buf)\n",
    "        f_thetas = np.ndarray((theta_n), dtype=np.float64, buffer=output_shm.buf)\n",
    "        f_thetas[batch_id*batch_size:(batch_id+1)*batch_size] = f_a_loss(thetas[batch_id*batch_size:(batch_id+1)*batch_size, :])\n",
    "        return batch_id\n",
    "\n",
    "    def singB(args):\n",
    "        batch_id,theta_n,theta_m= args \n",
    "        params_shm = shared_memory.SharedMemory(name=\"params_by_theta3\")\n",
    "        output_shm = shared_memory.SharedMemory(name=\"outputs3\")\n",
    "        thetas = np.ndarray((theta_n,theta_m), dtype=np.float64, buffer=params_shm.buf)\n",
    "        f_thetas = np.ndarray((theta_n), dtype=np.float64, buffer=output_shm.buf)\n",
    "        f_thetas[batch_id*batch_size:(batch_id+1)*batch_size] = f_b_loss(thetas[batch_id*batch_size:(batch_id+1)*batch_size, :])\n",
    "        return batch_id\n",
    "\n",
    "    def singC(args):\n",
    "        batch_id,theta_n,theta_m= args \n",
    "        params_shm = shared_memory.SharedMemory(name=\"params_by_theta3\")\n",
    "        output_shm = shared_memory.SharedMemory(name=\"outputs3\")\n",
    "        thetas = np.ndarray((theta_n,theta_m), dtype=np.float64, buffer=params_shm.buf)\n",
    "        f_thetas = np.ndarray((theta_n), dtype=np.float64, buffer=output_shm.buf)\n",
    "        f_thetas[batch_id*batch_size:(batch_id+1)*batch_size] = f_c_loss(thetas[batch_id*batch_size:(batch_id+1)*batch_size, :])\n",
    "        return batch_id\n",
    "\n",
    "    _LocalFunctions.add_functions(singA, singB, singC)\n",
    "    \n",
    "    def run(theta_n,theta_m,params_by_theta, sing, L, epsilon, batch_size):\n",
    "        shm = shared_memory.SharedMemory(name=\"params_by_theta3\",\n",
    "                                         create=True, \n",
    "                                         size=params_by_theta.nbytes)\n",
    "        shared_thetas = np.ndarray((theta_n,theta_m), dtype=np.float64,\n",
    "                                    buffer=shm.buf)\n",
    "\n",
    "        shared_thetas[:,:] = params_by_theta[:,:]\n",
    "\n",
    "\n",
    "        f_thetas = np.zeros(theta_n)\n",
    "        shm_out = shared_memory.SharedMemory(name=\"outputs3\",create=True, size=f_thetas.nbytes)\n",
    "        shared_outputs = np.ndarray((theta_n), dtype=np.float64,\n",
    "                                     buffer=shm_out.buf)\n",
    "\n",
    "        \n",
    "        args =[ (batch_id, theta_n,theta_m) for batch_id in range(int(L/epsilon/batch_size) + 1)]\n",
    "\n",
    "        with Pool(55) as pool:\n",
    "            res = pool.map(sing, args)\n",
    "\n",
    "        f_thetas[:] = shared_outputs[:]\n",
    "        shm.close()\n",
    "        shm.unlink()\n",
    "\n",
    "        shm_out.close()\n",
    "        shm_out.unlink()\n",
    "\n",
    "        return f_thetas\n",
    "     \n",
    "    f_thetas_A = run(theta_A_n,theta_A_m,params_by_theta_A, singA, L_A, epsilon, batch_size)\n",
    "    f_thetas_B = run(theta_B_n,theta_B_m,params_by_theta_B, singB, L_B, epsilon, batch_size)\n",
    "    f_thetas_C = run(theta_C_n,theta_C_m,params_by_theta_C, singC, L_C, epsilon, batch_size)\n",
    "    ##########################################################\n",
    "    def minimise_top_n(n, h_list, bounds, loss_1_D, f_thetas, thetas):\n",
    "        shift = 0\n",
    "        init_params = np.zeros((n, len(h_list)))\n",
    "        final_params = np.zeros((n, len(h_list)))\n",
    "        init_loss = np.zeros(n)\n",
    "        final_loss = np.zeros(n)\n",
    "\n",
    "        top_n = np.argpartition(-f_thetas, -n)[-n:]\n",
    "        top_n = top_n[np.argsort(f_thetas[top_n])]\n",
    "\n",
    "        for shift in range(n):\n",
    "\n",
    "            theta_star = thetas[top_n][0 + shift]\n",
    "            init_par = tuple([h(theta_star) for h in h_list])\n",
    "            init_params[shift, :] = init_par\n",
    "            init_loss[shift] = f_thetas[top_n][0 + shift]\n",
    "            #bounds = ((0, 200), (0, 200), (0, 200), (0, 200), (0, 200))\n",
    "            res3= minimize(loss_1_D, x0=init_par, method='L-BFGS-B', bounds=bounds)#, options={'ftol':1e-10})\n",
    "            final_params[shift, :] = res3['x']\n",
    "            final_loss[shift] = res3['fun']\n",
    "\n",
    "        sorted_loss_ind = np.argsort(final_loss)\n",
    "        init_params = init_params[sorted_loss_ind.tolist()]\n",
    "        init_loss = init_loss[sorted_loss_ind.tolist()]\n",
    "        final_params = final_params[sorted_loss_ind.tolist()]\n",
    "        final_loss = final_loss[sorted_loss_ind.tolist()]\n",
    "\n",
    "        return (final_loss, final_params, init_loss, init_params )\n",
    "    \n",
    "    (final_loss_A, final_params_A, \n",
    "     init_loss_A, init_params_A) = minimise_top_n(n_max, h_list2_A, \n",
    "                                                  ((0, 100), (0, 500), (0, 500), (0, 500), (0, 500)), \n",
    "                                                  f_a_loss_1_D, f_thetas_A, thetas_A)\n",
    "\n",
    "    (final_loss_B, final_params_B, \n",
    "     init_loss_B, init_params_B) = minimise_top_n(n_max, h_list2_B, \n",
    "                                                  ((0, 100), (0, 500), (0, 500), (0, 500), (0, 500)), \n",
    "                                                  f_b_loss_1_D, f_thetas_B, thetas_B)\n",
    "\n",
    "    (final_loss_C, final_params_C, \n",
    "     init_loss_C, init_params_C) = minimise_top_n(n_max, h_list2_C, \n",
    "                                                  ((0, 500), (0, 500), (0, 500), (0, 500), (0, 500)), \n",
    "                                                  f_c_loss_1_D, f_thetas_C, thetas_C)\n",
    "    \n",
    "    return (path,\n",
    "            (final_loss_A, final_params_A, \n",
    "             init_loss_A, init_params_A),\n",
    "            (final_loss_B, final_params_B, \n",
    "             init_loss_B, init_params_B),\n",
    "            (final_loss_C, final_params_C, \n",
    "             init_loss_C, init_params_C)\n",
    "           )\n",
    "\n",
    "def single_simulation(args):\n",
    "    (iter_i, \n",
    "     (simulate_from_start,\n",
    "     i,\n",
    "     index, \n",
    "     run, \n",
    "     path, \n",
    "     (D_A_val, b_A_val, V_A_val,  K_AA_val,  K_BA_val), \n",
    "     (D_B_val, b_B_val, V_B_val,  K_AB_val,  K_CB_val), \n",
    "     (b_C_val, V_C_val,  K_AC_val,  K_BC_val, K_CC_val))) = args\n",
    "        \n",
    "    N=5000\n",
    "    T=100\n",
    "    delta_t = T/N\n",
    "    model_128_10 = RD_2D_1st_Order(Ds=[D_A_val, D_B_val, 0], \n",
    "                                   delta_t=delta_t, Lx=10, Ly=10, \n",
    "                                   Ix=128, Jy=128,\n",
    "                                   boundary_condition=Neumann_Boundary_2D)\n",
    "\n",
    "    \n",
    "    (params, res_1, _) = load_dataset(path)    \n",
    "    if simulate_from_start:\n",
    "        A_init = res_1[0, 0, :]\n",
    "        B_init = res_1[0, 1, :]\n",
    "        C_init = res_1[0, 2, :]\n",
    "    else:\n",
    "        A_init = res_1[-1, 0, :]\n",
    "        B_init = res_1[-1, 1, :]\n",
    "        C_init = res_1[-1, 2, :]\n",
    "    \n",
    "    n_val = params[\"n\"]\n",
    "    mu_A_val = params[\"mu_A\"]\n",
    "    mu_B_val = params[\"mu_B\"]\n",
    "    mu_C_val = params[\"mu_C\"]\n",
    "        \n",
    "    actual_params = np.array(list(params.values())[:2] + list(params.values())[3:])\n",
    "    estimated_params = np.array(\n",
    "        [D_A_val, D_B_val, b_A_val, mu_A_val, V_A_val, K_AA_val, K_AB_val,\n",
    "         K_AC_val, b_B_val, mu_B_val, V_B_val, K_BA_val,\n",
    "         K_BC_val, b_C_val, mu_C_val, V_C_val, K_CB_val, K_CC_val])\n",
    "    euclidian_dist = np.linalg.norm(actual_params-estimated_params)\n",
    "    c_dist = cos_dist(actual_params, estimated_params)\n",
    "    kinetics = create_circuit_3954(n_val, \n",
    "                                   b_A_val, mu_A_val, V_A_val, K_AA_val, K_AB_val, K_AC_val,\n",
    "                                   b_B_val, mu_B_val, V_B_val, K_BA_val, K_BC_val,\n",
    "                                   b_C_val, mu_C_val, V_C_val, K_CB_val, K_CC_val)  \n",
    "\n",
    "\n",
    "\n",
    "    if simulate_from_start:\n",
    "        res_2 = model_128_10.integrate([A_init,B_init,C_init], kinetics, 5000-1, 100)\n",
    "    else:\n",
    "        res_2 = model_128_10.integrate([A_init,B_init,C_init], kinetics, 5000, 100)\n",
    "        \n",
    "    del model_128_10\n",
    "    \n",
    "    with open(f\"./temp/res_{index}_{run}_{i}_{0 if simulate_from_start else 1}_high_resolution_diffusion.npy\", \"wb\") as f:\n",
    "        np.save(f, res_2)\n",
    "    \n",
    "    return (simulate_from_start,\n",
    "            i,\n",
    "            index, \n",
    "            run, \n",
    "            path,\n",
    "            (n_val, \n",
    "             D_A_val, D_B_val,\n",
    "             b_A_val, mu_A_val, V_A_val, K_AA_val, K_AB_val, K_AC_val,\n",
    "             b_B_val, mu_B_val, V_B_val, K_BA_val, K_BC_val,\n",
    "             b_C_val, mu_C_val, V_C_val, K_CB_val, K_CC_val),\n",
    "             euclidian_dist,\n",
    "             c_dist)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a628da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c40d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T14:06:51.280871Z",
     "start_time": "2023-07-25T02:30:54.154005Z"
    },
    "code_folding": [
     5
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp/res_0_no_noise\n",
      "A_min=1.2536166807, A_max=6.3400690906\n",
      "B_min=28.1674935307, B_max=35.5214285374\n",
      "C_min=2.0000581460, C_max=2.0004858235\n",
      "min_validation=0.0000025441\n",
      "========================================\n",
      "0 outputs_second_search/solution_10_0_24.npy\n",
      "WARNING:tensorflow:From /usr/local/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "./temp/res_0_1_percent_noise\n",
      "A_min=1.2691744211, A_max=6.3376066737\n",
      "B_min=28.1750442621, B_max=35.4757363218\n",
      "C_min=2.0000585778, C_max=2.0004847108\n",
      "min_validation=0.0001276450\n",
      "========================================\n",
      "0 outputs_second_search/solution_10_0_24.npy\n",
      "./temp/res_0_2_percent_noise\n",
      "A_min=1.2683928335, A_max=6.3522614666\n",
      "B_min=28.1585525209, B_max=35.4657437053\n",
      "C_min=2.0000570875, C_max=2.0004859457\n",
      "min_validation=0.0001412799\n",
      "========================================\n",
      "0 outputs_second_search/solution_10_0_24.npy\n",
      "./temp/res_0_5_percent_noise\n",
      "A_min=1.2493561557, A_max=6.3962258453\n",
      "B_min=28.1090772973, B_max=35.4969332522\n",
      "C_min=2.0000507837, C_max=2.0004896504\n",
      "min_validation=0.0002387842\n",
      "========================================\n",
      "0 outputs_second_search/solution_10_0_24.npy\n",
      "./temp/res_1_no_noise\n",
      "A_min=0.2967170619, A_max=7.8640956801\n",
      "B_min=5.1053132294, B_max=6.8926331505\n",
      "C_min=2.0088850561, C_max=2.1617852585\n",
      "min_validation=0.0000140976\n",
      "========================================\n",
      "1 outputs_second_search/solution_10_0_26.npy\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function grads at 0x7f7e38741ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "./temp/res_1_1_percent_noise\n",
      "A_min=0.2964689763, A_max=7.8354658846\n",
      "B_min=5.1049058523, B_max=6.8760462332\n",
      "C_min=2.0090971282, C_max=2.1620059394\n",
      "min_validation=0.0000882643\n",
      "========================================\n",
      "1 outputs_second_search/solution_10_0_26.npy\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function grads at 0x7f7e38741ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "./temp/res_1_2_percent_noise\n",
      "A_min=0.2868431033, A_max=7.8583803335\n",
      "B_min=5.1005471611, B_max=6.8809110121\n",
      "C_min=2.0089005838, C_max=2.1625610677\n",
      "min_validation=0.0000757988\n",
      "========================================\n",
      "1 outputs_second_search/solution_10_0_26.npy\n",
      "./temp/res_1_5_percent_noise\n",
      "A_min=0.2313391283, A_max=7.9271236802\n",
      "B_min=5.0874710875, B_max=6.8955053489\n",
      "C_min=2.0083109508, C_max=2.1645727650\n",
      "min_validation=0.0003170800\n",
      "========================================\n",
      "1 outputs_second_search/solution_10_0_26.npy\n",
      "./temp/res_2_no_noise\n",
      "A_min=0.6284966199, A_max=7.5934214258\n",
      "B_min=10.5524367856, B_max=13.9051865785\n",
      "C_min=2.0384983964, C_max=19.6884102528\n",
      "min_validation=0.0007502667\n",
      "========================================\n",
      "2 outputs_second_search/solution_10_0_27.npy\n",
      "./temp/res_2_1_percent_noise\n",
      "A_min=0.6307513717, A_max=7.5640054927\n",
      "B_min=10.5559445707, B_max=13.8991717066\n",
      "C_min=1.9836370496, C_max=19.6390319191\n",
      "min_validation=0.0001973017\n",
      "========================================\n",
      "2 outputs_second_search/solution_10_0_27.npy\n",
      "./temp/res_2_2_percent_noise\n",
      "A_min=0.6102636739, A_max=7.5831906709\n",
      "B_min=10.5517138849, B_max=13.9064411833\n",
      "C_min=1.8963309656, C_max=19.6192312865\n",
      "min_validation=0.0001992591\n",
      "========================================\n",
      "2 outputs_second_search/solution_10_0_27.npy\n",
      "./temp/res_2_5_percent_noise\n",
      "A_min=0.5273058741, A_max=7.6635115607\n",
      "B_min=10.5277120106, B_max=13.9282496133\n",
      "C_min=1.6217765944, C_max=19.7878513648\n",
      "min_validation=0.0004637918\n",
      "========================================\n",
      "2 outputs_second_search/solution_10_0_27.npy\n",
      "./temp/res_5_no_noise\n",
      "A_min=1.9825076523, A_max=5.6812312643\n",
      "B_min=29.5593772489, B_max=35.1606856551\n",
      "C_min=10.2961982281, C_max=10.4654168520\n",
      "min_validation=0.0000023748\n",
      "========================================\n",
      "5 outputs_second_search/solution_10_0_44.npy\n",
      "./temp/res_5_1_percent_noise\n",
      "A_min=1.9935291827, A_max=5.6774216789\n",
      "B_min=29.5898548919, B_max=35.1372171107\n",
      "C_min=10.2963184980, C_max=10.4644075094\n",
      "min_validation=0.0000613064\n",
      "========================================\n",
      "5 outputs_second_search/solution_10_0_44.npy\n",
      "./temp/res_5_2_percent_noise\n",
      "A_min=1.9868471672, A_max=5.6828770791\n",
      "B_min=29.5946589859, B_max=35.1354727837\n",
      "C_min=10.2959460342, C_max=10.4644451917\n",
      "min_validation=0.0000731048\n",
      "========================================\n",
      "5 outputs_second_search/solution_10_0_44.npy\n",
      "./temp/res_5_5_percent_noise\n",
      "A_min=1.9668011205, A_max=5.6992432798\n",
      "B_min=29.5816491591, B_max=35.1302398026\n",
      "C_min=10.2944802082, C_max=10.4650092331\n",
      "min_validation=0.0004712788\n",
      "========================================\n",
      "5 outputs_second_search/solution_10_0_44.npy\n",
      "./temp/res_9_no_noise\n",
      "A_min=0.5029088624, A_max=0.5572815358\n",
      "B_min=26.8112494632, B_max=26.9837825696\n",
      "C_min=0.2005421412, C_max=0.2005730950\n",
      "min_validation=0.0000255099\n",
      "========================================\n",
      "9 outputs_second_search/solution_10_0_6.npy\n",
      "./temp/res_9_1_percent_noise\n",
      "A_min=0.5030256071, A_max=0.5564016088\n",
      "B_min=26.8114383856, B_max=26.9826424417\n",
      "C_min=0.2005425162, C_max=0.2005731086\n",
      "min_validation=0.0000245828\n",
      "========================================\n",
      "9 outputs_second_search/solution_10_0_6.npy\n",
      "./temp/res_9_2_percent_noise\n",
      "A_min=0.5030215051, A_max=0.5564001581\n",
      "B_min=26.8111700121, B_max=26.9823798667\n",
      "C_min=0.2005424343, C_max=0.2005731882\n",
      "min_validation=0.0001087737\n",
      "========================================\n",
      "9 outputs_second_search/solution_10_0_6.npy\n",
      "./temp/res_9_5_percent_noise\n",
      "A_min=0.5030091988, A_max=0.5563958062\n",
      "B_min=26.8103648916, B_max=26.9828146734\n",
      "C_min=0.2005421887, C_max=0.2005734271\n",
      "min_validation=0.0005357623\n",
      "========================================\n",
      "9 outputs_second_search/solution_10_0_6.npy\n",
      "./temp/res_10_no_noise\n",
      "A_min=0.2929634737, A_max=7.2074082342\n",
      "B_min=7.1070814178, B_max=10.7187385485\n",
      "C_min=2.0126402499, C_max=2.0723484757\n",
      "min_validation=0.0007560249\n",
      "========================================\n",
      "10 outputs_second_search/solution_10_10_103.npy\n",
      "./temp/res_10_1_percent_noise\n",
      "A_min=0.3532475683, A_max=7.1399904673\n",
      "B_min=7.1604510859, B_max=10.6737563452\n",
      "C_min=2.0125654059, C_max=2.0699331188\n",
      "min_validation=0.0004891436\n",
      "========================================\n",
      "10 outputs_second_search/solution_10_10_103.npy\n",
      "./temp/res_10_2_percent_noise\n",
      "A_min=0.3593825680, A_max=7.1514985844\n",
      "B_min=7.1494263618, B_max=10.6686696314\n",
      "C_min=2.0123267129, C_max=2.0698455505\n",
      "min_validation=0.0002074672\n",
      "========================================\n",
      "10 outputs_second_search/solution_10_10_103.npy\n",
      "./temp/res_10_5_percent_noise\n",
      "A_min=0.3777875670, A_max=7.2281225170\n",
      "B_min=7.1163521895, B_max=10.6673944997\n",
      "C_min=2.0116106340, C_max=2.0695828456\n",
      "min_validation=0.0004226958\n",
      "========================================\n",
      "10 outputs_second_search/solution_10_10_103.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp/res_12_no_noise\n",
      "A_min=0.2404987008, A_max=7.4204162638\n",
      "B_min=6.8952767527, B_max=10.6157212793\n",
      "C_min=2.0047268408, C_max=2.1407829887\n",
      "min_validation=0.0006928497\n",
      "========================================\n",
      "12 outputs_second_search/solution_10_10_106.npy\n",
      "./temp/res_12_1_percent_noise\n",
      "A_min=0.2760125962, A_max=7.3600902781\n",
      "B_min=6.9577019126, B_max=10.5723264707\n",
      "C_min=2.0045140692, C_max=2.1358223138\n",
      "min_validation=0.0006758085\n",
      "========================================\n",
      "12 outputs_second_search/solution_10_10_106.npy\n",
      "./temp/res_12_2_percent_noise\n",
      "A_min=0.2483731234, A_max=7.3673408296\n",
      "B_min=6.9593224903, B_max=10.5729304304\n",
      "C_min=2.0039909590, C_max=2.1357638986\n",
      "min_validation=0.0002785452\n",
      "========================================\n",
      "12 outputs_second_search/solution_10_10_106.npy\n",
      "./temp/res_12_5_percent_noise\n",
      "A_min=0.1654547050, A_max=7.3917385681\n",
      "B_min=6.9597864375, B_max=10.5747423093\n",
      "C_min=2.0023592419, C_max=2.1362038851\n",
      "min_validation=0.0008735233\n",
      "========================================\n",
      "12 outputs_second_search/solution_10_10_106.npy\n",
      "./temp/res_21_no_noise\n",
      "A_min=0.0450001654, A_max=0.6490631991\n",
      "B_min=1.6157334404, B_max=2.1248533572\n",
      "C_min=0.4020736777, C_max=0.4068234556\n",
      "min_validation=0.0038545310\n",
      "========================================\n",
      "21 outputs_second_search/solution_10_10_2.npy\n",
      "./temp/res_21_1_percent_noise\n",
      "A_min=0.0507991032, A_max=0.6272576091\n",
      "B_min=1.6193965933, B_max=2.1103344590\n",
      "C_min=0.4021323176, C_max=0.4067362776\n",
      "min_validation=0.0007853181\n",
      "========================================\n",
      "21 outputs_second_search/solution_10_10_2.npy\n",
      "./temp/res_21_2_percent_noise\n",
      "A_min=0.0508887850, A_max=0.6273209583\n",
      "B_min=1.6176232572, B_max=2.1096366685\n",
      "C_min=0.4021304063, C_max=0.4067325861\n",
      "min_validation=0.0006342983\n",
      "========================================\n",
      "21 outputs_second_search/solution_10_10_2.npy\n",
      "./temp/res_21_5_percent_noise\n",
      "A_min=0.0466925652, A_max=0.6292356654\n",
      "B_min=1.6123032488, B_max=2.1116491402\n",
      "C_min=0.4021238604, C_max=0.4067427746\n",
      "min_validation=0.0009584028\n",
      "========================================\n",
      "21 outputs_second_search/solution_10_10_2.npy\n",
      "./temp/res_23_no_noise\n",
      "A_min=0.0484724173, A_max=8.5984056961\n",
      "B_min=8.2977969680, B_max=10.5561876652\n",
      "C_min=2.0557266085, C_max=29.0625973616\n",
      "min_validation=0.0022229897\n",
      "========================================\n",
      "23 outputs_second_search/solution_10_10_84.npy\n",
      "./temp/res_23_1_percent_noise\n",
      "A_min=0.0304723806, A_max=8.5444162083\n",
      "B_min=8.3187438533, B_max=10.5448540956\n",
      "C_min=1.9236650531, C_max=29.1486394824\n",
      "min_validation=0.0001826949\n",
      "========================================\n",
      "23 outputs_second_search/solution_10_10_84.npy\n",
      "./temp/res_23_2_percent_noise\n",
      "A_min=-0.0035697411, A_max=8.5341965882\n",
      "B_min=8.3132577419, B_max=10.5440797969\n",
      "C_min=1.7833756549, C_max=29.3454203807\n",
      "min_validation=0.0002923634\n",
      "========================================\n",
      "23 outputs_second_search/solution_10_10_84.npy\n",
      "./temp/res_23_5_percent_noise\n",
      "A_min=-0.1056961063, A_max=8.6148471840\n",
      "B_min=8.2967994075, B_max=10.5541730429\n",
      "C_min=1.3625074600, C_max=29.9357630758\n",
      "min_validation=0.0010017322\n",
      "========================================\n",
      "23 outputs_second_search/solution_10_10_84.npy\n",
      "./temp/res_29_no_noise\n",
      "A_min=0.0763052873, A_max=1.6141719482\n",
      "B_min=1.9772656657, B_max=2.6104886039\n",
      "C_min=0.2000006381, C_max=0.2002042629\n",
      "min_validation=0.0128147951\n",
      "========================================\n",
      "29 outputs_second_search/solution_10_11_26.npy\n",
      "./temp/res_29_1_percent_noise\n",
      "A_min=0.0932387335, A_max=1.5584105106\n",
      "B_min=1.9936651112, B_max=2.5878910977\n",
      "C_min=0.2000000296, C_max=0.2001973773\n",
      "min_validation=0.0017795494\n",
      "========================================\n",
      "29 outputs_second_search/solution_10_11_26.npy\n",
      "./temp/res_29_2_percent_noise\n",
      "A_min=0.0963677174, A_max=1.5602902722\n",
      "B_min=1.9940308383, B_max=2.5872394394\n",
      "C_min=0.1999991198, C_max=0.2001969466\n",
      "min_validation=0.0009154654\n",
      "========================================\n",
      "29 outputs_second_search/solution_10_11_26.npy\n",
      "./temp/res_29_5_percent_noise\n",
      "A_min=0.0929814194, A_max=1.5735618602\n",
      "B_min=1.9939148501, B_max=2.5874289935\n",
      "C_min=0.1999963903, C_max=0.2001956543\n",
      "min_validation=0.0077944043\n",
      "========================================\n",
      "29 outputs_second_search/solution_10_11_26.npy\n",
      "./temp/res_37_no_noise\n",
      "A_min=0.0994217533, A_max=1.4386881937\n",
      "B_min=8.3288100580, B_max=12.8531256288\n",
      "C_min=2.0056142145, C_max=2.0304933986\n",
      "min_validation=0.0000261771\n",
      "========================================\n",
      "37 outputs_second_search/solution_10_3_64.npy\n",
      "./temp/res_37_1_percent_noise\n",
      "A_min=0.1039040974, A_max=1.4308392717\n",
      "B_min=8.3491042097, B_max=12.8294709314\n",
      "C_min=2.0055844804, C_max=2.0301773654\n",
      "min_validation=0.0000250074\n",
      "========================================\n",
      "37 outputs_second_search/solution_10_3_64.npy\n",
      "./temp/res_37_2_percent_noise\n",
      "A_min=0.1023337440, A_max=1.4303035273\n",
      "B_min=8.3478026428, B_max=12.8269489128\n",
      "C_min=2.0055089229, C_max=2.0301544661\n",
      "min_validation=0.0000967772\n",
      "========================================\n",
      "37 outputs_second_search/solution_10_3_64.npy\n",
      "./temp/res_37_5_percent_noise\n",
      "A_min=0.0857070957, A_max=1.4371916775\n",
      "B_min=8.3438979422, B_max=12.8312226045\n",
      "C_min=2.0052822505, C_max=2.0300857683\n",
      "min_validation=0.0003858943\n",
      "========================================\n",
      "37 outputs_second_search/solution_10_3_64.npy\n",
      "./temp/res_38_no_noise\n",
      "A_min=0.0831491517, A_max=1.3895065937\n",
      "B_min=7.9480421721, B_max=13.1907743490\n",
      "C_min=2.8647744651, C_max=36.1776535723\n",
      "min_validation=0.0000459278\n",
      "========================================\n",
      "38 outputs_second_search/solution_10_3_77.npy\n",
      "./temp/res_38_1_percent_noise\n",
      "A_min=0.0833790339, A_max=1.3847068026\n",
      "B_min=7.9492141868, B_max=13.1701473826\n",
      "C_min=2.9173313754, C_max=36.1585063063\n",
      "min_validation=0.0000814734\n",
      "========================================\n",
      "38 outputs_second_search/solution_10_3_77.npy\n",
      "./temp/res_38_2_percent_noise\n",
      "A_min=0.0815402520, A_max=1.3851770888\n",
      "B_min=7.9356372746, B_max=13.1703371966\n",
      "C_min=2.8622154331, C_max=36.2602413710\n",
      "min_validation=0.0000717636\n",
      "========================================\n",
      "38 outputs_second_search/solution_10_3_77.npy\n",
      "./temp/res_38_5_percent_noise\n",
      "A_min=0.0749490664, A_max=1.3920886076\n",
      "B_min=7.8949065379, B_max=13.2071450076\n",
      "C_min=2.6806179311, C_max=36.5770608850\n",
      "min_validation=0.0002312760\n",
      "========================================\n",
      "38 outputs_second_search/solution_10_3_77.npy\n",
      "./temp/res_39_no_noise\n",
      "A_min=0.0761619928, A_max=1.6104933535\n",
      "B_min=19.3640827058, B_max=26.6022848931\n",
      "C_min=0.2000053869, C_max=0.2001431866\n",
      "min_validation=0.0000052753\n",
      "========================================\n",
      "39 outputs_second_search/solution_10_3_80.npy\n",
      "./temp/res_39_1_percent_noise\n",
      "A_min=0.0773289802, A_max=1.6038261414\n",
      "B_min=19.3624708396, B_max=26.5360633022\n",
      "C_min=0.2000054188, C_max=0.2001426426\n",
      "min_validation=0.0000293224\n",
      "========================================\n",
      "39 outputs_second_search/solution_10_3_80.npy\n",
      "./temp/res_39_2_percent_noise\n",
      "A_min=0.0758806628, A_max=1.6065442313\n",
      "B_min=19.3430763837, B_max=26.5502259093\n",
      "C_min=0.2000051471, C_max=0.2001426881\n",
      "min_validation=0.0002623167\n",
      "========================================\n",
      "39 outputs_second_search/solution_10_3_80.npy\n",
      "./temp/res_39_5_percent_noise\n",
      "A_min=0.0609945087, A_max=1.6161981555\n",
      "B_min=19.2848930161, B_max=26.5927708179\n",
      "C_min=0.2000041526, C_max=0.2001434852\n",
      "min_validation=0.0003051678\n",
      "========================================\n",
      "39 outputs_second_search/solution_10_3_80.npy\n",
      "./temp/res_40_no_noise\n",
      "A_min=0.1194315726, A_max=1.6207156060\n",
      "B_min=10.4517748219, B_max=13.5891290017\n",
      "C_min=2.0044977526, C_max=2.0127479262\n",
      "min_validation=0.0000031106\n",
      "========================================\n",
      "40 outputs_second_search/solution_10_3_92.npy\n",
      "./temp/res_40_1_percent_noise\n",
      "A_min=0.1179412012, A_max=1.6162020955\n",
      "B_min=10.4590849873, B_max=13.5635546162\n",
      "C_min=2.0045244670, C_max=2.0126715818\n",
      "min_validation=0.0000788191\n",
      "========================================\n",
      "40 outputs_second_search/solution_10_3_92.npy\n",
      "./temp/res_40_2_percent_noise\n",
      "A_min=0.1116638554, A_max=1.6152465906\n",
      "B_min=10.4539365304, B_max=13.5588852095\n",
      "C_min=2.0045208344, C_max=2.0126540118\n",
      "min_validation=0.0000767568\n",
      "========================================\n",
      "40 outputs_second_search/solution_10_3_92.npy\n",
      "./temp/res_40_5_percent_noise\n",
      "A_min=0.0925416033, A_max=1.6182845207\n",
      "B_min=10.4384911596, B_max=13.5600644524\n",
      "C_min=2.0044950638, C_max=2.0126386903\n",
      "min_validation=0.0003925364\n",
      "========================================\n",
      "40 outputs_second_search/solution_10_3_92.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp/res_44_no_noise\n",
      "A_min=0.0904517381, A_max=9.1282162414\n",
      "B_min=14.7490119213, B_max=20.8363636789\n",
      "C_min=2.0051448842, C_max=2.2960615786\n",
      "min_validation=0.0000365830\n",
      "========================================\n",
      "44 outputs_second_search/solution_10_8_140.npy\n",
      "./temp/res_44_1_percent_noise\n",
      "A_min=0.1036461638, A_max=9.0873889174\n",
      "B_min=14.7630551225, B_max=20.8163388049\n",
      "C_min=2.0048676169, C_max=2.2921263811\n",
      "min_validation=0.0000363943\n",
      "========================================\n",
      "44 outputs_second_search/solution_10_8_140.npy\n",
      "./temp/res_44_2_percent_noise\n",
      "A_min=0.0963454523, A_max=9.0779412729\n",
      "B_min=14.7503843965, B_max=20.8220008982\n",
      "C_min=2.0042515229, C_max=2.2921232053\n",
      "min_validation=0.0000625903\n",
      "========================================\n",
      "44 outputs_second_search/solution_10_8_140.npy\n",
      "./temp/res_44_5_percent_noise\n",
      "A_min=0.0086126863, A_max=9.0608843166\n",
      "B_min=14.7123722183, B_max=20.8475418820\n",
      "C_min=2.0010219839, C_max=2.2924222540\n",
      "min_validation=0.0003611558\n",
      "========================================\n",
      "44 outputs_second_search/solution_10_8_140.npy\n",
      "./temp/res_56_no_noise\n",
      "A_min=0.0330913538, A_max=0.7920515686\n",
      "B_min=8.8902010676, B_max=10.7254766697\n",
      "C_min=0.2011176582, C_max=0.2030878826\n",
      "min_validation=0.0000760525\n",
      "========================================\n",
      "56 outputs_second_search/solution_10_8_51.npy\n",
      "./temp/res_56_1_percent_noise\n",
      "A_min=0.0371946025, A_max=0.7858142974\n",
      "B_min=8.9070802883, B_max=10.7109927683\n",
      "C_min=0.2011264469, C_max=0.2030697953\n",
      "min_validation=0.0003237122\n",
      "========================================\n",
      "56 outputs_second_search/solution_10_8_51.npy\n",
      "./temp/res_56_2_percent_noise\n",
      "A_min=0.0384333921, A_max=0.7866598665\n",
      "B_min=8.9051158124, B_max=10.7146191488\n",
      "C_min=0.2011249387, C_max=0.2030729374\n",
      "min_validation=0.0000611625\n",
      "========================================\n",
      "56 outputs_second_search/solution_10_8_51.npy\n",
      "./temp/res_56_5_percent_noise\n",
      "A_min=0.0390775245, A_max=0.7891965737\n",
      "B_min=8.8927612547, B_max=10.7254982902\n",
      "C_min=0.2011095827, C_max=0.2030823638\n",
      "min_validation=0.0003815364\n",
      "========================================\n",
      "56 outputs_second_search/solution_10_8_51.npy\n",
      "./temp/res_62_no_noise\n",
      "A_min=0.0478547339, A_max=1.6675072460\n",
      "B_min=23.9279902957, B_max=27.1749230407\n",
      "C_min=0.2000046446, C_max=0.2000608040\n",
      "min_validation=0.0002459788\n",
      "========================================\n",
      "62 outputs_second_search/solution_10_9_132.npy\n",
      "./temp/res_62_1_percent_noise\n",
      "A_min=0.0522591638, A_max=1.6592080287\n",
      "B_min=23.9486652576, B_max=27.1513358253\n",
      "C_min=0.2000047793, C_max=0.2000605786\n",
      "min_validation=0.0000590068\n",
      "========================================\n",
      "62 outputs_second_search/solution_10_9_132.npy\n",
      "./temp/res_62_2_percent_noise\n",
      "A_min=0.0497298016, A_max=1.6619129152\n",
      "B_min=23.9478145535, B_max=27.1500717134\n",
      "C_min=0.2000046481, C_max=0.2000605704\n",
      "min_validation=0.0001003832\n",
      "========================================\n",
      "62 outputs_second_search/solution_10_9_132.npy\n",
      "./temp/res_62_5_percent_noise\n",
      "A_min=0.0420607470, A_max=1.6853128002\n",
      "B_min=23.9380350592, B_max=27.1534423314\n",
      "C_min=0.2000042031, C_max=0.2000605699\n",
      "min_validation=0.0004901818\n",
      "========================================\n",
      "62 outputs_second_search/solution_10_9_132.npy\n",
      "./temp/res_69_no_noise\n",
      "A_min=0.1070347551, A_max=1.4895044147\n",
      "B_min=23.6597106889, B_max=27.4502578093\n",
      "C_min=0.2001000969, C_max=0.2010110331\n",
      "min_validation=0.0000810463\n",
      "========================================\n",
      "69 outputs_second_search/solution_10_9_172.npy\n",
      "./temp/res_69_1_percent_noise\n",
      "A_min=0.1190242394, A_max=1.4847814592\n",
      "B_min=23.6994379486, B_max=27.4394819988\n",
      "C_min=0.2001006263, C_max=0.2010042915\n",
      "min_validation=0.0001330843\n",
      "========================================\n",
      "69 outputs_second_search/solution_10_9_172.npy\n",
      "./temp/res_69_2_percent_noise\n",
      "A_min=0.1201484683, A_max=1.4862542632\n",
      "B_min=23.6964056558, B_max=27.4410759683\n",
      "C_min=0.2000980539, C_max=0.2010049747\n",
      "min_validation=0.0004447111\n",
      "========================================\n",
      "69 outputs_second_search/solution_10_9_172.npy\n",
      "./temp/res_69_5_percent_noise\n",
      "A_min=0.1144333108, A_max=1.4935213861\n",
      "B_min=23.6820362097, B_max=27.4546519074\n",
      "C_min=0.2000854222, C_max=0.2010080595\n",
      "min_validation=0.0004654335\n",
      "========================================\n",
      "69 outputs_second_search/solution_10_9_172.npy\n",
      "./temp/res_73_no_noise\n",
      "A_min=0.0501380609, A_max=0.7430282720\n",
      "B_min=23.6160203441, B_max=27.4899110137\n",
      "C_min=0.2011447711, C_max=0.2026245606\n",
      "min_validation=0.0001323765\n",
      "========================================\n",
      "73 outputs_second_search/solution_10_9_38.npy\n",
      "./temp/res_73_1_percent_noise\n",
      "A_min=0.0550695725, A_max=0.7431286863\n",
      "B_min=23.6549444687, B_max=27.4772602006\n",
      "C_min=0.2011549482, C_max=0.2026034489\n",
      "min_validation=0.0000746412\n",
      "========================================\n",
      "73 outputs_second_search/solution_10_9_38.npy\n",
      "./temp/res_73_2_percent_noise\n",
      "A_min=0.0552520872, A_max=0.7460737877\n",
      "B_min=23.6480137927, B_max=27.4798159771\n",
      "C_min=0.2011535938, C_max=0.2026051596\n",
      "min_validation=0.0003709311\n",
      "========================================\n",
      "73 outputs_second_search/solution_10_9_38.npy\n",
      "./temp/res_73_5_percent_noise\n",
      "A_min=0.0507517494, A_max=0.7549090921\n",
      "B_min=23.6272217646, B_max=27.4874833068\n",
      "C_min=0.2011401601, C_max=0.2026181513\n",
      "min_validation=0.0013842260\n",
      "========================================\n",
      "73 outputs_second_search/solution_10_9_38.npy\n",
      "./temp/res_84_no_noise\n",
      "A_min=0.1379534273, A_max=8.2416058427\n",
      "B_min=25.5410542857, B_max=29.1482526587\n",
      "C_min=10.5310966586, C_max=10.8076479823\n",
      "min_validation=0.0000419499\n",
      "========================================\n",
      "84 outputs_second_search/solution_10_9_92.npy\n",
      "./temp/res_84_1_percent_noise\n",
      "A_min=0.1774374374, A_max=8.2416766421\n",
      "B_min=25.5585676993, B_max=29.1374475569\n",
      "C_min=10.5318753688, C_max=10.8057162288\n",
      "min_validation=0.0001675099\n",
      "========================================\n",
      "84 outputs_second_search/solution_10_9_92.npy\n",
      "./temp/res_84_2_percent_noise\n",
      "A_min=0.1890676456, A_max=8.2727336299\n",
      "B_min=25.5528964817, B_max=29.1409378844\n",
      "C_min=10.5317067031, C_max=10.8059909715\n",
      "min_validation=0.0000747072\n",
      "========================================\n",
      "84 outputs_second_search/solution_10_9_92.npy\n",
      "./temp/res_84_5_percent_noise\n",
      "A_min=0.1091402835, A_max=8.3659045933\n",
      "B_min=25.5358828291, B_max=29.1645410284\n",
      "C_min=10.5300806716, C_max=10.8068151997\n",
      "min_validation=0.0004475932\n",
      "========================================\n",
      "84 outputs_second_search/solution_10_9_92.npy\n"
     ]
    }
   ],
   "source": [
    "n_max = 10000\n",
    "results = []\n",
    "for index in [0, 1, 2, 5, 9, 10, 12, 21, 23, 29, 37, 38, 39, 40, 44, 56, 62, 69, 73, 84]:\n",
    "#for index in [0, 1, 5, 10, 29, 37, 39, 40, 44, 56, 62, 69, 84]:\n",
    "#for index in [2,9,12, 21, 23, 38, 73]:\n",
    "    for run in [\"no_noise\", \"1_percent_noise\", \"2_percent_noise\", \"5_percent_noise\"]:\n",
    "        print(f\"./temp/res_{index}_{run}\")\n",
    "        pinn = tu.NN.restore(\".\", f\"pinn_final_{index}_{run}\")\n",
    "        # Load max and mins        \n",
    "        with open(f\"./temp/res_{index}_{run}.npy\", \"rb\") as f:\n",
    "            (A_max, A_min, \n",
    "             B_max, B_min, \n",
    "             C_max, C_min, \n",
    "             min_validation)= np.load(f, allow_pickle=True)\n",
    "            print(f\"A_min={A_min:.10f}, A_max={A_max:.10f}\")\n",
    "            print(f\"B_min={B_min:.10f}, B_max={B_max:.10f}\")\n",
    "            print(f\"C_min={C_min:.10f}, C_max={C_max:.10f}\")\n",
    "            print(f\"min_validation={min_validation:.10f}\")\n",
    "\n",
    "        #################\n",
    "        (path,\n",
    "         (final_loss_A, final_params_A, \n",
    "             init_loss_A, init_params_A),\n",
    "            (final_loss_B, final_params_B, \n",
    "             init_loss_B, init_params_B),\n",
    "            (final_loss_C, final_params_C, \n",
    "             init_loss_C, init_params_C)\n",
    "           ) = search_for_params(index, \n",
    "                      pinn,\n",
    "                      A_max, A_min,\n",
    "                      B_max, B_min,\n",
    "                      C_max, C_min,\n",
    "                      n_max,\n",
    "                      slice_min = 45, \n",
    "                      slice_max = 100,)\n",
    "        results.append({\n",
    "          'index':index,\n",
    "          'run':run,\n",
    "          'path': path,\n",
    "          'A_max':A_max, \n",
    "          'A_min':A_min,\n",
    "          'B_max':B_max,\n",
    "          'B_min':B_min,\n",
    "          'C_max':C_max,\n",
    "          'C_min':C_min,\n",
    "          'final_loss_A':final_loss_A,\n",
    "          'final_params_A':final_params_A, \n",
    "          'init_loss_A':init_loss_A,\n",
    "          'init_params_A':init_params_A,\n",
    "          'final_loss_B':final_loss_B, \n",
    "          'final_params_B':final_params_B, \n",
    "          'init_loss_B':init_loss_B,\n",
    "          'init_params_B':init_params_B,\n",
    "          'final_loss_C':final_loss_C, \n",
    "          'final_params_C':final_params_C, \n",
    "          'init_loss_C':init_loss_C, \n",
    "          'init_params_C':init_params_C\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d83a0252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T20:05:29.662441Z",
     "start_time": "2023-07-25T20:05:05.891137Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"./temp/estimates_results_high_resolution_diffusion.npy\", \"wb\") as f:\n",
    "    np.save(f, results)\n",
    "n_max = 20\n",
    "# with open(f\"./temp/estimates_results_diffusion.npy\", \"rb\") as f:\n",
    "#     results = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7740a007",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T20:05:03.485438Z",
     "start_time": "2023-07-25T20:05:03.452071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f531cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T20:05:34.927926Z",
     "start_time": "2023-07-25T20:05:34.867207Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "n_max = 20\n",
    "simulate_from_start = True\n",
    "args_list = [\n",
    "    (simulate_from_start,\n",
    "     i,\n",
    "     dict_params[\"index\"],\n",
    "     dict_params[\"run\"],\n",
    "     dict_params[\"path\"],\n",
    "     dict_params[\"final_params_A\"][i], \n",
    "     dict_params[\"final_params_B\"][i], \n",
    "     dict_params[\"final_params_C\"][i]) for dict_params in results\n",
    "                                       for i in range(n_max) \n",
    "]\n",
    "\n",
    "args_list = [ (iter_i, item)\n",
    "    for iter_i, item in enumerate(args_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "938eecee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T00:13:25.215280Z",
     "start_time": "2023-07-25T20:05:34.933527Z"
    }
   },
   "outputs": [],
   "source": [
    "with Pool(pool_num) as pool:\n",
    "    results2 = pool.map(single_simulation, args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea87b383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T00:13:25.937383Z",
     "start_time": "2023-07-26T00:13:25.317905Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"./temp/simulation_from_start_results_high_resolution_diffusion.npy\", \"wb\") as f:\n",
    "    np.save(f, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38815555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T17:12:22.235655Z",
     "start_time": "2023-07-10T17:12:22.226648Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c036679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T00:13:26.156605Z",
     "start_time": "2023-07-26T00:13:25.951098Z"
    }
   },
   "outputs": [],
   "source": [
    "simulate_from_start = False\n",
    "args_list = [\n",
    "    (simulate_from_start,\n",
    "     i,\n",
    "     dict_params[\"index\"],\n",
    "     dict_params[\"run\"],\n",
    "     dict_params[\"path\"],\n",
    "     dict_params[\"final_params_A\"][i], \n",
    "     dict_params[\"final_params_B\"][i], \n",
    "     dict_params[\"final_params_C\"][i]) for dict_params in results\n",
    "                                       for i in range(n_max) \n",
    "]\n",
    "\n",
    "args_list = [ (iter_i, item)\n",
    "    for iter_i, item in enumerate(args_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba904106",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-18T11:42:06.924Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f248651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T04:18:06.389469Z",
     "start_time": "2023-07-26T00:13:26.160945Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with Pool(pool_num) as pool:\n",
    "    results3 = pool.map(single_simulation, args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45859dd6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-18T11:42:06.927Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3759313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T20:25:47.373989Z",
     "start_time": "2023-07-26T20:25:46.994372Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"./temp/simulation_from_end_results_high_resolution_diffusion.npy\", \"wb\") as f:\n",
    "    np.save(f, results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2914d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
